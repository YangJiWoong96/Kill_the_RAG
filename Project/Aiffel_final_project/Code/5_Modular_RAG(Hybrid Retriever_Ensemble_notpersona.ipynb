{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from typing import List, Dict, Any, Optional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "from langchain_community.chat_models import ChatClovaX\n",
    "from pymilvus import connections, utility\n",
    "from langchain_community.vectorstores.milvus import Milvus\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    Field,\n",
    ")  # BaseModel/Field 는 현재 코드에서 직접 사용되지 않지만, Langchain 내부 의존성 가능성 있음\n",
    "\n",
    "from langchain_elasticsearch import ElasticsearchRetriever\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ISBNMergingRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    검색된 Document 리스트를 ISBN 기준으로 그룹화하고,\n",
    "    같은 ISBN을 가진 문서들의 page_content를 병합하며,\n",
    "    그룹 내에서 가장 정보가 많은 메타데이터를 대표로 사용합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    base_retriever: BaseRetriever\n",
    "\n",
    "    def _extract_isbn(self, doc: Document) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        다양한 중첩 구조에서 ISBN 값을 추출합니다. (기존 로직 유지)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Case 1: 평평한 구조\n",
    "            for key in [\"ISBN\", \"isbn\"]:\n",
    "                if key in doc.metadata:\n",
    "                    isbn_val = doc.metadata[key]\n",
    "                    # .0 제거 및 문자열 변환 추가\n",
    "                    return str(isbn_val).replace(\".0\", \"\").strip() if isbn_val else None\n",
    "\n",
    "            # Case 2: 1단계 중첩 ('metadata' 키 안에 메타데이터가 있는 경우 - ES Retriever 수정 후 이 경로 예상)\n",
    "            inner_meta = doc.metadata.get(\"metadata\", {})\n",
    "            if isinstance(inner_meta, dict):\n",
    "                for key in [\"ISBN\", \"isbn\"]:\n",
    "                    if key in inner_meta:\n",
    "                        isbn_val = inner_meta[key]\n",
    "                        return (\n",
    "                            str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                            if isbn_val\n",
    "                            else None\n",
    "                        )\n",
    "\n",
    "                # Case 3: 2단계 중첩 (혹시 모를 경우 대비)\n",
    "                inner_inner_meta = inner_meta.get(\"metadata\", {})\n",
    "                if isinstance(inner_inner_meta, dict):\n",
    "                    for key in [\"ISBN\", \"isbn\"]:\n",
    "                        if key in inner_inner_meta:\n",
    "                            isbn_val = inner_inner_meta[key]\n",
    "                            return (\n",
    "                                str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                                if isbn_val\n",
    "                                else None\n",
    "                            )\n",
    "\n",
    "            # Case 4: Elasticsearch `_source.metadata.ISBN` 구조 (ES Retriever 수정 전 대비)\n",
    "            source_meta = doc.metadata.get(\"_source\", {}).get(\"metadata\", {})\n",
    "            if isinstance(source_meta, dict):\n",
    "                for key in [\"ISBN\", \"isbn\"]:\n",
    "                    if key in source_meta:\n",
    "                        isbn_val = source_meta[key]\n",
    "                        return (\n",
    "                            str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                            if isbn_val\n",
    "                            else None\n",
    "                        )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(\n",
    "                f\"[ISBN 추출 오류] Metadata: {doc.metadata}, Error: {e}\"\n",
    "            )  # 오류 시 메타데이터 로깅\n",
    "\n",
    "        logger.debug(\n",
    "            f\"ISBN 추출 실패 - Metadata: {doc.metadata}\"\n",
    "        )  # 실패 시 메타데이터 로깅\n",
    "        return None\n",
    "\n",
    "    def _get_best_metadata(self, doc_list: List[Document]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        주어진 문서 리스트(같은 ISBN 그룹) 내에서 가장 정보가 많은 메타데이터를 선택합니다.\n",
    "        정보량 기준: 필수 키('title', 'author', 'ISBN') 존재 여부 및 전체 키 개수\n",
    "        \"\"\"\n",
    "        best_meta = {}\n",
    "        max_score = -1\n",
    "\n",
    "        required_keys = {\"title\", \"author\", \"ISBN\"}  # 필수 메타데이터 키 정의\n",
    "\n",
    "        for doc in doc_list:\n",
    "            current_meta = doc.metadata\n",
    "            score = 0\n",
    "\n",
    "            # 1. 필수 키 존재 점수\n",
    "            #    (소문자로 변환하여 키 비교 - 대소문자 문제 방지)\n",
    "            keys_lower = {k.lower() for k in current_meta.keys()}\n",
    "            required_keys_lower = {rk.lower() for rk in required_keys}\n",
    "            score += sum(\n",
    "                1\n",
    "                for req_key in required_keys_lower\n",
    "                if req_key in keys_lower\n",
    "                and current_meta.get(\n",
    "                    next((k for k in current_meta if k.lower() == req_key), None)\n",
    "                )\n",
    "            )  # 값이 있는 경우만 점수 부여\n",
    "\n",
    "            # 2. 전체 키 개수 점수 (가중치 낮게)\n",
    "            score += len(current_meta) * 0.1\n",
    "\n",
    "            # 최고 점수 메타데이터 갱신\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_meta = current_meta\n",
    "\n",
    "        # 최종적으로 선택된 메타데이터 로깅 (디버깅용)\n",
    "        if best_meta:\n",
    "            logger.debug(\n",
    "                f\"선택된 최적 메타데이터 (Score: {max_score:.2f}): {best_meta}\"\n",
    "            )\n",
    "        else:\n",
    "            # 그룹 내 모든 문서의 메타데이터가 비어있는 극단적인 경우\n",
    "            logger.warning(\n",
    "                f\"ISBN 그룹 내에서 유효한 메타데이터를 찾지 못함. 첫 번째 문서 메타데이터 사용 시도.\"\n",
    "            )\n",
    "            if doc_list:  # 문서 목록이 비어있지 않다면\n",
    "                best_meta = doc_list[\n",
    "                    0\n",
    "                ].metadata  # 최소한 첫 번째 문서 메타데이터라도 반환\n",
    "\n",
    "        # 선택된 메타데이터 반환 (복사본)\n",
    "        return dict(best_meta)\n",
    "\n",
    "    def _merge_documents_by_isbn(\n",
    "        self, docs: List[Document], is_async=False\n",
    "    ) -> List[Document]:\n",
    "        grouped = defaultdict(list)\n",
    "        merged_docs = []\n",
    "\n",
    "        logger.info(\n",
    "            f\"[{'Async' if is_async else 'Sync'}] 병합 전 입력 문서 수: {len(docs)}\"\n",
    "        )\n",
    "\n",
    "        # 1. ISBN 기준으로 그룹화\n",
    "        for idx, doc in enumerate(docs):\n",
    "            isbn = self._extract_isbn(doc)  # 수정된 ISBN 추출 로직 사용\n",
    "            if isbn:\n",
    "                grouped[isbn].append(doc)\n",
    "            else:\n",
    "                # ISBN 추출 실패 시 경고 로그 강화\n",
    "                logger.warning(\n",
    "                    f\"[{'Async' if is_async else 'Sync'}] Doc {idx} ISBN 추출 실패 - Metadata: {doc.metadata}\"\n",
    "                )\n",
    "\n",
    "        # 2. 그룹별 병합 처리\n",
    "        for isbn, doc_list in grouped.items():\n",
    "            # --- <<< 메타데이터 선택 로직 변경 >>> ---\n",
    "            # 그룹 내 문서 리스트에서 가장 정보가 많은 메타데이터를 선택\n",
    "            merged_meta = self._get_best_metadata(doc_list)\n",
    "            # --- <<< 변경 끝 >>> ---\n",
    "\n",
    "            # 페이지 내용 병합 (기존 로직 유지)\n",
    "            combined_text = \"\\n\\n---\\n\\n\".join(\n",
    "                d.page_content for d in doc_list if d.page_content\n",
    "            ).strip()\n",
    "\n",
    "            # 병합된 내용과 선택된 메타데이터로 새 Document 생성\n",
    "            if combined_text:\n",
    "                # 병합된 문서 생성 전, 최종 메타데이터 확인 (디버깅)\n",
    "                logger.debug(f\"ISBN {isbn} 병합: 최종 사용될 메타데이터: {merged_meta}\")\n",
    "                merged_docs.append(\n",
    "                    Document(page_content=combined_text, metadata=merged_meta)\n",
    "                )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"[{'Async' if is_async else 'Sync'}] ISBN {isbn} 병합 후 내용 없음. 제외됨. 사용된 메타데이터: {merged_meta}\"\n",
    "                )\n",
    "\n",
    "        logger.info(\n",
    "            f\"[{'Async' if is_async else 'Sync'}] ISBN 병합 그룹 수: {len(grouped)}\"\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"[{'Async' if is_async else 'Sync'}] 병합 후 최종 문서 수: {len(merged_docs)}\"\n",
    "        )\n",
    "        return merged_docs\n",
    "\n",
    "    # _get_relevant_documents, _aget_relevant_documents 메서드는 변경 없음\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        try:\n",
    "            docs = self.base_retriever.get_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"기본 리트리버 동기 검색 오류: '{query}' → {e}\", exc_info=True\n",
    "            )\n",
    "            docs = []\n",
    "        logger.info(f\"Sync 검색 결과 총 문서 수: {len(docs)}\")\n",
    "        return self._merge_documents_by_isbn(docs, is_async=False)\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        try:\n",
    "            docs = await self.base_retriever.aget_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"기본 리트리버 비동기 검색 오류: '{query}' → {e}\", exc_info=True\n",
    "            )\n",
    "            docs = []\n",
    "        logger.info(f\"Async 검색 결과 총 문서 수: {len(docs)}\")\n",
    "        return self._merge_documents_by_isbn(docs, is_async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text는 아래와 같은 형태로 들어가서 청크\n",
    "\n",
    "# 제목 : [값]\n",
    "# 분류 : [값]\n",
    "# 저자 : [값]\n",
    "# 저자소개 : [값]\n",
    "# 책 소개 : [값]\n",
    "# 목차 : [값]\n",
    "# 출판사리뷰 : [값]\n",
    "\n",
    "# 임베딩 pkl에 포함된 메타데이터 컬럼과 (임베딩,원본text)로 묶인 컬럼\n",
    "\n",
    "# 메타데이터 및 벡터 문서 컬럼 설정\n",
    "\n",
    "# metadata_columns = [\n",
    "#     \"ISBN\",\n",
    "#     \"페이지\",\n",
    "#     \"가격\",\n",
    "#     \"제목\",\n",
    "#     \"부제\",\n",
    "#     \"저자\",\n",
    "#     \"분류\",\n",
    "#     \"목차\",\n",
    "#     \"발행자\",\n",
    "#     \"표지\",\n",
    "# ]\n",
    "# vector_doc_columns = [\n",
    "#     \"제목\",\n",
    "#     \"부제\",\n",
    "#     \"분류\",\n",
    "#     \"저자\",\n",
    "#     \"저자소개\",\n",
    "#     \"책소개\",\n",
    "#     \"출판사리뷰\",\n",
    "#     \"추천사\",\n",
    "#     \"목차\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Util Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar_question(new_emb, prev_embeds, threshold=0.65):\n",
    "    \"\"\"새 질문 임베딩이 이전 질문 임베딩 목록과 유사한지 확인\"\"\"\n",
    "    if not prev_embeds:\n",
    "        return False\n",
    "    # 코사인 유사도 계산\n",
    "    sim_scores = cosine_similarity([new_emb], prev_embeds)[0]\n",
    "    max_score = np.max(sim_scores)  # 가장 높은 유사도 점수\n",
    "    logger.info(\n",
    "        f\"[질문 유사도 판단] Max Similarity = {max_score:.3f} (Threshold = {threshold})\"\n",
    "    )\n",
    "    return max_score > threshold\n",
    "\n",
    "\n",
    "def extract_field(text, field_name):\n",
    "    \"\"\"주어진 텍스트에서 '필드명 : 값' 형식의 라인을 찾아 값을 추출\"\"\"\n",
    "    # 정규 표현식 패턴: 시작 부분 공백 허용, 필드명, 콜론(:), 값, 끝 부분 공백 허용\n",
    "    pattern = rf\"^\\s*{re.escape(field_name)}\\s*[:：]\\s*(.*?)\\s*$\"\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        match = re.search(pattern, line, re.IGNORECASE)  # 대소문자 구분 없이 매칭\n",
    "        if match:\n",
    "            return match.group(1).strip()  # 매칭된 값의 양쪽 공백 제거 후 반환\n",
    "    return \"\"  # 매칭되는 필드가 없으면 빈 문자열 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 환경설정 & 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 14:58:17,406 - INFO - ClovaX 임베딩 및 Chat 모델 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"NCP_CLOVASTUDIO_API_KEY\")\n",
    "api_url = os.getenv(\"NCP_CLOVASTUDIO_API_URL\", \"https://clovastudio.stream.ntruss.com/\")\n",
    "milvus_host = os.getenv(\"MILVUS_HOST\", \"localhost\")\n",
    "milvus_port = os.getenv(\"MILVUS_PORT\", \"19530\")\n",
    "es_url = os.getenv(\"ELASTICSEARCH_URL\", \"http://localhost:9200\")\n",
    "es_index_name = \"book_bm25_index_v2\"  # 인덱스 이름 변경 (SelfQuery 제거 반영)\n",
    "\n",
    "# 필수 환경 변수 확인\n",
    "if not api_key:\n",
    "    raise ValueError(\"NCP_CLOVASTUDIO_API_KEY 환경 변수가 설정되지 않았습니다.\")\n",
    "if not api_url:\n",
    "    raise ValueError(\"NCP_CLOVASTUDIO_API_URL 환경 변수가 설정되지 않았습니다.\")\n",
    "if not es_url:\n",
    "    raise ValueError(\"ELASTICSEARCH_URL 환경 변수가 설정되지 않았습니다.\")\n",
    "\n",
    "# Langchain이 사용할 환경 변수 설정 (필요시)\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_KEY\"] = api_key\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_URL\"] = api_url\n",
    "\n",
    "# --- 모델 초기화 ---\n",
    "try:\n",
    "    ncp_embeddings = ClovaXEmbeddings(model=\"bge-m3\")  # ClovaX 임베딩 모델\n",
    "    llm_clova = ChatClovaX(model=\"HCX-003\", max_tokens=2048)  # ClovaX 챗 모델\n",
    "    logger.info(\"ClovaX 임베딩 및 Chat 모델 초기화 완료\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"ClovaX 모델 초기화 실패: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 15:00:10,914 - INFO - 임베딩 데이터 로드 완료: 116218개\n",
      "2025-04-07 15:01:22,576 - INFO - 총 116218개의 Document 객체 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "embedding_file = r\"C:\\Kill_the_RAG\\Project\\Aiffel_final_project\\Code\\Data\\final_embedding\\final_embedding.pkl\"\n",
    "if os.path.exists(embedding_file):\n",
    "    try:\n",
    "        with open(embedding_file, \"rb\") as f:\n",
    "            saved_data = pickle.load(f)\n",
    "        # pkl 파일에서 (텍스트, 임베딩) 쌍과 메타데이터 리스트 추출\n",
    "        all_text_embedding_pairs = [\n",
    "            (v[\"text\"], v[\"embedding\"])\n",
    "            for v in saved_data.values()\n",
    "            if \"text\" in v and \"embedding\" in v\n",
    "        ]\n",
    "        all_metadata_list = [\n",
    "            v[\"metadata\"] for v in saved_data.values() if \"metadata\" in v\n",
    "        ]\n",
    "        # 로드된 데이터 개수 일치 확인\n",
    "        if len(all_text_embedding_pairs) != len(all_metadata_list):\n",
    "            logger.warning(\n",
    "                f\"로드된 텍스트/임베딩 쌍({len(all_text_embedding_pairs)})과 메타데이터({len(all_metadata_list)}) 개수 불일치.\"\n",
    "            )\n",
    "            min_len = min(len(all_text_embedding_pairs), len(all_metadata_list))\n",
    "            all_text_embedding_pairs = all_text_embedding_pairs[:min_len]\n",
    "            all_metadata_list = all_metadata_list[:min_len]\n",
    "            logger.info(f\"데이터를 {min_len}개로 조정하여 계속 진행.\")\n",
    "\n",
    "        logger.info(f\"임베딩 데이터 로드 완료: {len(all_text_embedding_pairs)}개\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"임베딩 파일 로드 실패: {e}\", exc_info=True)\n",
    "        raise\n",
    "else:\n",
    "    raise FileNotFoundError(f\"임베딩 파일을 찾을 수 없음: {embedding_file}\")\n",
    "\n",
    "# --- 메타데이터 처리 ---\n",
    "# 원본 키 -> 목표 키 매핑 정의 (Langchain Document의 metadata 필드명 기준)\n",
    "metadata_mapping = {\n",
    "    \"ISBN\": \"ISBN\",  # ISBN은 그대로 유지\n",
    "    \"페이지\": \"page\",  # 페이지 수\n",
    "    \"가격\": \"price\",  # 가격\n",
    "    \"제목\": \"title\",  # 제목\n",
    "    \"부제\": \"subtitle\",  # 부제\n",
    "    \"저자\": \"author\",  # 저자\n",
    "    \"분류\": \"category\",  # 분류/카테고리\n",
    "    \"저자소개\": \"author_intro\",  # 저자 소개\n",
    "    \"책소개\": \"book_intro\",  # 책 소개\n",
    "    \"목차\": \"table_of_contents\",  # 목차\n",
    "    \"출판사리뷰\": \"publisher_review\",  # 출판사 리뷰\n",
    "    \"추천사\": \"recommendation\",  # 추천사\n",
    "    \"발행자\": \"publisher\",  # 출판사/발행자\n",
    "    \"표지\": \"book_cover\",  # 표지 URL (사용한다면)\n",
    "}\n",
    "\n",
    "\n",
    "# 메타데이터 클리닝 함수: NA값 처리, 타입 변환 등\n",
    "def clean_metadata(meta: dict) -> dict:\n",
    "    cleaned = {}\n",
    "    target_keys = list(metadata_mapping.values())  # 목표 키 목록\n",
    "\n",
    "    # 원본 키와 목표 키 매핑 역전\n",
    "    original_to_target = {\n",
    "        k_orig: k_target for k_orig, k_target in metadata_mapping.items()\n",
    "    }\n",
    "\n",
    "    for target_key in target_keys:\n",
    "        # 해당 목표 키에 매핑된 원본 키 찾기\n",
    "        original_key = next(\n",
    "            (k for k, v in original_to_target.items() if v == target_key), None\n",
    "        )\n",
    "\n",
    "        # 원본 딕셔너리에서 값 가져오기 (원본 키 또는 목표 키 이름으로 시도)\n",
    "        value = (\n",
    "            meta.get(original_key)\n",
    "            if original_key and original_key in meta\n",
    "            else meta.get(target_key)\n",
    "        )\n",
    "\n",
    "        # 키별 타입 처리 및 NA 처리\n",
    "        if pd.isna(value):\n",
    "            if target_key in [\"page\", \"price\"]:\n",
    "                cleaned[target_key] = 0\n",
    "            else:\n",
    "                cleaned[target_key] = \"\"\n",
    "        elif target_key == \"ISBN\":  # ISBN 타입 에러 '.0'으로 끝나는 경우 제거\n",
    "            try:\n",
    "                str_value = str(value).strip()\n",
    "                if str_value.endswith(\".0\"):\n",
    "                    cleaned[target_key] = str_value[:-2]\n",
    "                else:\n",
    "                    cleaned[target_key] = str_value\n",
    "            except Exception as e:\n",
    "                logger.warning(\n",
    "                    f\"ISBN 값 '{value}' 처리 중 오류 발생 (기본 문자열 변환 사용): {e}\"\n",
    "                )\n",
    "                cleaned[target_key] = str(value).strip()\n",
    "        elif target_key == \"subtitle\":\n",
    "            cleaned[target_key] = str(value)\n",
    "        elif target_key in [\"page\", \"price\"]:\n",
    "            try:\n",
    "                cleaned[target_key] = int(float(value))\n",
    "            except (ValueError, TypeError):\n",
    "                logger.warning(\n",
    "                    f\"'{target_key}' 값 '{value}' 정수 변환 실패. 0으로 설정.\"\n",
    "                )\n",
    "                cleaned[target_key] = 0\n",
    "        else:\n",
    "            cleaned[target_key] = str(value)\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# --- Langchain Document 객체 생성 ---\n",
    "documents = []\n",
    "for i, (pair, meta) in enumerate(zip(all_text_embedding_pairs, all_metadata_list)):\n",
    "    try:\n",
    "        cleaned_meta = clean_metadata(meta)  # 메타데이터 클리닝\n",
    "        # Document 객체 생성: page_content는 텍스트, metadata는 클리닝된 딕셔너리\n",
    "        documents.append(Document(page_content=pair[0], metadata=cleaned_meta))\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"{i}번째 데이터 처리 중 오류 발생: {e}. 메타데이터: {meta}\", exc_info=True\n",
    "        )\n",
    "        # 오류 발생 시 해당 데이터 건너뛰거나 기본값으로 처리 가능\n",
    "\n",
    "logger.info(f\"총 {len(documents)}개의 Document 객체 생성 완료.\")\n",
    "\n",
    "# Document 리스트에서 텍스트, 임베딩, 메타데이터 분리 (이후 사용 위함)\n",
    "texts = [doc.page_content for doc in documents]\n",
    "embeds = [\n",
    "    pair[1] for pair in all_text_embedding_pairs[: len(documents)]\n",
    "]  # documents 개수에 맞춰 슬라이싱\n",
    "metadatas = [doc.metadata for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 15:01:28,278 - INFO - Milvus 유틸리티 함수용 임시 연결 설정 완료 (alias: utility_check_conn).\n",
      "2025-04-07 15:01:28,294 - WARNING - 기존 Milvus 컬렉션 'book_rag_db_v_no_sq'을 삭제.\n",
      "2025-04-07 15:01:28,454 - INFO - Milvus 유틸리티 함수용 임시 연결 해제 완료 (alias: utility_check_conn).\n",
      "2025-04-07 15:01:28,463 - INFO - Langchain Milvus 인스턴스 초기화 및 연결 설정 완료 (컬렉션: 'book_rag_db_v_no_sq').\n",
      "2025-04-07 15:01:28,509 - INFO - 사전 계산된 임베딩 사용: 116218개\n",
      "2025-04-07 15:04:55,277 - INFO - Milvus에 116218개의 텍스트와 임베딩 추가 완료.\n",
      "2025-04-07 15:04:55,903 - INFO - ClovaXEmbeddings.embed_documents 메소드 원상 복구 완료.\n"
     ]
    }
   ],
   "source": [
    "# --- Milvus 벡터 저장소 설정 ---\n",
    "collection_name = \"book_rag_db_v_no_sq\"  # 컬렉션 name\n",
    "temp_conn_alias = \"utility_check_conn\"  # 임시 연결\n",
    "\n",
    "# 기존 컬렉션 확인 및 삭제 (임시 연결 사용)\n",
    "try:\n",
    "    connections.connect(alias=temp_conn_alias, host=milvus_host, port=milvus_port)\n",
    "    logger.info(\n",
    "        f\"Milvus 유틸리티 함수용 임시 연결 설정 완료 (alias: {temp_conn_alias}).\"\n",
    "    )\n",
    "    if utility.has_collection(collection_name, using=temp_conn_alias):\n",
    "        logger.warning(f\"기존 Milvus 컬렉션 '{collection_name}'을 삭제.\")\n",
    "        utility.drop_collection(collection_name, using=temp_conn_alias)\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Milvus 컬렉션 '{collection_name}'이(가) 존재하지 않음. 새로 생성.\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Milvus 유틸리티 함수 실행 중 오류 발생: {e}\", exc_info=True)\n",
    "finally:\n",
    "    # 임시 연결 해제\n",
    "    try:\n",
    "        if connections.get_connection_addr(temp_conn_alias):\n",
    "            connections.disconnect(temp_conn_alias)\n",
    "            logger.info(\n",
    "                f\"Milvus 유틸리티 함수용 임시 연결 해제 완료 (alias: {temp_conn_alias}).\"\n",
    "            )\n",
    "    except Exception as disconnect_e:\n",
    "        logger.warning(f\"Milvus 임시 연결 해제 중 오류 (무시 가능): {disconnect_e}\")\n",
    "\n",
    "# Milvus 벡터 저장소 인스턴스 생성 및 데이터 추가\n",
    "try:\n",
    "    vectorstore = Milvus(\n",
    "        embedding_function=ncp_embeddings,  # 사용할 임베딩 함수\n",
    "        collection_name=collection_name,  # 사용할 컬렉션 이름\n",
    "        connection_args={\"host\": milvus_host, \"port\": milvus_port},  # Milvus 연결 정보\n",
    "        auto_id=True,  # Milvus가 자동으로 ID 생성하도록 설정\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Langchain Milvus 인스턴스 초기화 및 연결 설정 완료 (컬렉션: '{collection_name}').\"\n",
    "    )\n",
    "\n",
    "    # --- 사전 계산된 임베딩 사용 로직 (Monkey Patching) ---\n",
    "    # 기존 embed_documents 메소드 백업\n",
    "    original_embed_documents = ClovaXEmbeddings.embed_documents\n",
    "\n",
    "    # 사전 계산된 임베딩을 반환하는 새 메소드 정의\n",
    "    def precomputed_embed_documents(cls, input_texts: List[str]) -> List[List[float]]:\n",
    "        # add_texts 호출 시 전달된 texts 리스트와 미리 로드한 texts 리스트가 정확히 일치하는 경우,\n",
    "        # 미리 로드한 embeds 리스트를 반환 (API 호출 회피)\n",
    "        # 주의: 이 방식은 add_texts 호출 시점에 texts 순서와 내용이 정확히 일치해야 함\n",
    "        if len(input_texts) == len(texts) and all(\n",
    "            t1 == t2 for t1, t2 in zip(input_texts, texts)\n",
    "        ):\n",
    "            logger.info(f\"사전 계산된 임베딩 사용: {len(embeds)}개\")\n",
    "            return embeds\n",
    "        else:\n",
    "            # 일치하지 않으면 원래 embed_documents 메소드 호출\n",
    "            logger.warning(\n",
    "                \"입력 텍스트가 사전 계산된 데이터와 불일치. ClovaX API를 통해 임베딩 수행.\"\n",
    "            )\n",
    "            # 원래 클래스 메소드를 호출하는 방식으로 변경\n",
    "            return original_embed_documents.__func__(cls, input_texts)\n",
    "\n",
    "    # ClovaXEmbeddings 클래스의 embed_documents 메소드를 새 메소드로 교체 (Patch)\n",
    "    ClovaXEmbeddings.embed_documents = classmethod(precomputed_embed_documents)\n",
    "\n",
    "    # 데이터 추가 (이 때 precomputed_embed_documents가 호출됨)\n",
    "    vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
    "    logger.info(f\"Milvus에 {len(texts)}개의 텍스트와 임베딩 추가 완료.\")\n",
    "\n",
    "    # 작업 완료 후 원래 메소드로 복구\n",
    "    ClovaXEmbeddings.embed_documents = original_embed_documents\n",
    "    logger.info(\"ClovaXEmbeddings.embed_documents 메소드 원상 복구 완료.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Milvus 데이터 추가 중 오류 발생: {e}\", exc_info=True)\n",
    "    # 오류 발생 시에도 반드시 원래 메소드로 복구 시도\n",
    "    if (\n",
    "        \"original_embed_documents\" in locals()\n",
    "        and hasattr(ClovaXEmbeddings, \"embed_documents\")\n",
    "        and ClovaXEmbeddings.embed_documents != original_embed_documents\n",
    "    ):\n",
    "        ClovaXEmbeddings.embed_documents = original_embed_documents\n",
    "        logger.info(\n",
    "            \"오류 발생 후 ClovaXEmbeddings.embed_documents 메소드 원상 복구 시도 완료.\"\n",
    "        )\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 15:16:29,847 - INFO - Elasticsearch 연결 시도 중: http://localhost:9200...\n",
      "2025-04-07 15:16:33,478 - INFO - HEAD http://localhost:9200/ [status:200 duration:3.619s]\n",
      "2025-04-07 15:16:33,479 - INFO - Elasticsearch 연결 성공\n",
      "2025-04-07 15:16:33,793 - INFO - HEAD http://localhost:9200/book_bm25_index_v2 [status:200 duration:0.314s]\n",
      "2025-04-07 15:16:33,794 - WARNING - 기존 Elasticsearch 인덱스 'book_bm25_index_v2' 삭제 중...\n",
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_7132\\495359522.py:15: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=es_index_name, ignore=[400, 404])\n",
      "2025-04-07 15:16:48,414 - INFO - DELETE http://localhost:9200/book_bm25_index_v2 [status:200 duration:13.838s]\n",
      "2025-04-07 15:16:48,416 - INFO - 기존 Elasticsearch 인덱스 'book_bm25_index_v2' 삭제 완료.\n",
      "2025-04-07 15:16:48,417 - INFO - Langchain ElasticsearchStore 인스턴스 초기화 완료 (인덱스: 'book_bm25_index_v2', BM25 검색 전용 - ExactRetrievalStrategy).\n",
      "2025-04-07 15:16:48,418 - INFO - Elasticsearch에 문서 인덱싱 시작 (총 116218개)...\n",
      "2025-04-07 15:16:59,140 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:7.717s]\n",
      "2025-04-07 15:17:00,040 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.820s]\n",
      "2025-04-07 15:17:00,725 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.507s]\n",
      "2025-04-07 15:17:01,234 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.395s]\n",
      "2025-04-07 15:17:01,651 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.339s]\n",
      "2025-04-07 15:17:02,043 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.304s]\n",
      "2025-04-07 15:17:02,460 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.330s]\n",
      "2025-04-07 15:17:02,885 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.363s]\n",
      "2025-04-07 15:17:03,230 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.276s]\n",
      "2025-04-07 15:17:03,596 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.296s]\n",
      "2025-04-07 15:17:04,030 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.361s]\n",
      "2025-04-07 15:17:04,386 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 15:17:04,729 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.269s]\n",
      "2025-04-07 15:17:05,061 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.271s]\n",
      "2025-04-07 15:17:05,389 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.271s]\n",
      "2025-04-07 15:17:05,747 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.295s]\n",
      "2025-04-07 15:17:06,034 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.218s]\n",
      "2025-04-07 15:17:06,450 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.313s]\n",
      "2025-04-07 15:17:06,952 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.430s]\n",
      "2025-04-07 15:17:07,535 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.527s]\n",
      "2025-04-07 15:17:08,120 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.502s]\n",
      "2025-04-07 15:17:08,740 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.556s]\n",
      "2025-04-07 15:17:09,415 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.602s]\n",
      "2025-04-07 15:17:10,034 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.524s]\n",
      "2025-04-07 15:17:10,738 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.584s]\n",
      "2025-04-07 15:17:11,248 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.452s]\n",
      "2025-04-07 15:17:12,474 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.160s]\n",
      "2025-04-07 15:17:14,740 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.059s]\n",
      "2025-04-07 15:17:16,985 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.057s]\n",
      "2025-04-07 15:17:18,861 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.774s]\n",
      "2025-04-07 15:17:21,255 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.272s]\n",
      "2025-04-07 15:17:21,634 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.299s]\n",
      "2025-04-07 15:17:22,403 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.710s]\n",
      "2025-04-07 15:17:22,858 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.323s]\n",
      "2025-04-07 15:17:23,659 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.745s]\n",
      "2025-04-07 15:17:24,510 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.684s]\n",
      "2025-04-07 15:17:25,546 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.953s]\n",
      "2025-04-07 15:17:25,822 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.244s]\n",
      "2025-04-07 15:17:26,134 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.257s]\n",
      "2025-04-07 15:17:26,455 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.244s]\n",
      "2025-04-07 15:17:26,835 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.307s]\n",
      "2025-04-07 15:17:27,053 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.171s]\n",
      "2025-04-07 15:17:27,287 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.165s]\n",
      "2025-04-07 15:17:27,561 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.222s]\n",
      "2025-04-07 15:17:27,912 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.276s]\n",
      "2025-04-07 15:17:28,224 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.256s]\n",
      "2025-04-07 15:17:28,523 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.232s]\n",
      "2025-04-07 15:17:28,861 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.258s]\n",
      "2025-04-07 15:17:29,192 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.262s]\n",
      "2025-04-07 15:17:29,537 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.265s]\n",
      "2025-04-07 15:17:29,815 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.207s]\n",
      "2025-04-07 15:17:30,096 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.199s]\n",
      "2025-04-07 15:17:30,396 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 15:17:30,684 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.200s]\n",
      "2025-04-07 15:17:31,022 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.237s]\n",
      "2025-04-07 15:18:51,818 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.304s]\n",
      "2025-04-07 15:18:52,271 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.254s]\n",
      "2025-04-07 15:18:52,661 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.190s]\n",
      "2025-04-07 15:18:53,566 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.754s]\n",
      "2025-04-07 15:18:54,125 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.421s]\n",
      "2025-04-07 15:18:54,550 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.326s]\n",
      "2025-04-07 15:18:55,942 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.282s]\n",
      "2025-04-07 15:18:56,369 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.306s]\n",
      "2025-04-07 15:18:56,687 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.238s]\n",
      "2025-04-07 15:18:57,019 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.258s]\n",
      "2025-04-07 15:18:57,352 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.256s]\n",
      "2025-04-07 15:18:57,647 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 15:18:58,032 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.296s]\n",
      "2025-04-07 15:18:58,324 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.229s]\n",
      "2025-04-07 15:18:58,777 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.376s]\n",
      "2025-04-07 15:18:59,069 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.222s]\n",
      "2025-04-07 15:18:59,406 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.255s]\n",
      "2025-04-07 15:18:59,754 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.277s]\n",
      "2025-04-07 15:19:00,046 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.228s]\n",
      "2025-04-07 15:19:00,406 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.296s]\n",
      "2025-04-07 15:19:00,703 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.210s]\n",
      "2025-04-07 15:19:01,063 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.278s]\n",
      "2025-04-07 15:19:01,356 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.228s]\n",
      "2025-04-07 15:19:01,712 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.285s]\n",
      "2025-04-07 15:19:02,018 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.223s]\n",
      "2025-04-07 15:19:02,301 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.212s]\n",
      "2025-04-07 15:19:02,579 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.204s]\n",
      "2025-04-07 15:19:02,842 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.198s]\n",
      "2025-04-07 15:19:03,553 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.638s]\n",
      "2025-04-07 15:19:03,910 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.287s]\n",
      "2025-04-07 15:19:04,286 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.315s]\n",
      "2025-04-07 15:19:04,629 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.286s]\n",
      "2025-04-07 15:19:04,886 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.201s]\n",
      "2025-04-07 15:19:05,091 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.150s]\n",
      "2025-04-07 15:19:05,313 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.169s]\n",
      "2025-04-07 15:19:05,527 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.154s]\n",
      "2025-04-07 15:19:05,716 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.142s]\n",
      "2025-04-07 15:19:05,986 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.209s]\n",
      "2025-04-07 15:19:06,193 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.149s]\n",
      "2025-04-07 15:19:06,412 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.165s]\n",
      "2025-04-07 15:19:06,710 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.239s]\n",
      "2025-04-07 15:19:07,474 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.703s]\n",
      "2025-04-07 15:19:07,801 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.259s]\n",
      "2025-04-07 15:19:08,237 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.370s]\n",
      "2025-04-07 15:19:08,467 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.157s]\n",
      "2025-04-07 15:19:08,707 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.155s]\n",
      "2025-04-07 15:19:09,060 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.290s]\n",
      "2025-04-07 15:19:09,286 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.170s]\n",
      "2025-04-07 15:19:09,546 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.197s]\n",
      "2025-04-07 15:19:09,823 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.222s]\n",
      "2025-04-07 15:19:10,057 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.173s]\n",
      "2025-04-07 15:19:10,265 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.141s]\n",
      "2025-04-07 15:19:10,527 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.188s]\n",
      "2025-04-07 15:19:10,781 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.183s]\n",
      "2025-04-07 15:19:11,048 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.187s]\n",
      "2025-04-07 15:19:11,335 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.216s]\n",
      "2025-04-07 15:19:11,595 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.184s]\n",
      "2025-04-07 15:19:11,970 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.307s]\n",
      "2025-04-07 15:19:12,191 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.150s]\n",
      "2025-04-07 15:19:12,414 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.168s]\n",
      "2025-04-07 15:19:12,665 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.191s]\n",
      "2025-04-07 15:19:12,870 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.146s]\n",
      "2025-04-07 15:19:13,087 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.158s]\n",
      "2025-04-07 15:19:13,301 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.157s]\n",
      "2025-04-07 15:19:13,558 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.203s]\n",
      "2025-04-07 15:19:13,773 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.163s]\n",
      "2025-04-07 15:19:14,063 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.228s]\n",
      "2025-04-07 15:19:14,295 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.175s]\n",
      "2025-04-07 15:19:14,612 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.171s]\n",
      "2025-04-07 15:19:14,858 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.175s]\n",
      "2025-04-07 15:19:15,091 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.172s]\n",
      "2025-04-07 15:19:15,324 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.169s]\n",
      "2025-04-07 15:19:15,530 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.153s]\n",
      "2025-04-07 15:19:15,762 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.172s]\n",
      "2025-04-07 15:19:16,051 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.234s]\n",
      "2025-04-07 15:19:16,295 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.182s]\n",
      "2025-04-07 15:19:16,486 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.140s]\n",
      "2025-04-07 15:19:16,764 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.223s]\n",
      "2025-04-07 15:19:16,997 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.178s]\n",
      "2025-04-07 15:19:17,238 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.181s]\n",
      "2025-04-07 15:19:17,441 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.149s]\n",
      "2025-04-07 15:19:17,689 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.187s]\n",
      "2025-04-07 15:19:17,940 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.185s]\n",
      "2025-04-07 15:19:18,156 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.161s]\n",
      "2025-04-07 15:19:18,379 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.158s]\n",
      "2025-04-07 15:19:18,679 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.222s]\n",
      "2025-04-07 15:19:18,891 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.144s]\n",
      "2025-04-07 15:19:19,121 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.163s]\n",
      "2025-04-07 15:19:19,397 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.191s]\n",
      "2025-04-07 15:19:19,738 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.253s]\n",
      "2025-04-07 15:19:19,997 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.185s]\n",
      "2025-04-07 15:19:20,383 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.311s]\n",
      "2025-04-07 15:19:20,613 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.167s]\n",
      "2025-04-07 15:19:20,820 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.153s]\n",
      "2025-04-07 15:19:21,044 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.163s]\n",
      "2025-04-07 15:19:21,275 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.172s]\n",
      "2025-04-07 15:19:21,564 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.220s]\n",
      "2025-04-07 15:19:21,867 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.237s]\n",
      "2025-04-07 15:19:22,074 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.148s]\n",
      "2025-04-07 15:19:22,258 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.129s]\n",
      "2025-04-07 15:19:22,477 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.157s]\n",
      "2025-04-07 15:19:22,710 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.174s]\n",
      "2025-04-07 15:19:22,939 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.171s]\n",
      "2025-04-07 15:19:23,184 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.183s]\n",
      "2025-04-07 15:19:23,456 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 15:19:23,690 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.163s]\n",
      "2025-04-07 15:19:23,910 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.164s]\n",
      "2025-04-07 15:19:24,166 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.204s]\n",
      "2025-04-07 15:19:24,332 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.120s]\n",
      "2025-04-07 15:19:24,737 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.353s]\n",
      "2025-04-07 15:19:24,969 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.175s]\n",
      "2025-04-07 15:19:25,194 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.171s]\n",
      "2025-04-07 15:19:25,432 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.184s]\n",
      "2025-04-07 15:19:25,649 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.155s]\n",
      "2025-04-07 15:19:25,886 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.171s]\n",
      "2025-04-07 15:19:26,157 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.179s]\n",
      "2025-04-07 15:19:26,787 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.553s]\n",
      "2025-04-07 15:19:27,071 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 15:19:27,303 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.170s]\n",
      "2025-04-07 15:19:27,553 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.184s]\n",
      "2025-04-07 15:19:27,729 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.119s]\n",
      "2025-04-07 15:19:27,976 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.175s]\n",
      "2025-04-07 15:19:28,212 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.182s]\n",
      "2025-04-07 15:19:28,427 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.163s]\n",
      "2025-04-07 15:19:28,625 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.142s]\n",
      "2025-04-07 15:19:28,831 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.148s]\n",
      "2025-04-07 15:19:29,072 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.189s]\n",
      "2025-04-07 15:19:29,335 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.206s]\n",
      "2025-04-07 15:19:29,604 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 15:19:29,784 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.116s]\n",
      "2025-04-07 15:19:30,035 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.177s]\n",
      "2025-04-07 15:19:30,338 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.228s]\n",
      "2025-04-07 15:19:30,500 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.115s]\n",
      "2025-04-07 15:19:30,779 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.224s]\n",
      "2025-04-07 15:19:31,054 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.202s]\n",
      "2025-04-07 15:19:31,261 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.156s]\n",
      "2025-04-07 15:19:31,497 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.181s]\n",
      "2025-04-07 15:19:31,715 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.163s]\n",
      "2025-04-07 15:19:32,009 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.235s]\n",
      "2025-04-07 15:19:32,270 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.208s]\n",
      "2025-04-07 15:19:32,674 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.349s]\n",
      "2025-04-07 15:19:32,888 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.157s]\n",
      "2025-04-07 15:19:33,132 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.185s]\n",
      "2025-04-07 15:19:33,352 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.169s]\n",
      "2025-04-07 15:19:33,624 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 15:19:33,927 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.248s]\n",
      "2025-04-07 15:19:34,198 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 15:19:34,418 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.168s]\n",
      "2025-04-07 15:19:34,713 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.214s]\n",
      "2025-04-07 15:19:34,959 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.188s]\n",
      "2025-04-07 15:19:35,220 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.206s]\n",
      "2025-04-07 15:19:35,687 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.411s]\n",
      "2025-04-07 15:19:35,918 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.177s]\n",
      "2025-04-07 15:19:36,159 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.186s]\n",
      "2025-04-07 15:19:36,400 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.183s]\n",
      "2025-04-07 15:19:36,599 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.144s]\n",
      "2025-04-07 15:19:36,829 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.165s]\n",
      "2025-04-07 15:19:37,059 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.179s]\n",
      "2025-04-07 15:19:37,290 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.173s]\n",
      "2025-04-07 15:19:37,502 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.162s]\n",
      "2025-04-07 15:19:37,765 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.207s]\n",
      "2025-04-07 15:19:38,087 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 15:19:38,321 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.173s]\n",
      "2025-04-07 15:19:38,522 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.148s]\n",
      "2025-04-07 15:19:38,783 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.198s]\n",
      "2025-04-07 15:19:39,068 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.223s]\n",
      "2025-04-07 15:19:39,292 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.174s]\n",
      "2025-04-07 15:19:39,520 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.174s]\n",
      "2025-04-07 15:19:39,827 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.244s]\n",
      "2025-04-07 15:19:40,089 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.191s]\n",
      "2025-04-07 15:19:40,323 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.176s]\n",
      "2025-04-07 15:19:40,606 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.238s]\n",
      "2025-04-07 15:19:40,868 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.199s]\n",
      "2025-04-07 15:19:41,093 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.171s]\n",
      "2025-04-07 15:19:41,306 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.155s]\n",
      "2025-04-07 15:19:41,528 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.166s]\n",
      "2025-04-07 15:19:41,776 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.194s]\n",
      "2025-04-07 15:19:41,863 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.062s]\n",
      "2025-04-07 15:19:41,866 - INFO - Elasticsearch 벌크 인덱싱 시도 완료: 116218 문서 성공.\n",
      "2025-04-07 15:19:58,166 - INFO - POST http://localhost:9200/book_bm25_index_v2/_refresh [status:200 duration:16.299s]\n",
      "2025-04-07 15:19:58,167 - INFO - Elasticsearch 인덱스 'book_bm25_index_v2' 새로고침 완료.\n"
     ]
    }
   ],
   "source": [
    "# Elasticsearch store 설정\n",
    "try:\n",
    "    logger.info(f\"Elasticsearch 연결 시도 중: {es_url}...\")\n",
    "    es_client = Elasticsearch(\n",
    "        hosts=[es_url],\n",
    "        request_timeout=120,\n",
    "    )\n",
    "\n",
    "    if not es_client.ping():\n",
    "        raise ConnectionError(\"Elasticsearch 연결 실패. 서버 상태 및 URL 확인 필요.\")\n",
    "    logger.info(\"Elasticsearch 연결 성공\")\n",
    "\n",
    "    if es_client.indices.exists(index=es_index_name):\n",
    "        logger.warning(f\"기존 Elasticsearch 인덱스 '{es_index_name}' 삭제 중...\")\n",
    "        es_client.indices.delete(index=es_index_name, ignore=[400, 404])\n",
    "        logger.info(f\"기존 Elasticsearch 인덱스 '{es_index_name}' 삭제 완료.\")\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Elasticsearch 인덱스 '{es_index_name}' 존재하지 않음. 새로 생성됩니다.\"\n",
    "        )\n",
    "\n",
    "    # ElasticsearchStore 초기화 (BM25)\n",
    "    es_store = ElasticsearchStore(\n",
    "        index_name=es_index_name,\n",
    "        es_connection=es_client,\n",
    "        strategy=ElasticsearchStore.ExactRetrievalStrategy(),  # <-- 추가: BM25 검색 명시!!!\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Langchain ElasticsearchStore 인스턴스 초기화 완료 (인덱스: '{es_index_name}', BM25 검색 전용 - ExactRetrievalStrategy).\"\n",
    "    )\n",
    "\n",
    "    # Elasticsearch 인덱싱 (Bulk API 사용)\n",
    "    logger.info(f\"Elasticsearch에 문서 인덱싱 시작 (총 {len(texts)}개)...\")\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": es_index_name,\n",
    "            \"_source\": {\"text\": texts[i], \"metadata\": metadatas[i]},\n",
    "        }\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    "    indexed_count, errors = helpers.bulk(es_client, actions, raise_on_error=False)\n",
    "    logger.info(f\"Elasticsearch 벌크 인덱싱 시도 완료: {indexed_count} 문서 성공.\")\n",
    "    if errors:\n",
    "        logger.error(\n",
    "            f\"Elasticsearch 벌크 인덱싱 중 오류 발생: {len(errors)}개 문서 실패.\"\n",
    "        )\n",
    "        for i, error in enumerate(errors[:5]):\n",
    "            logger.error(f\"  실패 {i+1}: {error}\")\n",
    "\n",
    "    es_client.indices.refresh(index=es_index_name)\n",
    "    logger.info(f\"Elasticsearch 인덱스 '{es_index_name}' 새로고침 완료.\")\n",
    "\n",
    "except ConnectionError as ce:\n",
    "    logger.error(f\"Elasticsearch 연결 실패: {ce}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(\n",
    "        f\"Elasticsearch 설정 또는 데이터 추가 중 오류 발생: {e}\", exc_info=True\n",
    "    )\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Retriever 및 QA 체인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 15:21:14,998 - INFO - Dense retriever (Milvus 벡터 검색) 설정 완료 (k=5).\n",
      "2025-04-07 15:21:15,242 - INFO - HEAD http://localhost:9200/ [status:200 duration:0.238s]\n",
      "2025-04-07 15:21:15,365 - INFO - Sparse retriever (Elasticsearch BM25) 설정 완료 (ElasticsearchRetriever 직접 사용, metadata_field 지정).\n",
      "2025-04-07 15:21:15,391 - INFO - Hybrid ensemble retriever 설정 완료 (Direct ES BM25: 0.5, Milvus Vector: 0.5).\n",
      "2025-04-07 15:21:15,400 - INFO - ISBN Merging Retriever 설정 완료 (Hybrid 결과 기반).\n",
      "2025-04-07 15:21:15,592 - INFO - RetrievalQA 체인 설정 완료 (Merged Hybrid Retriever 사용).\n"
     ]
    }
   ],
   "source": [
    "# 1. Dense Retriever (Milvus)\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "logger.info(\"Dense retriever (Milvus 벡터 검색) 설정 완료 (k=5).\")\n",
    "\n",
    "# 2. Sparse Retriever (Elasticsearch - BM25)\n",
    "try:\n",
    "    if \"es_client\" not in locals() or not es_client.ping():\n",
    "        raise ConnectionError(\n",
    "            \"Elasticsearch client가 준비되지 않았거나 연결할 수 없습니다.\"\n",
    "        )\n",
    "\n",
    "    sparse_retriever = ElasticsearchRetriever(\n",
    "        es_client=es_client,\n",
    "        index_name=es_index_name,\n",
    "        body_func=lambda query: {\n",
    "            \"size\": 5,\n",
    "            \"query\": {\"match\": {\"text\": {\"query\": query}}},\n",
    "        },  # ES에서 가져올 문서 수를 제한 (Ensemble이 최종 개수 조절)\n",
    "        content_field=\"text\",  # ES 문서의 text 필드를 Document.page_content로 사용\n",
    "        metadata_field=\"metadata\",\n",
    "    )\n",
    "    # 로그 메시지 업데이트\n",
    "    logger.info(\n",
    "        \"Sparse retriever (Elasticsearch BM25) 설정 완료 (ElasticsearchRetriever 직접 사용, metadata_field 지정).\"\n",
    "    )\n",
    "\n",
    "except ConnectionError as ce:\n",
    "    logger.error(f\"Elasticsearch 클라이언트 오류: {ce}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"ElasticsearchRetriever 직접 설정 중 오류 발생: {e}\", exc_info=True)\n",
    "    raise\n",
    "\n",
    "# 3. Hybrid Retriever - Ensemble (Dense + Sparse)\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[sparse_retriever, dense_retriever], weights=[0.5, 0.5], c=60\n",
    ")\n",
    "logger.info(\n",
    "    \"Hybrid ensemble retriever 설정 완료 (Direct ES BM25: 0.5, Milvus Vector: 0.5).\"\n",
    ")\n",
    "\n",
    "# 4. Final Retriever with ISBN Merging\n",
    "merged_hybrid_retriever = ISBNMergingRetriever(base_retriever=hybrid_retriever)\n",
    "logger.info(\"ISBN Merging Retriever 설정 완료 (Hybrid 결과 기반).\")\n",
    "\n",
    "# 5. RetrievalQA Chain 설정 (최종 리트리버 사용)\n",
    "dpr_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_clova,\n",
    "    retriever=merged_hybrid_retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "logger.info(\"RetrievalQA 체인 설정 완료 (Merged Hybrid Retriever 사용).\")\n",
    "\n",
    "MIN_INFO_LENGTH = 10  # 요약 생성을 위한 최소 텍스트 길이\n",
    "previous_additional_question_embeddings = (\n",
    "    []\n",
    ")  # 이전 추가 질문 임베딩 저장 리스트 (유사 질문 반복 방지 &~)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 사용자 선호도 추출 프롬프트\n",
    "extract_pref_prompt_v2 = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "다음 사용자 발화에서 사용자의 선호도 및 책에 대한 요구사항을 아래 JSON 형식으로 추출해라. 각 항목은 관련된 정보가 명확할때만 명확한 항목에 포함(소설 -> category)하고, 없다면 빈 리스트 `[]` 또는 빈 문자열 `\"\"`로 남겨라. 여러개가 추출될 수 있는 항목은 리스트로 추출하라.\n",
    "사용자 입력에서 모호한 정보는 implicit info로 포함해라.\n",
    "존재하지 않는 사용자 선호도 정보는 임의로 생성하지 마라.\n",
    "\n",
    "입력: {{ text }}\n",
    "\n",
    "출력 형식 (JSON, 다른 설명 없이 JSON만 출력):\n",
    "{\n",
    "    \"title\": [<!-- 추출된 책 제목 -->],\n",
    "    \"author\": [<!-- 추출된 책 저자 -->],\n",
    "    \"category\": [<!-- 추출된 책 분류/장르(소설/에세이/기술) -->],\n",
    "    \"author_intro\": [<!-- 저자 특성 언급/요구사항 -->],\n",
    "    \"book_intro\": [<!-- 줄거리 관련 언급/요구사항 -->],\n",
    "    \"table_of_contents\": [<!-- 세부적인 키워드 언급/요구사항 -->],\n",
    "    \"purpose\": [<!-- 사용자의 독서 목적/이유 목록 (예: '재미', '학습', '시간 때우기', '기분') -->],\n",
    "    \"implicit info\": [<!-- 추천해야 할 책에 대한 암시적 정보/특징/분위기 목록 (예: '밝은 분위기', '특정 상황에 어울리는 책', '최신 기술 동향') -->]\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",  # 변수 치환을 위한 탬플릿\n",
    ")\n",
    "\n",
    "# 2. 선호도 통합 프롬프트\n",
    "consolidate_pref_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_preferences\", \"new_preferences\"],\n",
    "    template=\"\"\"\n",
    "기존에 수집된 사용자 선호도 정보와 새로 추출된 선호도 정보가 주어졌다. 두 정보를 지능적으로 통합하여 중복을 제거하고 관련 내용을 요약/결합하여 최종 선호도 목록을 생성해라.\n",
    "\n",
    "[기존 선호도]\n",
    "{{ existing_preferences }}\n",
    "\n",
    "[새로운 선호도]\n",
    "{{ new_preferences }}\n",
    "\n",
    "[통합된 최종 선호도 목록]\n",
    "(아래 목록 형태로만 출력, 각 항목은 문자열 리스트)\n",
    "- 항목1: [\"통합 내용1\", \"통합 내용2\"]\n",
    "- 항목2: [\"통합 내용3\"]\n",
    "...\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 3. Decision Prompt\n",
    "decision_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "수집된 사용자 선호도:\n",
    "{{ preferences }}\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "현재 대화 상황, 질문, 수집된 선호도를 분석하여 아래 두 가지 행동 중 하나만 결정하고 필요한 정보를 생성하라.\n",
    "- \"추천\": 사용자가 명시적으로 추천을 요청했거나, 사용자의 선호도 정보(카테고리, 저자, 목적, 책 줄거리, 사용자 수준, 분위기 등)를 반드시 3개 이상 수집했을 때만 추천에 들어가라.\n",
    "- \"추가 질문\": 추천하기에 정보가 부족하거나 모호할 때, **아직 수집되지 않았거나 더욱 구체적인 선호도 정보**를 얻기 위한 질문 생성. (예: 어떤 장르를 선호하시나요? 특정 작가를 찾으시나요? 책을 읽는 목적이 무엇인가요?)\n",
    "\n",
    "[출력 형식] (반드시 아래 형식만 정확히 따를 것)\n",
    "행동: <추천 또는 추가 질문>\n",
    "추가 질문: <\"추가 질문\" 행동일 경우 구체적인 질문 생성, \"추천\" 행동일 경우 빈 문자열>\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"preferences\", \"role_instructions\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 4. Final Query Generation Prompt\n",
    "final_query_generation_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "\n",
    "[페르소나 정보]\n",
    "{{ persona_info }}\n",
    "\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "위 정보를 전부 활용하여, 도서 검색에 가장 유용한 **핵심 키워드 중심의 최종 검색 쿼리**를 한 문장으로 작성하라.\n",
    "오직 검색 쿼리 문장만 출력하라.\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 5. Refine Prompt - 추후 더 업데이트를 통해 정제 기능 활성화\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"주어진 검색 쿼리를 분석하여, 검색 엔진이나 다음 단계에서 사용하기 좋은 명확하고 간결한 단일 문장으로 정제해라. 불필요한 설명 없이 오직 정제된 쿼리 문장만 출력해라.\n",
    "\n",
    "- \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 라고 사용자가 언급하면, 해당 책/저자의 **특징(예: 장르, 분위기, 핵심 소재, 작가 스타일)**을 반영하여 확장하라. 책 제목이나 저자 이름은 절대 직접 포함하지 마라.\n",
    "- 예시 (입력: 해리포터 시리즈물같은 판타지 소설 알려줘) ->\n",
    "1. 마법학교 배경의 청소년 판타지 소설 추천\n",
    "2. 선과 악의 대결을 다룬 영국 판타지 시리즈\n",
    "3. 성장 서사를 담은 인기 판타지 소설\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 6. Query Expansion Prompt\n",
    "query_expansion_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"주어진 원본 검색 쿼리를 바탕으로, 관련성이 높으면서도 다양한 측면을 탐색할 수 있는 확장된 검색 쿼리 3개를 생성해라. 확장된 쿼리는 원본 쿼리의 핵심 의도를 반드시 유지해야 한다. 다른 설명이나 서론 없이, 오직 번호(1., 2., 3.)가 매겨진 확장 쿼리 목록만 한 줄에 하나씩 출력해라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 7. Re_ranking Prompt\n",
    "re_ranking_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"documents\"],\n",
    "    template=\"\"\"사용자의 검색 쿼리는 다음과 같습니다: \"{{ query }}\"\n",
    "다음은 검색된 도서 목록입니다 (내용은 일부만 표시됨):\n",
    "{% for doc in documents %}\n",
    "{{ loop.index }}. 제목: {{ doc.metadata.get('title', '제목 없음') }}, 저자: {{ doc.metadata.get('author', '저자 없음') }}, 내용 일부: {{ doc.page_content | truncate(200) }}\n",
    "{% endfor %}\n",
    "\n",
    "위 검색 결과를 사용자의 검색 쿼리 \"{{ query }}\"와의 관련성, 그리고 문서 내용의 충실도를 종합적으로 고려하여 가장 적합한 순서대로 재배치하라.\n",
    "가장 관련성이 높은 도서를 목록의 맨 위에 배치하고, 순위가 매겨진 **도서 제목과 저자**만으로 결과를 다음 형식으로 출력하라.\n",
    "\n",
    "[출력 형식 예시]\n",
    "1. 제목: <가장 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "2. 제목: <두 번째 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "...\n",
    "\n",
    "[리랭킹된 도서 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 8. HyDE Generation Prompt\n",
    "hyde_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"다음 검색 쿼리에 완벽하게 부합하는 **이상적인 가상의 책**을 추천하고 이를 기반으로 **간결한 요약(2-3 문장)**을 생성해라. 이 요약은 해당 쿼리로 책을 찾는 사용자가 가장 만족할 만한 내용을 담고 있어야 한다. 오직 생성된 요약 텍스트만 출력하라.\n",
    "\n",
    "[검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[가상의 책 요약]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 9. Persona prompt\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 깊이 이해하고 공감하는 말투로 문학적인 표현을 사용하여 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 지식 수준과 관심 분야를 파악하고, 최신 정보와 기술 동향을 반영하여 체계적으로 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다. 친근한 말투로 다양한 분야의 책에 대해 균형 잡힌 시각으로 정보를 제공하고, 사용자의 요구사항에 맞춰 명확하고 이해하기 쉽게 책을 추천해라.\"\n",
    "\n",
    "\n",
    "# 10. hyde_keyword_prompt\n",
    "hyde_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"hyde_summary\"],\n",
    "    template=\"\"\"다음은 사용자의 질문에 이상적으로 부합하는 가상의 책 요약입니다:\n",
    "\"{{ hyde_summary }}\"\n",
    "\n",
    "이 요약 내용에서 **핵심 키워드 5개**를 추출하여 쉼표(,)로 구분하여 나열해라. 오직 키워드 목록만 출력하라.\n",
    "\n",
    "[핵심 키워드 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Async Invoke function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_invoke(chain: LLMChain, vars_dict: dict, step_name: str) -> dict:\n",
    "    \"\"\"LLMChain을 비동기로 실행하고 로깅\"\"\"\n",
    "    try:\n",
    "        # 입력 변수 일부 로깅\n",
    "        log_vars = {\n",
    "            k: (v[:100] + \"...\" if isinstance(v, str) and len(v) > 100 else v)\n",
    "            for k, v in vars_dict.items()\n",
    "        }\n",
    "        logger.debug(f\"[{step_name}] Chain 호출 시작. 입력 변수 일부: {log_vars}\")\n",
    "        # chain.invoke를 별도 스레드에서 실행하여 비동기 처리\n",
    "        result = await asyncio.to_thread(chain.invoke, vars_dict)\n",
    "        result_text = result.get(\"text\", \"\")\n",
    "        # 결과 텍스트 일부 로깅\n",
    "        log_result = (\n",
    "            result_text[:200] + \"...\" if len(result_text) > 200 else result_text\n",
    "        )\n",
    "        logger.debug(f\"[{step_name}] Chain 호출 완료. 결과 일부: {log_result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step_name}] Chain 호출 중 예외 발생: {e}\", exc_info=True)\n",
    "        return {\"text\": \"\"}  # 오류 시 빈 결과 반환\n",
    "\n",
    "\n",
    "async def async_invoke_llm(prompt: str, step_name: str) -> str:\n",
    "    \"\"\"LLM 직접 호출을 비동기로 실행하고 로깅\"\"\"\n",
    "    try:\n",
    "        # 프롬프트 일부 로깅\n",
    "        log_prompt = prompt[:200] + \"...\" if len(prompt) > 200 else prompt\n",
    "        logger.debug(f\"[{step_name}] LLM 호출 시작. 프롬프트 일부: {log_prompt}\")\n",
    "        # llm.invoke를 별도 스레드에서 실행\n",
    "        response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
    "\n",
    "        # 응답 객체에서 텍스트 추출\n",
    "        if hasattr(response, \"content\"):\n",
    "            result_text = response.content.strip()\n",
    "        elif isinstance(response, str):  # ChatClovaX가 문자열 직접 반환하는 경우\n",
    "            result_text = response.strip()\n",
    "        else:\n",
    "            result_text = str(response).strip()\n",
    "\n",
    "        # 응답 텍스트 일부 로깅\n",
    "        log_result = (\n",
    "            result_text[:200] + \"...\" if len(result_text) > 200 else result_text\n",
    "        )\n",
    "        logger.debug(f\"[{step_name}] LLM 호출 완료. 응답 일부: {log_result}\")\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step_name}] LLM 호출 중 예외 발생: {e}\", exc_info=True)\n",
    "        return \"\"  # 오류 시 빈 문자열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_metadata_field(doc: Document, field: str, default: str = \"N/A\") -> str:\n",
    "    \"\"\"\n",
    "    Document의 다양한 metadata 구조에서 필드 값을 추출 (예: title, ISBN 등).\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Case 1: 평평한 구조\n",
    "    candidates.append(doc.metadata)\n",
    "\n",
    "    # Case 2: 1단계 중첩\n",
    "    if \"metadata\" in doc.metadata and isinstance(doc.metadata[\"metadata\"], dict):\n",
    "        candidates.append(doc.metadata[\"metadata\"])\n",
    "\n",
    "        # Case 3: 2단계 중첩\n",
    "        inner = doc.metadata[\"metadata\"]\n",
    "        if \"metadata\" in inner and isinstance(inner[\"metadata\"], dict):\n",
    "            candidates.append(inner[\"metadata\"])\n",
    "\n",
    "    # Case 4: Elasticsearch 구조 (_source.metadata)\n",
    "    if \"_source\" in doc.metadata and isinstance(doc.metadata[\"_source\"], dict):\n",
    "        source_meta = doc.metadata[\"_source\"].get(\"metadata\", {})\n",
    "        if isinstance(source_meta, dict):\n",
    "            candidates.append(source_meta)\n",
    "\n",
    "    # 실제 값 추출\n",
    "    for meta in candidates:\n",
    "        if field in meta:\n",
    "            return (\n",
    "                meta[field].strip()\n",
    "                if isinstance(meta[field], str)\n",
    "                else str(meta[field])\n",
    "            )\n",
    "\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- RAG 파이프라인 기본 클래스 ---\n",
    "class BaseRAGPipeline:\n",
    "    def __init__(\n",
    "        self, config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "    ):\n",
    "        self.config = config  # 페르소나 등 설정 정보\n",
    "        self.llm = llm  # 답변 생성 LLM\n",
    "        self.embeddings = embeddings  # 임베딩 모델\n",
    "        self.vectorstore = vectorstore  # Milvus 벡터 저장소\n",
    "        self.es_store = es_store  # Elasticsearch 저장소\n",
    "        self.retriever = retriever  # 최종 리트리버 (ISBN 병합 포함)\n",
    "        # self.qa_chain = qa_chain # RetrievalQA 체인 (직접 사용 대신 내부 로직 구현)\n",
    "        self.documents = documents  # 전체 원본 문서 목록 (ISBN 병합 시 사용)\n",
    "\n",
    "        # 대화 상태 관리\n",
    "        self.user_history: List[str] = []  # 사용자 발화 기록\n",
    "        self.llm_history: List[str] = []  # 챗봇 응답 기록\n",
    "        self.user_preferences: Dict[str, List[str]] = (\n",
    "            self._initialize_preferences()\n",
    "        )  # 사용자 선호도\n",
    "        self.preferences_text: str = \"수집된 선호도 없음\"  # 사용자 선호도 요약 텍스트\n",
    "        self.preference_update_count: int = 0  # 선호도 업데이트 횟수\n",
    "        self.last_recommendations: List[Document] = []  # 마지막 추천 결과 (병합된 문서)\n",
    "        self.last_action: Optional[str] = None  # 마지막 챗봇 행동 (추천 or 추가 질문)\n",
    "\n",
    "        # LLM 체인 초기화\n",
    "        self.extract_pref_chain = LLMChain(llm=self.llm, prompt=extract_pref_prompt_v2)\n",
    "        self.decision_chain = LLMChain(llm=self.llm, prompt=decision_prompt_template)\n",
    "        self.final_query_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=final_query_generation_template\n",
    "        )\n",
    "        self.refine_chain = LLMChain(llm=self.llm, prompt=refine_prompt)\n",
    "        self.query_expansion_chain = LLMChain(\n",
    "            llm=self.llm, prompt=query_expansion_prompt\n",
    "        )\n",
    "        self.re_ranking_chain = LLMChain(llm=self.llm, prompt=re_ranking_prompt)\n",
    "        self.hyde_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=hyde_generation_prompt\n",
    "        )\n",
    "        self.hyde_keyword_chain = LLMChain(llm=self.llm, prompt=hyde_keyword_prompt)\n",
    "\n",
    "    def _initialize_preferences(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"선호도 딕셔너리 초기화\"\"\"\n",
    "        return {\n",
    "            \"title\": [],\n",
    "            \"author\": [],\n",
    "            \"category\": [],\n",
    "            \"author_intro\": [],\n",
    "            \"book_intro\": [],\n",
    "            \"table_of_contents\": [],\n",
    "            \"purpose\": [],\n",
    "            \"implicit info\": [],\n",
    "        }\n",
    "\n",
    "    def robust_parse_decision_response(\n",
    "        self, response_text: str\n",
    "    ) -> tuple[Optional[str], str]:\n",
    "        \"\"\"LLM의 행동 결정 응답을 파싱 (형식 오류에 강건하게)\"\"\"\n",
    "        action = None\n",
    "        additional_question = \"\"\n",
    "\n",
    "        # \"행동:\" 패턴 찾기\n",
    "        action_match = re.search(r'행동\\s*[:：]\\s*\"?([^\"\\n]+)\"?', response_text)\n",
    "        if action_match:\n",
    "            action = action_match.group(1).strip().lower()\n",
    "            # \"추천\" 또는 \"추가 질문\" 외의 값은 None 처리 (혹은 기본값 설정)\n",
    "            if action not in [\"추천\", \"추가 질문\"]:\n",
    "                logger.warning(\n",
    "                    f\"알 수 없는 행동 값 파싱됨: '{action}'. '추가 질문'으로 처리.\"\n",
    "                )\n",
    "                action = \"추가 질문\"\n",
    "\n",
    "        # \"추가 질문:\" 패턴 찾기\n",
    "        follow_match = re.search(\n",
    "            r'추가\\s*질문\\s*[:：]\\s*\"?(.+)\"?', response_text, re.DOTALL\n",
    "        )\n",
    "        if follow_match:\n",
    "            additional_question = follow_match.group(1).strip()\n",
    "\n",
    "        # 행동은 찾았는데 추가 질문 내용이 없는 경우 기본 메시지 설정\n",
    "        if action == \"추가 질문\" and not additional_question:\n",
    "            additional_question = \"어떤 점이 궁금하신가요? 또는 어떤 책을 찾으시나요?\"\n",
    "            logger.warning(\n",
    "                f\"행동은 '추가 질문'이나 질문 내용 없음. 기본 질문 사용: '{additional_question}'\"\n",
    "            )\n",
    "\n",
    "        # 행동 자체를 못 찾은 경우 기본값 '추가 질문' 설정\n",
    "        if not action:\n",
    "            logger.warning(\n",
    "                f\"행동 결정 파싱 실패: '{response_text}'. 기본 '추가 질문'으로 처리.\"\n",
    "            )\n",
    "            action = \"추가 질문\"\n",
    "            if not additional_question:  # 추가 질문 내용도 없으면 기본 메시지\n",
    "                additional_question = \"요청을 이해하기 어려웠습니다. 어떤 책을 찾으시는지 다시 말씀해주시겠어요?\"\n",
    "\n",
    "        logger.info(\n",
    "            f\"행동 결정 파싱 결과: 행동='{action}', 추가 질문='{additional_question[:50]}...'\"\n",
    "        )\n",
    "        return action, additional_question\n",
    "\n",
    "    async def update_preferences_from_input(self, user_input: str) -> None:\n",
    "        \"\"\"사용자 입력에서 선호도를 추출하고 내부 상태 업데이트\"\"\"\n",
    "        logger.info(f\"사용자 입력에서 선호도 추출 시작: '{user_input[:100]}...'\")\n",
    "        # 선호도 추출 LLMChain 호출\n",
    "        extract_result = await async_invoke(\n",
    "            self.extract_pref_chain, {\"text\": user_input}, \"선호도 추출\"\n",
    "        )\n",
    "        extracted_text = extract_result.get(\"text\", \"{}\")\n",
    "\n",
    "        extracted_prefs: Dict[str, List[str]] = {}\n",
    "        try:\n",
    "            # LLM 응답에서 JSON 부분만 찾기 (설명 등 제외)\n",
    "            json_match = re.search(r\"\\{.*\\}\", extracted_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                # 찾은 JSON 문자열 파싱\n",
    "                extracted_prefs_raw = json.loads(json_match.group(0))\n",
    "                # 정의된 키만 사용하고 값 형식(리스트) 통일\n",
    "                defined_keys = self.user_preferences.keys()\n",
    "                for key, value in extracted_prefs_raw.items():\n",
    "                    if key in defined_keys:\n",
    "                        vals_to_add = []\n",
    "                        if isinstance(\n",
    "                            value, list\n",
    "                        ):  # 값이 리스트면, 빈 값 제외하고 문자열로 변환\n",
    "                            vals_to_add = [\n",
    "                                str(item).strip()\n",
    "                                for item in value\n",
    "                                if item and str(item).strip()\n",
    "                            ]\n",
    "                        elif (\n",
    "                            isinstance(value, str) and value.strip()\n",
    "                        ):  # 값이 문자열이면, 공백 아니면 리스트에 추가\n",
    "                            vals_to_add = [value.strip()]\n",
    "                        # 유효한 값이 있을 때만 extracted_prefs에 추가\n",
    "                        if vals_to_add:\n",
    "                            extracted_prefs[key] = vals_to_add\n",
    "                    else:\n",
    "                        logger.warning(\n",
    "                            f\"추출된 선호도 키 '{key}'가 정의된 형식에 없음. 무시.\"\n",
    "                        )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"선호도 추출 결과에서 JSON 객체를 찾을 수 없음: {extracted_text}\"\n",
    "                )\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(\n",
    "                f\"선호도 추출 결과 JSON 파싱 실패: {e}. 원본 텍스트: {extracted_text}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"선호도 추출/처리 중 예외 발생: {e}\", exc_info=True)\n",
    "\n",
    "        if not extracted_prefs:\n",
    "            logger.info(\"새로 추출된 유효한 선호도 정보가 없음\")\n",
    "            return  # 업데이트할 내용 없으면 종료\n",
    "\n",
    "        # 기존 선호도와 비교하여 변경 사항 적용\n",
    "        updated_something = False\n",
    "        for key, new_values in extracted_prefs.items():\n",
    "            # 기존 값 집합 생성 (중복 제거 및 빠른 조회)\n",
    "            existing_values_set = set(self.user_preferences.get(key, []))\n",
    "            # 새로 추가될 값 필터링 (기존에 없는 값만)\n",
    "            added_values = [v for v in new_values if v not in existing_values_set]\n",
    "\n",
    "            if added_values:  # 새로 추가된 값이 있으면\n",
    "                self.user_preferences[key].extend(added_values)  # 기존 리스트에 추가\n",
    "                updated_something = True\n",
    "                logger.info(f\"선호도 업데이트됨 [{key}]: {self.user_preferences[key]}\")\n",
    "\n",
    "        if updated_something:\n",
    "            self.preference_update_count += 1\n",
    "            logger.info(\n",
    "                f\"선호도 업데이트 완료. 누적 업데이트 횟수: {self.preference_update_count}\"\n",
    "            )\n",
    "            # 선호도 요약 텍스트 업데이트\n",
    "            self._update_preferences_text()\n",
    "        else:\n",
    "            logger.info(\"기존 선호도에서 변경된 내용 없음.\")\n",
    "\n",
    "    def _update_preferences_text(self):\n",
    "        \"\"\"현재 user_preferences를 기반으로 요약 텍스트 업데이트\"\"\"\n",
    "        pref_items = []\n",
    "        # 사용자 친화적 키 이름 매핑\n",
    "        display_key_map = {\n",
    "            \"title\": \"관련 제목\",\n",
    "            \"author\": \"선호 저자\",\n",
    "            \"category\": \"선호 장르/분류\",\n",
    "            \"author_intro\": \"저자 관련 요구\",\n",
    "            \"book_intro\": \"내용 관련 요구\",\n",
    "            \"table_of_contents\": \"목차/키워드 요구\",\n",
    "            \"purpose\": \"독서 목적\",\n",
    "            \"implicit info\": \"기타 희망 사항/분위기\",\n",
    "        }\n",
    "        # 값이 있는 선호도 항목만 문자열로 변환\n",
    "        for key, values in self.user_preferences.items():\n",
    "            if values:\n",
    "                display_key = display_key_map.get(\n",
    "                    key, key\n",
    "                )  # 매핑된 이름 사용, 없으면 원래 키 사용\n",
    "                # 값들을 쉼표로 연결하여 표시\n",
    "                pref_items.append(f\"- {display_key}: {', '.join(values)}\")\n",
    "\n",
    "        # 최종 요약 텍스트 생성\n",
    "        self.preferences_text = (\n",
    "            \"\\n\".join(pref_items) if pref_items else \"수집된 선호도 없음\"\n",
    "        )\n",
    "        logger.debug(f\"업데이트된 선호도 요약 텍스트:\\n{self.preferences_text}\")\n",
    "\n",
    "    async def get_final_query(self, current_user_query: str) -> str:\n",
    "        \"\"\"대화 기록, 선호도 등을 종합하여 최종 검색 쿼리 생성 및 정제\"\"\"\n",
    "        logger.info(\"최종 검색 쿼리 생성 시작\")\n",
    "        persona = self.config.get(\"persona\", \"General\")  # 설정된 페르소나 가져오기\n",
    "        # 페르소나별 중요 정보 예시 (쿼리 생성 프롬프트에 제공)\n",
    "        persona_info_map = {\n",
    "            \"Literature\": \"감성, 현재 기분, 선호하는 문학 장르 및 작가 스타일\",\n",
    "            \"Science\": \"독자의 지식 수준(초심자/전문가), 관심 기술 분야, 문제 해결 목표\",\n",
    "            \"General\": \"선호 장르, 책을 찾는 이유, 원하는 분위기나 난이도\",\n",
    "        }\n",
    "        persona_info = persona_info_map.get(persona, persona_info_map[\"General\"])\n",
    "\n",
    "        # 최종 쿼리 생성 LLMChain 호출\n",
    "        final_query_vars = {\n",
    "            \"history\": \"\\n\".join(\n",
    "                self.user_history[-5:] + self.llm_history[-5:]\n",
    "            ),  # 최근 대화 5턴\n",
    "            \"query\": current_user_query,\n",
    "            \"persona_info\": persona_info,\n",
    "            \"preferences\": self.preferences_text,  # 업데이트된 선호도 요약\n",
    "        }\n",
    "        result_gen = await async_invoke(\n",
    "            self.final_query_generation_chain, final_query_vars, \"선호도 종합 쿼리 생성\"\n",
    "        )\n",
    "        generated_query = result_gen.get(\"text\", \"\").strip()\n",
    "        logger.info(f\"LLM 생성 쿼리 (정제 전): '{generated_query}'\")\n",
    "\n",
    "        query_to_use = generated_query  # 기본값은 생성된 쿼리\n",
    "\n",
    "        # 생성된 쿼리가 있으면 정제 시도\n",
    "        if generated_query:\n",
    "            refine_result = await async_invoke(\n",
    "                self.refine_chain, {\"query\": generated_query}, \"쿼리 정제\"\n",
    "            )\n",
    "            refined_query = (\n",
    "                refine_result.get(\"text\", \"\").strip().strip('\"')\n",
    "            )  # 양쪽 따옴표 제거\n",
    "            logger.info(f\"정제된 쿼리: '{refined_query}'\")\n",
    "\n",
    "            # 정제된 쿼리가 유효한지 검사 (너무 짧거나, 특정 부정 키워드 포함 등)\n",
    "            negative_keywords = [\n",
    "                \"없\",\n",
    "                \"못\",\n",
    "                \"않\",\n",
    "                \"오류\",\n",
    "                \"잘못\",\n",
    "                \"알 수 없\",\n",
    "                \"죄송\",\n",
    "                \"필요\",\n",
    "            ]\n",
    "            is_invalid_refinement = (\n",
    "                not refined_query\n",
    "                or len(refined_query) < 3  # 너무 짧음\n",
    "                or any(\n",
    "                    keyword in refined_query for keyword in negative_keywords\n",
    "                )  # 부정 키워드\n",
    "                or \"{\" in refined_query\n",
    "                or \"}\" in refined_query  # JSON 형식 오류\n",
    "                or refined_query.lower()\n",
    "                == generated_query.lower()  # 정제 결과가 원본과 같음 (LLM이 정제 실패 시)\n",
    "            )\n",
    "\n",
    "            if is_invalid_refinement:\n",
    "                logger.warning(\n",
    "                    f\"정제된 쿼리('{refined_query}')가 유효하지 않아 정제 전 쿼리('{generated_query}') 사용.\"\n",
    "                )\n",
    "                # query_to_use는 이미 generated_query 이므로 변경 필요 없음\n",
    "            else:\n",
    "                query_to_use = refined_query  # 유효하면 정제된 쿼리 사용\n",
    "        else:\n",
    "            # 쿼리 생성이 아예 실패한 경우 원본 사용자 쿼리 사용\n",
    "            logger.warning(\"선호도 종합 쿼리 생성 실패. 원본 사용자 쿼리를 사용.\")\n",
    "            query_to_use = current_user_query\n",
    "\n",
    "        # 최종 결정된 쿼리가 너무 짧으면 원본 사용자 쿼리 사용\n",
    "        if not query_to_use or len(query_to_use) < 3:\n",
    "            logger.warning(\n",
    "                f\"최종 결정된 쿼리('{query_to_use}')가 너무 짧거나 비어있어 원본 사용자 쿼리('{current_user_query}') 사용.\"\n",
    "            )\n",
    "            query_to_use = current_user_query\n",
    "\n",
    "        logger.info(f\"최종 결정된 검색 쿼리: '{query_to_use}'\")\n",
    "        return query_to_use\n",
    "\n",
    "    async def _summarize_chunk_with_llm(self, text: str) -> str:\n",
    "        \"\"\"주어진 텍스트(주로 책 소개 등)를 LLM을 이용해 짧게 요약\"\"\"\n",
    "        # 텍스트 길이 검사\n",
    "        if not text or len(text.strip()) < MIN_INFO_LENGTH:\n",
    "            return \"요약할 정보가 충분하지 않습니다.\"\n",
    "\n",
    "        # LLM 입력 길이 제한 고려 (예: 4000자)\n",
    "        max_len = 4000\n",
    "        truncated_text = text[:max_len].strip()\n",
    "        if not truncated_text:\n",
    "            return \"요약할 정보가 없습니다.\"  # 공백만 있는 경우\n",
    "\n",
    "        # 요약 프롬프트\n",
    "        prompt = f\"다음 책 정보를 2~3 문장으로 핵심 내용만 명확하게 요약해줘:\\n\\n{truncated_text}\\n\\n요약:\"\n",
    "        summary = await async_invoke_llm(prompt, \"청크 요약\")\n",
    "\n",
    "        # LLM 요약 결과 검증 (너무 짧거나, 실패 메시지 포함 등)\n",
    "        if (\n",
    "            not summary\n",
    "            or len(summary) < 10\n",
    "            or \"요약할 정보가\" in summary\n",
    "            or \"죄송\" in summary\n",
    "            or \"모르겠\" in summary\n",
    "        ):\n",
    "            # LLM 요약 실패 시, 원본 텍스트 일부를 fallback으로 사용\n",
    "            fallback_summary = text[:300].strip() + (\"...\" if len(text) > 300 else \"\")\n",
    "            logger.warning(\n",
    "                f\"LLM 요약 실패 또는 부적절. Fallback 요약 사용: '{fallback_summary[:100]}...'\"\n",
    "            )\n",
    "            return (\n",
    "                fallback_summary\n",
    "                if fallback_summary\n",
    "                else \"별도의 상세 정보가 충분치 않습니다.\"\n",
    "            )\n",
    "\n",
    "        return summary\n",
    "\n",
    "    def _merge_documents_by_isbn(self, isbn: str) -> Optional[Document]:\n",
    "        \"\"\"주어진 ISBN에 해당하는 모든 원본 Document를 찾아 병합 (마스터 목록 사용)\"\"\"\n",
    "        if not isbn:\n",
    "            logger.warning(\"ISBN 없이 문서 병합 시도됨.\")\n",
    "            return None\n",
    "\n",
    "        # self.documents (전체 원본 문서 목록)에서 해당 ISBN 찾기\n",
    "        docs_for_isbn = [\n",
    "            doc\n",
    "            for doc in self.documents\n",
    "            if str(doc.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "        ]\n",
    "\n",
    "        if not docs_for_isbn:\n",
    "            logger.warning(\n",
    "                f\"ISBN '{isbn}'에 해당하는 문서를 마스터 목록에서 찾을 수 없음.\"\n",
    "            )\n",
    "            return None  # 해당 ISBN 문서가 없으면 None 반환\n",
    "\n",
    "        # 찾은 문서들의 page_content 병합\n",
    "        combined_text = \"\\n\\n---\\n\\n\".join(\n",
    "            doc.page_content for doc in docs_for_isbn if doc.page_content\n",
    "        ).strip()\n",
    "\n",
    "        if not combined_text:\n",
    "            logger.warning(f\"ISBN '{isbn}' 병합 후 텍스트 내용 없음.\")\n",
    "            # 텍스트 내용이 없어도 메타데이터는 유효할 수 있으므로 일단 반환 (호출부에서 처리)\n",
    "            # 혹은 여기서 None을 반환할 수도 있음\n",
    "\n",
    "        # 메타데이터는 첫 번째 문서의 것을 사용\n",
    "        merged_meta = dict(docs_for_isbn[0].metadata)\n",
    "\n",
    "        logger.debug(\n",
    "            f\"ISBN '{isbn}' 문서 병합 완료 (전체 원본 기준). 병합된 청크 수: {len(docs_for_isbn)}, 총 텍스트 길이: {len(combined_text)}\"\n",
    "        )\n",
    "        return Document(page_content=combined_text, metadata=merged_meta)\n",
    "\n",
    "    async def _embedding_rerank_documents(\n",
    "        self, query: str, documents: List[Document]\n",
    "    ) -> List[Document]:\n",
    "        if not documents:\n",
    "            logger.info(\"리랭킹할 문서가 없습니다.\")\n",
    "            return []\n",
    "\n",
    "        # 쿼리 임베딩 준비\n",
    "        embedding_tasks = {\n",
    "            \"main\": asyncio.to_thread(self.embeddings.embed_query, query)\n",
    "        }\n",
    "\n",
    "        # 사용자 선호 임베딩 생성\n",
    "        if self.user_preferences.get(\"author\"):\n",
    "            embedding_tasks[\"author\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"author\"][0]\n",
    "            )\n",
    "        if self.user_preferences.get(\"title\"):\n",
    "            embedding_tasks[\"title\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"title\"][0]\n",
    "            )\n",
    "        if self.user_preferences.get(\"category\"):\n",
    "            embedding_tasks[\"category\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"category\"][0]\n",
    "            )\n",
    "\n",
    "        query_embeddings = await asyncio.gather(*embedding_tasks.values())\n",
    "        query_embedding_map = dict(zip(embedding_tasks.keys(), query_embeddings))\n",
    "\n",
    "        # 가중치 설정\n",
    "        weights = {\"main\": 0.1, \"author\": 0.3, \"title\": 0.1, \"category\": 0.5}\n",
    "\n",
    "        scored_docs = []\n",
    "\n",
    "        for doc in documents:\n",
    "            score_map: Dict[str, float] = {}\n",
    "\n",
    "            # 실제 메타데이터 추출\n",
    "            real_meta = doc.metadata.get(\"metadata\", doc.metadata)\n",
    "\n",
    "            # 1. 본문 유사도\n",
    "            doc_embedding = await asyncio.to_thread(\n",
    "                self.embeddings.embed_query, doc.page_content\n",
    "            )\n",
    "            score_map[\"main\"] = cosine_similarity(\n",
    "                [query_embedding_map[\"main\"]], [doc_embedding]\n",
    "            )[0][0]\n",
    "\n",
    "            # 2. Author\n",
    "            author_text = real_meta.get(\"author\", \"\")\n",
    "            if author_text and \"author\" in query_embedding_map:\n",
    "                author_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, author_text\n",
    "                )\n",
    "                score_map[\"author\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"author\"]], [author_emb]\n",
    "                )[0][0]\n",
    "\n",
    "            # 3. Title\n",
    "            title_text = real_meta.get(\"title\", \"\")\n",
    "            if title_text and \"title\" in query_embedding_map:\n",
    "                title_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, title_text\n",
    "                )\n",
    "                score_map[\"title\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"title\"]], [title_emb]\n",
    "                )[0][0]\n",
    "\n",
    "            # 4. Category\n",
    "            category_text = real_meta.get(\"category\", \"\")\n",
    "            if category_text and \"category\" in query_embedding_map:\n",
    "                category_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, category_text\n",
    "                )\n",
    "                score_map[\"category\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"category\"]], [category_emb]\n",
    "                )[0][0]\n",
    "\n",
    "            # 정규화된 가중치 기반 점수 계산\n",
    "            valid_keys = score_map.keys()\n",
    "            total_weight = sum(weights[k] for k in valid_keys)\n",
    "            final_score = sum(\n",
    "                (weights[k] / total_weight) * score_map[k] for k in valid_keys\n",
    "            )\n",
    "\n",
    "            scored_docs.append((doc, final_score))\n",
    "\n",
    "        # 점수 기준 정렬\n",
    "        sorted_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "        logger.info(\"리랭킹 완료 (정규화 가중치 방식)\")\n",
    "\n",
    "        for i, (doc, score) in enumerate(sorted_docs):\n",
    "            title = _extract_metadata_field(doc, \"title\", default=\"제목 없음\")\n",
    "            isbn = _extract_metadata_field(doc, \"ISBN\", default=\"N/A\")\n",
    "            logger.info(\n",
    "                f\"{i+1}. 제목: {title} | ISBN: {isbn} | 점수: {round(score, 4)}\"\n",
    "            )\n",
    "\n",
    "        reranked_docs = [\n",
    "            doc for doc, _ in sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "        ]\n",
    "        logger.info(\"리랭킹 완료 (정규화 가중치 방식, metadata 이중 구조 대응).\")\n",
    "        return reranked_docs\n",
    "\n",
    "    async def _expand_query(self, query: str) -> List[str]:\n",
    "        \"\"\"LLM을 사용하여 원본 쿼리를 확장된 쿼리 여러 개로 생성\"\"\"\n",
    "        logger.info(f\"검색 쿼리 확장 시작: '{query}'\")\n",
    "        # 쿼리 확장 LLMChain 호출\n",
    "        expansion_result = await async_invoke(\n",
    "            self.query_expansion_chain, {\"query\": query}, \"검색 쿼리 확장\"\n",
    "        )\n",
    "        expanded_queries_text = expansion_result.get(\"text\", \"\").strip()\n",
    "        expanded_queries = []\n",
    "        # LLM 응답 파싱 (번호 매겨진 리스트 형식 가정)\n",
    "        for line in expanded_queries_text.splitlines():\n",
    "            line_stripped = line.strip()\n",
    "            if not line_stripped:\n",
    "                continue  # 빈 줄 건너뛰기\n",
    "            # \"1. 확장쿼리 내용\" 에서 쿼리 내용만 추출\n",
    "            query_part = re.sub(r\"^\\d+\\.\\s*\", \"\", line_stripped).strip()\n",
    "            # 유효하고 원본과 다른 쿼리만 추가\n",
    "            if query_part and query_part.lower() != query.lower():\n",
    "                expanded_queries.append(query_part)\n",
    "\n",
    "        # 최대 3개까지만 사용\n",
    "        final_expanded_queries = expanded_queries[:3]\n",
    "        logger.info(\n",
    "            f\"생성된 확장 쿼리 ({len(final_expanded_queries)}개): {final_expanded_queries}\"\n",
    "        )\n",
    "        return final_expanded_queries\n",
    "\n",
    "    async def _retrieve_documents(\n",
    "        self, query: str, use_hyde: bool = False\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        최종 리트리버(Ensemble + ISBN Merging)를 사용하여 문서를 검색합니다.\n",
    "        use_hyde가 True이고 조건 충족 시, HyDE 기법을 적용하여 검색 쿼리를 보강합니다.\n",
    "        \"\"\"\n",
    "        retrieval_query = query\n",
    "        hyde_summary = \"\"\n",
    "\n",
    "        # HyDE 적용 조건: use_hyde=True 이고, 'implicit info' 선호도가 있을 때\n",
    "        if use_hyde and self.user_preferences.get(\"implicit info\"):\n",
    "            logger.info(\"HyDE 활성화: 가상 문서 요약 및 키워드 추출 시도\")\n",
    "            # 1. 가상 문서 요약 생성\n",
    "            hyde_result = await async_invoke(\n",
    "                self.hyde_generation_chain, {\"query\": query}, \"HyDE 가상 문서 생성\"\n",
    "            )\n",
    "            hyde_summary = hyde_result.get(\"text\", \"\").strip()\n",
    "\n",
    "            if hyde_summary:\n",
    "                logger.info(f\"생성된 가상 문서 요약: '{hyde_summary[:200]}...'\")\n",
    "                # 2. 요약에서 키워드 추출\n",
    "                keyword_result = await async_invoke(\n",
    "                    self.hyde_keyword_chain,\n",
    "                    {\"hyde_summary\": hyde_summary},\n",
    "                    \"HyDE 키워드 추출\",\n",
    "                )\n",
    "                hyde_keywords_text = keyword_result.get(\"text\", \"\").strip()\n",
    "                # 쉼표로 구분된 키워드를 리스트로 변환\n",
    "                hyde_keywords = [\n",
    "                    k.strip() for k in hyde_keywords_text.split(\",\") if k.strip()\n",
    "                ]\n",
    "\n",
    "                if hyde_keywords:\n",
    "                    logger.info(f\"추출된 HyDE 키워드: {hyde_keywords}\")\n",
    "                    # 3. 원본 쿼리 + HyDE 키워드로 최종 검색 쿼리 구성\n",
    "                    retrieval_query = f\"{query} {' '.join(hyde_keywords)}\"\n",
    "                    logger.info(f\"HyDE 적용된 검색 쿼리: '{retrieval_query}'\")\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"HyDE 요약에서 키워드를 추출하지 못했습니다. 원본 쿼리 사용.\"\n",
    "                    )\n",
    "                    # retrieval_query는 원본 query 유지\n",
    "            else:\n",
    "                logger.warning(\"HyDE 가상 문서 요약 생성 실패. 원본 쿼리 사용.\")\n",
    "                # retrieval_query는 원본 query 유지\n",
    "        elif use_hyde:\n",
    "            # use_hyde는 True지만 implicit info가 없을 때\n",
    "            logger.info(\"HyDE 조건 미충족 ('implicit info' 없음). 일반 쿼리 검색 수행.\")\n",
    "        else:\n",
    "            # use_hyde 자체가 False일 때\n",
    "            logger.info(\"일반 쿼리 검색 수행.\")\n",
    "\n",
    "        logger.info(f\"최종 리트리버 호출 시작 (쿼리: '{retrieval_query[:100]}...')\")\n",
    "        try:\n",
    "            # 최종 리트리버(merged_hybrid_retriever) 호출\n",
    "            retrieved_docs = await self.retriever.aget_relevant_documents(\n",
    "                retrieval_query\n",
    "            )\n",
    "            logger.info(f\"검색된 문서 수 (ISBN 병합 완료됨): {len(retrieved_docs)}\")\n",
    "        except Exception as e:\n",
    "            # 리트리버 실행 중 발생할 수 있는 모든 예외 처리\n",
    "            logger.error(\n",
    "                f\"문서 검색 실패 (쿼리: '{retrieval_query}'): {e}\", exc_info=True\n",
    "            )\n",
    "            retrieved_docs = []  # 오류 시 빈 목록 반환\n",
    "\n",
    "        return retrieved_docs\n",
    "\n",
    "    async def _generate_recommendations(self, final_query: str) -> str:\n",
    "        \"\"\"\n",
    "        최종 검색 쿼리를 사용하여 문서를 검색, 확장, 정렬, 리랭킹하고\n",
    "        상위 결과를 요약하여 최종 추천 응답 문자열을 생성합니다.\n",
    "        \"\"\"\n",
    "        logger.info(f\"추천 생성 시작. 최종 쿼리: '{final_query}'\")\n",
    "\n",
    "        # 1. 초기 검색 (HyDE 적용 가능성 있음)\n",
    "        # 'implicit info' 선호도가 있으면 HyDE 시도\n",
    "        use_hyde = False\n",
    "        use_expansion = False\n",
    "\n",
    "        # 명시적 author/category 없고, implicit info만 있을 때만 hyde + expansion\n",
    "        has_author = bool(self.user_preferences.get(\"author\"))\n",
    "        has_title = bool(self.user_preferences.get(\"title\"))\n",
    "        has_implicit = bool(self.user_preferences.get(\"implicit info\"))\n",
    "\n",
    "        if not has_author and not has_title and has_implicit:\n",
    "            use_hyde = True\n",
    "            use_expansion = True\n",
    "\n",
    "        # 2. 최초 검색 수행 (HyDE 적용 여부 반영)\n",
    "        initial_docs = await self._retrieve_documents(final_query, use_hyde=use_hyde)\n",
    "\n",
    "        # # 통합된 전체 문서 리스트\n",
    "\n",
    "        # 그대로 사용 (이미 ISBN 병합된 상태)\n",
    "        all_docs_to_consider = list(initial_docs)\n",
    "        processed_queries = {final_query.lower()}\n",
    "\n",
    "        # 2. 확장 쿼리 적용 (필요한 경우에만)\n",
    "        if use_expansion:\n",
    "            expanded_queries = await self._expand_query(final_query)\n",
    "            expansion_tasks = []\n",
    "\n",
    "            if expanded_queries:\n",
    "                logger.info(\n",
    "                    f\"확장 쿼리 ({len(expanded_queries)}개)로 추가 검색 수행...\"\n",
    "                )\n",
    "                for eq in expanded_queries:\n",
    "                    eq_lower = eq.lower()\n",
    "                    if eq_lower not in processed_queries:\n",
    "                        expansion_tasks.append(\n",
    "                            self._retrieve_documents(eq, use_hyde=False)\n",
    "                        )\n",
    "                        processed_queries.add(eq_lower)\n",
    "\n",
    "                if expansion_tasks:\n",
    "                    expansion_results = await asyncio.gather(*expansion_tasks)\n",
    "\n",
    "                    # ISBN 기준 추가 (중복 방지)\n",
    "                    existing_isbns = {\n",
    "                        doc.metadata.get(\"ISBN\")\n",
    "                        for doc in all_docs_to_consider\n",
    "                        if doc.metadata.get(\"ISBN\")\n",
    "                    }\n",
    "                    for docs_list in expansion_results:\n",
    "                        for doc in docs_list:\n",
    "                            isbn = doc.metadata.get(\"ISBN\")\n",
    "                            if isbn and isbn not in existing_isbns:\n",
    "                                all_docs_to_consider.append(doc)\n",
    "                                existing_isbns.add(isbn)\n",
    "\n",
    "        logger.info(\n",
    "            f\"초기 및 확장 검색 후 고려할 총 고유 문서 수: {len(all_docs_to_consider)}\"\n",
    "        )\n",
    "\n",
    "        logger.debug(\n",
    "            f\"--- 리랭킹 함수(_embedding_rerank_documents) 입력 문서 메타데이터 확인 (총 {len(all_docs_to_consider)}개) ---\"\n",
    "        )\n",
    "        for i, doc in enumerate(all_docs_to_consider):\n",
    "            metadata_content = doc.metadata if doc.metadata else {}  # None 방지\n",
    "            logger.debug(\n",
    "                f\"문서 {i+1} Metadata: {json.dumps(metadata_content, indent=2, ensure_ascii=False)}\"\n",
    "            )\n",
    "            try:\n",
    "                isbn_check = metadata_content.get(\"ISBN\", \"ISBN 키 없음\")\n",
    "                title_check = metadata_content.get(\"title\", \"Title 키 없음\")\n",
    "                logger.debug(f\"  -> 확인: ISBN='{isbn_check}', Title='{title_check}'\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  -> 메타데이터 접근 오류 발생: {e}\")\n",
    "        logger.debug(\"--- 리랭킹 입력 데이터 확인 완료 ---\")\n",
    "\n",
    "        # 검색 결과가 전혀 없으면 추천 불가 메시지 반환\n",
    "        if not all_docs_to_consider:\n",
    "            logger.warning(\"검색 및 확장 결과 문서를 찾지 못했습니다. 추천 생성 불가.\")\n",
    "            return \"죄송합니다, 해당 조건에 맞는 책을 찾지 못했습니다. 다른 조건으로 다시 시도해 보시겠어요?\"\n",
    "\n",
    "        # 4. LLM 기반 리랭킹\n",
    "        logger.info(\"리랭킹 수행...\")\n",
    "        ranked_docs = await self._embedding_rerank_documents(\n",
    "            final_query, all_docs_to_consider\n",
    "        )\n",
    "\n",
    "        # 리랭킹 결과가 없으면 추천 불가\n",
    "        if not ranked_docs:\n",
    "            logger.warning(\"리랭킹 결과 유효한 문서가 없습니다. 추천 생성 불가.\")\n",
    "            return \"죄송합니다, 추천할 책을 선정하는 데 어려움이 있습니다. 잠시 후 다시 시도해주세요.\"\n",
    "\n",
    "        # 5. 상위 결과 선택 및 최종 추천 생성\n",
    "        # 상위 3개 문서 선택\n",
    "        top_docs = ranked_docs[:3]\n",
    "        logger.info(f\"최종 추천 후보 문서 수: {len(top_docs)}\")\n",
    "\n",
    "        recommendations = []  # 최종 응답에 포함될 추천 문구 리스트\n",
    "        self.last_recommendations = []  # 후속 질문 처리를 위한 추천 문서 저장\n",
    "        processed_isbns = set()  # 중복 추천 방지\n",
    "\n",
    "        for rank, doc in enumerate(top_docs):\n",
    "            isbn = _extract_metadata_field(doc, \"ISBN\")\n",
    "            title = _extract_metadata_field(doc, \"title\", default=\"제목 없음\")\n",
    "\n",
    "            logger.debug(\n",
    "                f\"추천 후보 처리 중 (Rank {rank+1}): ISBN={isbn}, Title={title}\"\n",
    "            )\n",
    "\n",
    "            if not isbn or isbn == \"N/A\":\n",
    "                logger.warning(\n",
    "                    f\"Rank {rank+1} 추천 후보에 ISBN 없음. 건너뜀. Title: {title}\"\n",
    "                )\n",
    "                continue\n",
    "            if isbn in processed_isbns:\n",
    "                logger.warning(f\"중복 ISBN '{isbn}' 추천 목록에 이미 존재. 건너뜀.\")\n",
    "                continue\n",
    "\n",
    "            # 후속 질문 처리를 위해, 해당 ISBN의 *전체* 내용이 담긴 문서를 master 목록에서 다시 가져와 저장\n",
    "            # _re_rank_documents 에서 사용된 doc은 이미 ISBN 병합된 상태지만,\n",
    "            # 명시적으로 전체 내용을 다시 로드하여 last_recommendations에 저장\n",
    "            full_merged_doc = self._merge_documents_by_isbn(isbn)\n",
    "            if not full_merged_doc:\n",
    "                logger.error(\n",
    "                    f\"치명적 오류: 리랭킹된 문서(ISBN: {isbn})의 전체 정보를 병합하지 못했습니다. 추천 목록에서 제외.\"\n",
    "                )\n",
    "                continue\n",
    "            # 병합된 전체 문서 내용을 last_recommendations에 저장\n",
    "            self.last_recommendations.append(full_merged_doc)\n",
    "            processed_isbns.add(isbn)  # 처리된 ISBN 기록\n",
    "\n",
    "            # 사용자에게 보여줄 추천 문구 생성\n",
    "            metadata = full_merged_doc.metadata\n",
    "            title = metadata.get(\"title\", \"제목 정보 없음\")\n",
    "            author = metadata.get(\"author\", \"저자 정보 없음\")\n",
    "            book_cover = metadata.get(\"book_cover\", \"표지 정보 없음\")\n",
    "\n",
    "            # 요약할 텍스트 선택 (책소개 > 출판사리뷰 > 추천사 > 전체 내용 일부 순)\n",
    "            book_intro = extract_field(full_merged_doc.page_content, \"책소개\")\n",
    "            publisher_review = extract_field(full_merged_doc.page_content, \"출판사리뷰\")\n",
    "            recommendation_field = extract_field(full_merged_doc.page_content, \"추천사\")\n",
    "\n",
    "            text_for_summary = \"\"\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "                text_for_summary = book_intro\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "                text_for_summary = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "                text_for_summary = recommendation_field\n",
    "            else:\n",
    "                # 필드 추출 실패 시, 전체 내용에서 앞부분 사용 (필드명 제외 시도)\n",
    "                page_content_cleaned = re.sub(\n",
    "                    r\"^\\s*.*?\\s*[:：]\\s*\",\n",
    "                    \"\",\n",
    "                    full_merged_doc.page_content,\n",
    "                    flags=re.MULTILINE,\n",
    "                ).strip()\n",
    "                text_for_summary = page_content_cleaned[:500]  # 길이 제한\n",
    "\n",
    "            # LLM으로 요약 생성\n",
    "            if text_for_summary and len(text_for_summary.strip()) >= MIN_INFO_LENGTH:\n",
    "                summary = await self._summarize_chunk_with_llm(text_for_summary)\n",
    "            else:\n",
    "                summary = \"책에 대한 상세 설명이 부족합니다.\"\n",
    "\n",
    "            # 최종 추천 문구 형식\n",
    "            # recommendation_text = (f\"{rank+1}. \\n표지: {book_cover}\\n제목: {title}\\n저자: {author}\\n- 추천 이유: {summary}\")\n",
    "            recommendation_text = f\"{rank+1}. \\r\\n표지: {book_cover}\\r\\n제목: {title}\\r\\n저자: {author}\\r\\n- 추천 이유: {summary}\"\n",
    "            recommendations.append(recommendation_text)\n",
    "            logger.debug(f\"추천 문구 생성됨: {title}\")\n",
    "\n",
    "        # 최종 추천 결과 로깅\n",
    "        if self.last_recommendations:\n",
    "            rec_titles = [\n",
    "                d.metadata.get(\"title\", \"N/A\") for d in self.last_recommendations\n",
    "            ]\n",
    "            logger.info(\n",
    "                f\"'_generate_recommendations' 종료. last_recommendations 업데이트 ({len(self.last_recommendations)}개): {rec_titles}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"'_generate_recommendations' 종료. 최종 추천 목록(last_recommendations)이 비어있음!\"\n",
    "            )\n",
    "\n",
    "        # 생성된 추천 문구가 없으면 실패 메시지 반환\n",
    "        if not recommendations:\n",
    "            return \"추천할 만한 책을 찾지 못했습니다. 조건을 바꿔서 다시 질문해 주시겠어요?\"\n",
    "\n",
    "        # 최종 답변 조립\n",
    "        final_answer = \"이런 책들은 어떠신가요? 마음에 드는 책이 있다면 더 자세히 알려드릴게요.\\n\\n\" + \"\\n\\n\".join(\n",
    "            recommendations\n",
    "        )\n",
    "        logger.info(\"추천 응답 생성 완료.\")\n",
    "        return final_answer\n",
    "\n",
    "    async def handle_followup_query(self, followup_query: str) -> tuple[bool, str]:\n",
    "        \"\"\"이전 추천에 대한 후속 질문인지 판단하고 처리\"\"\"\n",
    "        logger.info(f\"후속 질문 처리 시작. Query: '{followup_query}'\")\n",
    "\n",
    "        # 이전 추천 결과가 없으면 후속 질문 처리 불가\n",
    "        if not self.last_recommendations:\n",
    "            logger.error(\n",
    "                \"handle_followup_query 진입 오류: last_recommendations가 비어 있음!\"\n",
    "            )\n",
    "            # 후속 질문이 아니라고 판단하고 False 반환\n",
    "            return False, \"\"\n",
    "\n",
    "        # LLM에게 후속 질문 의도 분석 요청\n",
    "        # 이전 추천 목록 정보 제공\n",
    "        rec_info = []\n",
    "        for i, doc in enumerate(self.last_recommendations):\n",
    "            title = doc.metadata.get(\"title\", \"제목 없음\")\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            # 간단한 요약 정보만 제공 (LLM 컨텍스트 길이 고려)\n",
    "            snippet = await self._summarize_chunk_with_llm(\n",
    "                doc.page_content[:500]\n",
    "            )  # 앞 500자만 요약\n",
    "            rec_info.append(f\"{i+1}. 제목: {title}, ISBN: {isbn}\\n   요약: {snippet}\")\n",
    "        rec_info_str = \"\\n\".join(rec_info)\n",
    "\n",
    "        # 후속 질문 의도 분석 프롬프트\n",
    "        prompt = f\"\"\"이전에 다음 책들을 추천했습니다:\n",
    "{rec_info_str}\n",
    "\n",
    "사용자의 후속 질문은 다음과 같습니다: \"{followup_query}\"\n",
    "\n",
    "이 질문이 위 추천 목록과 관련된 후속 질문인지, 아니면 완전히 새로운 질문인지 판단하고, 후속 질문이라면 그 의도를 분석하여 다음 JSON 형식 중 **하나만** 출력해라. 새로운 질문이면 `{{ \"action\": \"새 질문\", \"ISBN\": null, \"query\": null }}` 형식으로 출력하라. **절대로 다른 설명이나 대화 없이 오직 JSON 객체 하나만 출력해야 한다.**\n",
    "\n",
    "[후속 질문 의도 분류 및 JSON 형식]\n",
    "- 특정 책 상세 정보 요청: `{{\"action\": \"상세\", \"ISBN\": \"<요청된 책의 ISBN>\", \"query\": \"{followup_query}\"}}` (몇 번째 책, 또는 제목으로 언급 시 해당 ISBN 사용)\n",
    "- 특정 책과 유사한 책 추천 요청: `{{\"action\": \"유사\", \"ISBN\": \"<기준 책의 ISBN>\", \"query\": \"<유사성 관련 사용자 언급>\"}}`\n",
    "- 추천된 책들 비교 요청: `{{\"action\": \"비교\", \"ISBN\": \"<비교 대상 ISBN 목록 (쉼표 구분)>\", \"query\": \"{followup_query}\"}}`\n",
    "- 추천 결과에 대한 피드백/불만: `{{\"action\": \"피드백\", \"ISBN\": null, \"query\": \"{followup_query}\"}}` (예: \"더 쉬운 책은 없나요?\", \"이건 별로네요\")\n",
    "- 완전히 새로운 질문: `{{\"action\": \"새 질문\", \"ISBN\": null, \"query\": null}}`\n",
    "\n",
    "[주의사항]\n",
    "- 사용자가 몇 번째 책이나 제목으로 언급하면, 제공된 추천 목록에서 정확한 ISBN을 찾아 사용하라. (예: 첫 번째 책이면 목록의 첫 ISBN)\n",
    "- 여러 책을 언급하면 해당 ISBN들을 쉼표로 구분하여 포함하라.\n",
    "- **출력은 반드시 유효한 JSON 객체 하나여야 한다. 다른 텍스트는 절대 포함하지 마라.**\n",
    "\n",
    "[분석 결과 (JSON 객체만 출력)]\n",
    "\"\"\"\n",
    "\n",
    "        try:\n",
    "            # 의도 분석 LLM 호출\n",
    "            result_text = await async_invoke_llm(prompt, \"후속 질문 의도 분석\")\n",
    "            logger.debug(f\"후속 질문 의도 분석 LLM 원본 응답: {result_text}\")\n",
    "\n",
    "            # LLM 응답에서 JSON 파싱\n",
    "            analysis_result = None\n",
    "            json_match = re.search(r\"\\{.*\\}\", result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    analysis_result = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    logger.error(\n",
    "                        f\"후속 질문 의도 분석 결과 JSON 파싱 실패 (JSON 형식 오류): {result_text}\"\n",
    "                    )\n",
    "                    # 파싱 실패 시 새 질문으로 간주\n",
    "                    analysis_result = {\"action\": \"새 질문\"}\n",
    "            else:\n",
    "                # JSON 객체를 찾지 못한 경우, 응답 텍스트 내용으로 추론 시도 (최후의 수단)\n",
    "                if (\n",
    "                    \"새 질문\" in result_text\n",
    "                    or '\"action\": \"새 질문\"' in result_text.replace(\" \", \"\")\n",
    "                ):\n",
    "                    logger.warning(\n",
    "                        f\"후속 질문 의도 분석 JSON 객체 미발견, '새 질문' 패턴 감지: {result_text}\"\n",
    "                    )\n",
    "                    analysis_result = {\"action\": \"새 질문\"}\n",
    "                else:\n",
    "                    logger.error(\n",
    "                        f\"후속 질문 의도 분석 결과 JSON 파싱 실패 및 '새 질문' 패턴 미감지: {result_text}\"\n",
    "                    )\n",
    "                    # 처리 불가로 판단, 후속 질문이 아닌 것으로 처리\n",
    "                    return False, \"\"\n",
    "\n",
    "            # 파싱된 결과에서 정보 추출\n",
    "            action = analysis_result.get(\"action\", \"새 질문\")  # 기본값 '새 질문'\n",
    "            isbn_str = analysis_result.get(\"ISBN\", \"\")\n",
    "            query_part = analysis_result.get(\n",
    "                \"query\", followup_query\n",
    "            )  # query 필드 없으면 원본 사용\n",
    "\n",
    "            logger.info(\n",
    "                f\"후속 질문 분석 결과: action='{action}', ISBN='{isbn_str}', query='{query_part[:50]}...'\"\n",
    "            )\n",
    "\n",
    "            # 분석 결과에 따른 분기 처리\n",
    "            if action == \"새 질문\":\n",
    "                # 새 질문이면 처리하지 않고 False 반환\n",
    "                return False, \"\"\n",
    "\n",
    "            # ISBN 문자열을 리스트로 변환\n",
    "            isbn_list = (\n",
    "                [s.strip() for s in str(isbn_str).split(\",\") if s.strip()]\n",
    "                if isbn_str\n",
    "                else []\n",
    "            )\n",
    "            target_isbn = isbn_list[0] if isbn_list else None  # 주로 첫 번째 ISBN 사용\n",
    "\n",
    "            # --- 상세 정보 요청 처리 ---\n",
    "            if action == \"상세\":\n",
    "                if not target_isbn:\n",
    "                    # 대상 ISBN이 없으면 사용자에게 다시 질문\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"어떤 책에 대해 더 알고 싶으신지 알려주시겠어요? (예: 첫 번째 책 또는 책 제목)\",\n",
    "                    )\n",
    "\n",
    "                # last_recommendations에서 해당 ISBN의 전체 문서 찾기\n",
    "                target_doc = next(\n",
    "                    (\n",
    "                        doc\n",
    "                        for doc in self.last_recommendations\n",
    "                        if str(doc.metadata.get(\"ISBN\", \"\")).strip()\n",
    "                        == str(target_isbn).strip()\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                if target_doc:\n",
    "                    logger.debug(\n",
    "                        f\"상세 정보 요청: ISBN '{target_isbn}' 문서 찾음: Title='{target_doc.metadata.get('title')}'\"\n",
    "                    )\n",
    "                    # 상세 설명 생성 프롬프트\n",
    "                    detail_prompt = f\"\"\"다음은 사용자가 문의한 '{target_doc.metadata.get(\"title\", \"해당 책\")}'에 대한 정보입니다. 이 정보를 바탕으로 사용자 질문 \"{query_part}\"에 답하거나, 특별한 질문이 없다면 책에 대해 자연스럽게 더 자세히 설명해주세요. 책의 특징, 주요 내용, 대상 독자 등을 포함하면 좋습니다. 관련 정보가 부족하면 솔직하게 말해주세요.\n",
    "\n",
    "[책 정보 요약]\n",
    "제목: {target_doc.metadata.get(\"title\", \"정보 없음\")}\n",
    "저자: {target_doc.metadata.get(\"author\", \"정보 없음\")}\n",
    "분류: {target_doc.metadata.get(\"category\", \"정보 없음\")}\n",
    "페이지: {target_doc.metadata.get(\"page\", \"정보 없음\")} 쪽\n",
    "가격: {target_doc.metadata.get(\"price\", \"정보 없음\")} 원\n",
    "\n",
    "[책 소개 및 내용 (일부)]\n",
    "{target_doc.page_content[:3000]}...\n",
    "\n",
    "[답변 또는 상세 설명]\n",
    "\"\"\"\n",
    "                    # 상세 설명 LLM 호출\n",
    "                    detailed_info = await async_invoke_llm(\n",
    "                        detail_prompt, \"후속 상세 설명 생성\"\n",
    "                    )\n",
    "                    return True, (\n",
    "                        detailed_info\n",
    "                        if detailed_info\n",
    "                        else \"죄송합니다, 요청하신 내용에 대한 추가 정보를 제공하기 어렵습니다.\"\n",
    "                    )\n",
    "                else:\n",
    "                    # 해당 ISBN 문서를 못 찾은 경우\n",
    "                    logger.warning(\n",
    "                        f\"상세 정보 요청 실패: target_isbn '{target_isbn}' 문서를 last_recommendations 에서 찾지 못함.\"\n",
    "                    )\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 요청하신 ISBN({target_isbn})의 책 정보를 찾을 수 없습니다. 현재 추천된 책들의 ISBN은 다음과 같습니다: {available_isbns}\",\n",
    "                    )\n",
    "\n",
    "            # --- 유사한 책 추천 요청 처리 ---\n",
    "            elif action == \"유사\":\n",
    "                if not target_isbn:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"어떤 책과 유사한 책을 찾으시는지 알려주시겠어요? (예: 두 번째 책 같은 스타일)\",\n",
    "                    )\n",
    "\n",
    "                # 기준이 되는 책 정보 찾기\n",
    "                base_doc = next(\n",
    "                    (\n",
    "                        doc\n",
    "                        for doc in self.last_recommendations\n",
    "                        if str(doc.metadata.get(\"ISBN\", \"\")).strip()\n",
    "                        == str(target_isbn).strip()\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                if base_doc:\n",
    "                    logger.debug(\n",
    "                        f\"유사 책 요청: 기준 ISBN '{target_isbn}' 문서 찾음: Title='{base_doc.metadata.get('title')}'\"\n",
    "                    )\n",
    "                    # 유사성 기반 새 검색 쿼리 생성\n",
    "                    base_title = base_doc.metadata.get(\"title\", \"\")\n",
    "                    base_author = base_doc.metadata.get(\"author\", \"\")\n",
    "                    base_category = base_doc.metadata.get(\"category\", \"\")\n",
    "                    # 유사성 특징 추출 (LLM 사용 또는 간단한 규칙 기반)\n",
    "                    # 예: \"카테고리 장르의 저자 작가 스타일\" 또는 \"제목과 비슷한 분위기\"\n",
    "                    similarity_aspects = (\n",
    "                        f\"{base_category} 장르\"\n",
    "                        if base_category\n",
    "                        else f\"'{base_title}'와 비슷한\"\n",
    "                    )\n",
    "                    if base_author:\n",
    "                        similarity_aspects += f\" {base_author} 작가 스타일\"\n",
    "\n",
    "                    # 사용자가 추가로 언급한 내용 반영 (query_part)\n",
    "                    user_refinement = (\n",
    "                        f\" 그리고 '{query_part}' 특징을 가진\"\n",
    "                        if query_part and query_part != followup_query\n",
    "                        else \"\"\n",
    "                    )\n",
    "                    # 새 검색 쿼리 조합\n",
    "                    new_query = f\"{similarity_aspects}{user_refinement} 책 추천\"\n",
    "                    logger.info(f\"유사 책 추천을 위한 새 쿼리 생성: {new_query}\")\n",
    "\n",
    "                    # 생성된 새 쿼리로 다시 추천 생성 함수 호출\n",
    "                    recommendation_result = await self._generate_recommendations(\n",
    "                        new_query\n",
    "                    )\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"네, '{base_title}'와(과) 비슷한 다른 책을 찾아볼게요.\\n\\n\"\n",
    "                        + recommendation_result,\n",
    "                    )\n",
    "                else:\n",
    "                    # 기준 책을 못 찾은 경우\n",
    "                    logger.warning(\n",
    "                        f\"유사 책 요청 실패: target_isbn '{target_isbn}' 기준 문서를 last_recommendations 에서 찾지 못함.\"\n",
    "                    )\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 기준이 되는 ISBN({target_isbn})의 책 정보를 찾을 수 없습니다. 현재 추천된 책들의 ISBN은 다음과 같습니다: {available_isbns}\",\n",
    "                    )\n",
    "\n",
    "            # --- 책 비교 요청 처리 ---\n",
    "            elif action == \"비교\":\n",
    "                if len(isbn_list) < 2:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"비교할 책을 두 권 이상 알려주시겠어요? (예: 첫 번째랑 세 번째 책 비교해주세요)\",\n",
    "                    )\n",
    "\n",
    "                # 비교 대상 ISBN들이 실제로 last_recommendations에 있는지 확인\n",
    "                valid_comparison_isbns = [\n",
    "                    isbn\n",
    "                    for isbn in isbn_list\n",
    "                    if any(\n",
    "                        str(d.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "                        for d in self.last_recommendations\n",
    "                    )\n",
    "                ]\n",
    "\n",
    "                if len(valid_comparison_isbns) < 2:\n",
    "                    logger.warning(\n",
    "                        f\"비교 요청 실패: 유효한 비교 대상 ISBN 부족 ({valid_comparison_isbns} / 요청: {isbn_list})\"\n",
    "                    )\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 비교 요청하신 책({isbn_list}) 중 일부를 찾을 수 없거나 유효하지 않습니다. 현재 추천된 책 ISBN: {available_isbns}\",\n",
    "                    )\n",
    "\n",
    "                # 비교 처리 함수 호출\n",
    "                comparison_result = await self._handle_comparison(\n",
    "                    query_part, valid_comparison_isbns\n",
    "                )\n",
    "                return True, comparison_result\n",
    "\n",
    "            # --- 피드백/불만 처리 ---\n",
    "            elif action == \"피드백\":\n",
    "                logger.info(f\"사용자 피드백/불만 처리 시도: '{query_part}'\")\n",
    "                # 피드백을 반영하여 새 검색 쿼리 생성 (간단한 방식)\n",
    "                feedback_based_query = f\"이전 추천에 대해 '{query_part}' 라는 피드백이 있었습니다. 이 점을 고려하여 다른 책을 추천해주세요.\"\n",
    "                logger.info(f\"피드백 기반 새 쿼리 생성: {feedback_based_query}\")\n",
    "\n",
    "                # 새 쿼리로 다시 추천 생성 함수 호출\n",
    "                recommendation_result = await self._generate_recommendations(\n",
    "                    feedback_based_query\n",
    "                )\n",
    "                return (\n",
    "                    True,\n",
    "                    \"피드백 감사합니다. 말씀해주신 점을 바탕으로 다른 책을 찾아보겠습니다.\\n\\n\"\n",
    "                    + recommendation_result,\n",
    "                )\n",
    "\n",
    "            # --- 처리되지 않은 action ---\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"처리되지 않은 후속 질문 action: {action}. 새 질문으로 간주.\"\n",
    "                )\n",
    "                return False, \"\"  # 새 질문으로 처리\n",
    "\n",
    "        except Exception as e:\n",
    "            # 후속 질문 처리 중 예외 발생\n",
    "            logger.error(f\"후속 질문 처리 중 예외 발생: {e}\", exc_info=True)\n",
    "            return True, \"후속 질문 처리 중 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "    async def _handle_comparison(self, query_part: str, isbn_list: List[str]) -> str:\n",
    "        \"\"\"주어진 ISBN 목록의 책들을 비교 설명하는 기능\"\"\"\n",
    "        logger.info(\n",
    "            f\"도서 비교 시작. ISBN 목록: {isbn_list}, 비교 관점: '{query_part}'\"\n",
    "        )\n",
    "        comparison_docs_info = []  # 비교할 책들의 정보 저장 리스트\n",
    "\n",
    "        # last_recommendations에서 비교 대상 책 정보 추출\n",
    "        for isbn in isbn_list:\n",
    "            doc = next(\n",
    "                (\n",
    "                    d\n",
    "                    for d in self.last_recommendations\n",
    "                    if str(d.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if doc:\n",
    "                metadata = doc.metadata\n",
    "                # 비교에 사용할 정보 추출 (제목, 저자, 요약, 주요 메타데이터)\n",
    "                summary = await self._summarize_chunk_with_llm(\n",
    "                    doc.page_content[:2000]\n",
    "                )  # 비교를 위해 조금 더 긴 내용 요약\n",
    "                comparison_docs_info.append(\n",
    "                    {\n",
    "                        \"title\": metadata.get(\"title\", \"제목 없음\"),\n",
    "                        \"author\": metadata.get(\"author\", \"저자 없음\"),\n",
    "                        \"summary\": summary,\n",
    "                        \"category\": metadata.get(\"category\", \"분류 없음\"),\n",
    "                        \"page\": metadata.get(\"page\", \"페이지 수 없음\"),\n",
    "                        \"price\": metadata.get(\"price\", \"가격 정보 없음\"),\n",
    "                        \"isbn\": isbn,  # 식별용 ISBN 추가\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                # 이 경우는 이론상 발생하면 안됨 (handle_followup_query에서 검증했으므로)\n",
    "                logger.error(\n",
    "                    f\"비교 오류: 유효성 검사 후에도 ISBN '{isbn}' 문서를 last_recommendations에서 찾을 수 없음.\"\n",
    "                )\n",
    "\n",
    "        # 비교 대상이 2개 미만이면 비교 불가\n",
    "        if len(comparison_docs_info) < 2:\n",
    "            logger.warning(\n",
    "                f\"비교 가능한 문서가 2개 미만입니다 (찾은 문서 수: {len(comparison_docs_info)}).\"\n",
    "            )\n",
    "            return \"비교할 책 정보를 충분히 찾지 못했습니다.\"\n",
    "\n",
    "        # 비교 설명 생성 프롬프트\n",
    "        comparison_prompt_template = \"\"\"다음은 사용자가 비교를 요청한 책들의 정보입니다. 사용자의 비교 요청 관점인 \"{{ query }}\"에 특히 초점을 맞춰 이 책들을 명확하게 비교 설명해주세요. 각 책의 주요 특징, 장르, 내용 스타일, 난이도, 분량, 가격 등 관련 정보를 활용하고, 어떤 독자에게 더 적합할지 등을 포함하여 답변하는 것이 좋습니다. 표 형식보다는 자연스러운 문장으로 설명해주세요.\n",
    "\n",
    "[비교 대상 책 정보]\n",
    "{% for doc in summaries %}\n",
    "--- 책 {{ loop.index }} (ISBN: {{ doc.isbn }}) ---\n",
    "제목: {{ doc.title }}\n",
    "저자: {{ doc.author }}\n",
    "분류: {{ doc.category }}\n",
    "페이지 수: {{ doc.page }}\n",
    "가격: {{ doc.price }} 원\n",
    "요약: {{ doc.summary }}\n",
    "{% endfor %}\n",
    "\n",
    "[사용자 비교 요청 관점/질문]\n",
    "\"{{ query }}\"\n",
    "\n",
    "[비교 설명]\n",
    "\"\"\"\n",
    "        try:\n",
    "            # 프롬프트 템플릿 렌더링\n",
    "            comp_template = PromptTemplate(\n",
    "                template=comparison_prompt_template,\n",
    "                input_variables=[\"summaries\", \"query\"],\n",
    "                template_format=\"jinja2\",\n",
    "            )\n",
    "            rendered_prompt = comp_template.render(\n",
    "                summaries=comparison_docs_info, query=query_part\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"도서 비교 프롬프트 생성 완료 (일부):\\n{rendered_prompt[:500]}...\"\n",
    "            )\n",
    "\n",
    "            # 비교 설명 생성 LLM 호출\n",
    "            comparison_result = await async_invoke_llm(\n",
    "                rendered_prompt, \"도서 비교 설명 생성\"\n",
    "            )\n",
    "\n",
    "            # 결과 검증\n",
    "            if (\n",
    "                not comparison_result\n",
    "                or len(comparison_result) < 20\n",
    "                or \"죄송\" in comparison_result\n",
    "                or \"모르겠\" in comparison_result\n",
    "            ):\n",
    "                logger.warning(\"LLM 기반 도서 비교 설명 생성 실패 또는 결과 부적절.\")\n",
    "                return \"죄송합니다, 요청하신 책들을 비교 설명하는 데 어려움이 있습니다.\"\n",
    "\n",
    "            logger.info(\"도서 비교 설명 생성 완료.\")\n",
    "            return comparison_result\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"도서 비교 설명 생성 중 예외 발생: {e}\", exc_info=True)\n",
    "            return \"죄송합니다, 책들을 비교하는 중 오류가 발생했습니다.\"\n",
    "\n",
    "    async def process_query(\n",
    "        self, user_query: str, force_recommendation: bool = False\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        사용자 쿼리를 받아 처리하는 메인 로직.\n",
    "        선호도 업데이트, 행동 결정(추가 질문 vs 추천), 후속 질문 처리 등을 수행.\n",
    "        \"\"\"\n",
    "        logger.info(f\"=== 새로운 사용자 쿼리 처리 시작: '{user_query}' ===\")\n",
    "        # 사용자 발화 기록 추가\n",
    "        self.user_history.append(f\"사용자: {user_query}\")\n",
    "\n",
    "        # 1. 사용자 입력에서 선호도 업데이트\n",
    "        await self.update_preferences_from_input(user_query)\n",
    "\n",
    "        # 2. 후속 질문 처리 시도 (이전 행동이 '추천'이었고, 추천 결과가 있을 경우)\n",
    "        is_potential_followup = self.last_action == \"추천\" and self.last_recommendations\n",
    "        if is_potential_followup:\n",
    "            logger.info(\"이전 추천에 대한 후속 질문 가능성 확인 중...\")\n",
    "            handled, followup_output = await self.handle_followup_query(user_query)\n",
    "            if handled:\n",
    "                logger.info(\"후속 질문 처리 완료.\")\n",
    "                self.llm_history.append(f\"챗봇: {followup_output}\")  # 챗봇 응답 기록\n",
    "                return followup_output  # 후속 질문 처리 결과 반환\n",
    "\n",
    "            else:\n",
    "                # 후속 질문이 아니라고 판단되면, 일반 질문 처리 로직으로 넘어감\n",
    "                logger.info(\"후속 질문이 아님. 일반 질문 처리 로직으로 진행합니다.\")\n",
    "\n",
    "        # 3. 일반 질문 처리: 행동 결정 (추천 vs 추가 질문)\n",
    "        action: Optional[str] = None\n",
    "        additional_question: str = \"\"\n",
    "\n",
    "        if not force_recommendation:  # 강제 추천 모드가 아닐 경우\n",
    "            logger.info(\"행동 결정 요청 (추천 vs 추가 질문)\")\n",
    "            # 선호도 수집 상태 확인 (예: 제목 외 유의미한 선호도 1개 이상 & 업데이트 1회 이상)\n",
    "            meaningful_prefs_count = sum(\n",
    "                1 for k, v in self.user_preferences.items() if v and k != \"title\"\n",
    "            )\n",
    "            # 추천을 위한 최소 조건 설정 (예: 유의미 선호도 1개 이상 or 업데이트 2회 이상)\n",
    "            should_recommend_heuristically = (\n",
    "                meaningful_prefs_count >= 1 or self.preference_update_count >= 2\n",
    "            )\n",
    "\n",
    "            if not should_recommend_heuristically and self.preference_update_count < 2:\n",
    "                # 초기 대화 단계에서는 추가 질문 유도\n",
    "                logger.info(\n",
    "                    f\"선호도 부족 ({meaningful_prefs_count}개 / {self.preference_update_count}번 업데이트). '추가 질문' 강제 실행.\"\n",
    "                )\n",
    "                action = \"추가 질문\"\n",
    "                additional_question = \"어떤 종류의 책을 찾으시는지 좀 더 자세히 말씀해주시겠어요? (예: 구체적인 카테고리, 특정 작가, 책의 수준/분위기 등)\"\n",
    "            else:\n",
    "                # 정보가 어느 정도 모였으면 LLM에게 판단 요청\n",
    "                prompt_vars = {\n",
    "                    \"history\": \"\\n\".join(\n",
    "                        self.user_history[-5:] + self.llm_history[-5:]\n",
    "                    ),  # 최근 대화 5턴\n",
    "                    \"query\": user_query,\n",
    "                    \"preferences\": self.preferences_text,\n",
    "                    \"role_instructions\": self.config.get(\n",
    "                        \"role_instructions\", general_role\n",
    "                    ),  # 설정된 페르소나 역할 지침\n",
    "                }\n",
    "                try:\n",
    "                    decision_result = await async_invoke(\n",
    "                        self.decision_chain, prompt_vars, \"행동 결정\"\n",
    "                    )\n",
    "                    decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "                    action, additional_question_llm = (\n",
    "                        self.robust_parse_decision_response(decision_text)\n",
    "                    )\n",
    "                    # LLM이 생성한 추가 질문 사용\n",
    "                    if action == \"추가 질문\" and additional_question_llm:\n",
    "                        additional_question = additional_question_llm\n",
    "\n",
    "                except Exception as e:\n",
    "                    # LLM 호출 실패 시 안전하게 '추가 질문'으로 처리\n",
    "                    logger.error(\n",
    "                        f\"행동 결정 LLM 호출 실패: {e}. '추가 질문'으로 안전하게 진행.\",\n",
    "                        exc_info=True,\n",
    "                    )\n",
    "                    action = \"추가 질문\"\n",
    "                    additional_question = \"요청을 이해하는 데 어려움이 있었습니다. 어떤 책을 찾으시는지 다시 말씀해주시겠어요?\"\n",
    "        else:\n",
    "            # 강제 추천 모드\n",
    "            logger.info(\"강제 추천 모드 활성화. 행동='추천'\")\n",
    "            action = \"추천\"\n",
    "\n",
    "        # 4. 결정된 행동 수행\n",
    "        response = \"\"\n",
    "        if action == \"추가 질문\":\n",
    "            logger.info(\"행동: 추가 질문\")\n",
    "            self.last_action = \"추가 질문\"\n",
    "            # 반복적인 추가 질문 방지 로직\n",
    "            if additional_question:\n",
    "                try:\n",
    "                    # 추가 질문 임베딩 생성\n",
    "                    add_q_emb = await asyncio.to_thread(\n",
    "                        self.embeddings.embed_query, additional_question\n",
    "                    )\n",
    "                    # 이전 질문들과 유사도 비교\n",
    "                    if is_similar_question(\n",
    "                        add_q_emb,\n",
    "                        previous_additional_question_embeddings,\n",
    "                        threshold=0.90,\n",
    "                    ):  # 임계값 높게 설정\n",
    "                        logger.warning(\n",
    "                            \"이전과 매우 유사한 추가 질문 생성됨. 추천 강제 시도.\"\n",
    "                        )\n",
    "                        # 유사 질문 반복 시 강제로 추천 시도\n",
    "                        return await self.process_query(\n",
    "                            user_query, force_recommendation=True\n",
    "                        )\n",
    "                    else:\n",
    "                        # 새로운 질문이면 임베딩 기록 추가 (최대 5개 유지)\n",
    "                        previous_additional_question_embeddings.append(add_q_emb)\n",
    "                        if len(previous_additional_question_embeddings) > 5:\n",
    "                            previous_additional_question_embeddings.pop(0)\n",
    "                        response = additional_question  # 생성된 추가 질문 사용\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"추가 질문 임베딩 또는 유사도 비교 중 오류: {e}\")\n",
    "                    response = additional_question  # 오류 시에도 일단 질문은 반환\n",
    "\n",
    "            else:\n",
    "                # 추가 질문 내용이 없는 이상한 경우 -> 추천 시도\n",
    "                logger.warning(\"추가 질문 행동 결정되었으나 질문 내용 없음. 추천 시도.\")\n",
    "                action = \"추천\"\n",
    "\n",
    "        if action == \"추천\":\n",
    "            logger.info(\"행동: 추천\")\n",
    "            self.last_action = \"추천\"\n",
    "            # 최종 검색 쿼리 생성\n",
    "            final_query = await self.get_final_query(user_query)\n",
    "            if not final_query:\n",
    "                logger.error(\"최종 검색 쿼리 생성 실패. 추천 불가.\")\n",
    "                self.last_action = None  # 액션 상태 리셋\n",
    "                response = \"죄송합니다, 검색어를 만드는 데 실패했습니다. 다시 질문해 주시겠어요?\"\n",
    "            else:\n",
    "                # 추천 생성 함수 호출\n",
    "                recommendation_result = await self._generate_recommendations(\n",
    "                    final_query\n",
    "                )\n",
    "                response = recommendation_result\n",
    "                if (\n",
    "                    not self.last_recommendations\n",
    "                    and \"죄송합니다\" not in response\n",
    "                    and \"찾지 못했습니다\" not in response\n",
    "                ):\n",
    "                    logger.warning(\n",
    "                        \"추천 생성 과정 완료 후 self.last_recommendations가 비어있으나, 응답은 성공 메시지 형태임.\"\n",
    "                    )\n",
    "                    # 이 경우 후속 질문 처리가 불가능할 수 있음\n",
    "                    self.last_action = None  # 추천 실패로 간주하고 액션 리셋\n",
    "\n",
    "        # 5. 최종 응답 반환 및 기록\n",
    "        if response:\n",
    "            self.llm_history.append(f\"챗봇: {response}\")  # 챗봇 응답 기록\n",
    "            logger.info(\n",
    "                f\"챗봇 응답 생성 완료 (Action: {self.last_action}). 응답 일부: {response[:200]}...\"\n",
    "            )\n",
    "            return response\n",
    "        else:\n",
    "            # 응답 생성 실패 시 (로직 오류 등)\n",
    "            logger.error(f\"최종 응답 생성 실패 (Action: {action}).\")\n",
    "            self.last_action = None  # 액션 상태 리셋\n",
    "            fallback_msg = (\n",
    "                \"죄송합니다, 요청을 처리하는 중 문제가 발생했습니다. 다시 시도해주세요.\"\n",
    "            )\n",
    "            self.llm_history.append(f\"챗봇: {fallback_msg}\")\n",
    "            return fallback_msg\n",
    "\n",
    "    async def interactive_multi_turn_qa(self):\n",
    "        \"\"\"대화형 멀티턴 QA 세션 실행\"\"\"\n",
    "        # 페르소나별 시작 인사말\n",
    "        persona_greetings = {\n",
    "            \"Literature\": \"안녕하세요~ 감성적인 문학 도서 추천 챗봇입니다. 어떤 책을 찾으시나요? 당신의 이야기나 감정을 들려주셔도 좋아요.\",\n",
    "            \"Science\": \"안녕하십니까. 과학/기술 도서 전문 챗봇입니다. 관심 분야, 알고 계신 내용, 찾으시는 정보의 깊이 등을 알려주시면 더 정확한 추천을 드릴 수 있습니다.\",\n",
    "            \"General\": \"안녕하세요! 도서 추천 챗봇입니다. 어떤 종류의 책을 찾으시는지 편하게 말씀해주세요.\",\n",
    "        }\n",
    "        persona = self.config.get(\"persona\", \"General\")\n",
    "        greeting = persona_greetings.get(persona, persona_greetings[\"General\"])\n",
    "        self.llm_history.append(f\"챗봇: {greeting}\")  # 대화 기록에 추가\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"[{self.config.get('persona', '챗봇')}] {greeting}\")  # 화면 출력\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        turn_count = 0\n",
    "        while True:\n",
    "            turn_count += 1\n",
    "            print(f\"\\n--- Turn {turn_count} ---\")\n",
    "            logger.info(f\"--- Turn {turn_count} 시작 ---\")\n",
    "            # 디버깅 정보 로깅\n",
    "            logger.debug(\n",
    "                f\"Turn 시작 | last_action: {self.last_action} | last_recs: {len(self.last_recommendations)}\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # 사용자 입력 받기\n",
    "                user_query = input(\"[사용자] \").strip()\n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break  # Ctrl+C 또는 EOF 시 종료\n",
    "\n",
    "            # 종료 명령어 처리\n",
    "            if user_query.lower() in [\"quit\", \"exit\", \"종료\", \"그만\"]:\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break\n",
    "\n",
    "            # 빈 입력 무시\n",
    "            if not user_query:\n",
    "                continue\n",
    "\n",
    "            # 사용자 쿼리 처리 및 응답 생성\n",
    "            try:\n",
    "                final_answer = await self.process_query(user_query)\n",
    "            except Exception as e:\n",
    "                # 처리 중 예외 발생 시 오류 메시지 출력 및 로깅\n",
    "                logger.critical(\n",
    "                    f\"대화 처리 중 치명적 오류 발생 (Turn {turn_count}): {e}\",\n",
    "                    exc_info=True,\n",
    "                )\n",
    "                final_answer = \"죄송합니다. 요청을 처리하는 중에 예상치 못한 오류가 발생했습니다. 잠시 후 다시 시도해주세요.\"\n",
    "                # 오류 발생 시 상태 초기화 고려 (선택 사항)\n",
    "\n",
    "            # 최종 응답 출력\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"[{self.config.get('persona', '챗봇')}]\\n{final_answer}\")\n",
    "            print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 페르소나별 Pipeline 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteratureRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\"persona\": \"Literature\", \"role_instructions\": literature_role}\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )\n",
    "\n",
    "\n",
    "class ScienceRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\"persona\": \"Science\", \"role_instructions\": science_role}\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )\n",
    "\n",
    "\n",
    "class GeneralRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\"persona\": \"General\", \"role_instructions\": general_role}\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페르소나를 선택해주세요:\n",
      "1. 예술/문학 (감성적, 문학적 표현)\n",
      "2. 과학/기술 (논리적, 정확한 정보)\n",
      "3. 범용/일반 (친절, 균형잡힌 정보)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:27:43,111 - INFO - 선택된 페르소나: Literature\n",
      "2025-04-07 17:27:43,112 - INFO - --- Turn 1 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Literature' 페르소나로 대화를 시작합니다.\n",
      "대화를 종료하려면 'quit', 'exit', '종료', '그만' 중 하나를 입력하세요.\n",
      "----------------------------------------------------------------------\n",
      "[Literature] 안녕하세요~ 감성적인 문학 도서 추천 챗봇입니다. 어떤 책을 찾으시나요? 당신의 이야기나 감정을 들려주셔도 좋아요.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Turn 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:27:49,436 - INFO - === 새로운 사용자 쿼리 처리 시작: '히가시노 게이고의 추리소설 추천해줘.' ===\n",
      "2025-04-07 17:27:49,437 - INFO - 사용자 입력에서 선호도 추출 시작: '히가시노 게이고의 추리소설 추천해줘....'\n",
      "2025-04-07 17:27:51,201 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:27:51,204 - INFO - 선호도 업데이트됨 [author]: ['히가시노 게이고']\n",
      "2025-04-07 17:27:51,205 - INFO - 선호도 업데이트됨 [category]: ['추리소설']\n",
      "2025-04-07 17:27:51,205 - INFO - 선호도 업데이트됨 [implicit info]: ['유명 작가의 작품']\n",
      "2025-04-07 17:27:51,206 - INFO - 선호도 업데이트 완료. 누적 업데이트 횟수: 1\n",
      "2025-04-07 17:27:51,206 - INFO - 행동 결정 요청 (추천 vs 추가 질문)\n",
      "2025-04-07 17:27:59,626 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:27:59,628 - INFO - 행동 결정 파싱 결과: 행동='추천', 추가 질문='...'\n",
      "2025-04-07 17:27:59,629 - INFO - 행동: 추천\n",
      "2025-04-07 17:27:59,629 - INFO - 최종 검색 쿼리 생성 시작\n",
      "2025-04-07 17:28:00,447 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:00,458 - INFO - LLM 생성 쿼리 (정제 전): '히가시노 게이고 추리소설 추천'\n",
      "2025-04-07 17:28:01,173 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,182 - INFO - 정제된 쿼리: '일본 추리소설 대가 히가시노 게이고 작품 추천'\n",
      "2025-04-07 17:28:01,184 - INFO - 최종 결정된 검색 쿼리: '일본 추리소설 대가 히가시노 게이고 작품 추천'\n",
      "2025-04-07 17:28:01,185 - INFO - 추천 생성 시작. 최종 쿼리: '일본 추리소설 대가 히가시노 게이고 작품 추천'\n",
      "2025-04-07 17:28:01,191 - INFO - 일반 쿼리 검색 수행.\n",
      "2025-04-07 17:28:01,196 - INFO - 최종 리트리버 호출 시작 (쿼리: '일본 추리소설 대가 히가시노 게이고 작품 추천...')\n",
      "2025-04-07 17:28:01,277 - INFO - POST http://localhost:9200/book_bm25_index_v2/_search [status:200 duration:0.068s]\n",
      "2025-04-07 17:28:01,306 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,316 - INFO - Async 검색 결과 총 문서 수: 10\n",
      "2025-04-07 17:28:01,317 - INFO - [Async] 병합 전 입력 문서 수: 10\n",
      "2025-04-07 17:28:01,318 - INFO - [Async] ISBN 병합 그룹 수: 9\n",
      "2025-04-07 17:28:01,318 - INFO - [Async] 병합 후 최종 문서 수: 9\n",
      "2025-04-07 17:28:01,322 - INFO - 검색된 문서 수 (ISBN 병합 완료됨): 9\n",
      "2025-04-07 17:28:01,322 - INFO - 초기 및 확장 검색 후 고려할 총 고유 문서 수: 9\n",
      "2025-04-07 17:28:01,324 - INFO - 리랭킹 수행...\n",
      "2025-04-07 17:28:01,392 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,401 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,440 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,571 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,654 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,728 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,798 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,872 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:01,943 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,033 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,114 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,235 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,317 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,458 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,554 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,655 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:02,936 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:03,004 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:03,108 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:03,189 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:03,252 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:03,322 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:03,326 - INFO - 리랭킹 완료 (정규화 가중치 방식)\n",
      "2025-04-07 17:28:03,327 - INFO - 1. 제목: 추리소설가의 살인사건 | ISBN: 9791166111983 | 점수: 0.6642\n",
      "2025-04-07 17:28:03,327 - INFO - 2. 제목: 흑소 소설 | ISBN: 9788990982896 | 점수: 0.6582\n",
      "2025-04-07 17:28:03,328 - INFO - 3. 제목: 그녀는 다 계획이 있다 | ISBN: 9791136264473 | 점수: 0.5874\n",
      "2025-04-07 17:28:03,328 - INFO - 4. 제목: 아들 도키오 | ISBN: 9788934977056 | 점수: 0.5692\n",
      "2025-04-07 17:28:03,330 - INFO - 5. 제목: 고전 리뷰툰 | ISBN: 9791190812139 | 점수: 0.4592\n",
      "2025-04-07 17:28:03,332 - INFO - 6. 제목: 타인을 듣는 시간 | ISBN: 9791191187953 | 점수: 0.402\n",
      "2025-04-07 17:28:03,333 - INFO - 7. 제목: 책방으로 가다 | ISBN: 9791197779909 | 점수: 0.4012\n",
      "2025-04-07 17:28:03,334 - INFO - 8. 제목: 하루 한 편, 세상에서 가장 짧은 명작 읽기 1 | ISBN: 9791190908986 | 점수: 0.4004\n",
      "2025-04-07 17:28:03,334 - INFO - 9. 제목: 간단한 죽음 | ISBN: 9791190156264 | 점수: 0.3956\n",
      "2025-04-07 17:28:03,334 - INFO - 리랭킹 완료 (정규화 가중치 방식, metadata 이중 구조 대응).\n",
      "2025-04-07 17:28:03,335 - INFO - 최종 추천 후보 문서 수: 3\n",
      "2025-04-07 17:28:09,130 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:13,824 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:17,195 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 17:28:17,198 - INFO - '_generate_recommendations' 종료. last_recommendations 업데이트 (3개): ['추리소설가의 살인사건', '흑소 소설', '그녀는 다 계획이 있다']\n",
      "2025-04-07 17:28:17,198 - INFO - 추천 응답 생성 완료.\n",
      "2025-04-07 17:28:17,198 - INFO - 챗봇 응답 생성 완료 (Action: 추천). 응답 일부: 이런 책들은 어떠신가요? 마음에 드는 책이 있다면 더 자세히 알려드릴게요.\n",
      "\n",
      "1. \n",
      "표지: https://image.aladin.co.kr/product/25415/94/cover500/k702633114_1.jpg\n",
      "제목: 추리소설가의 살인사건\n",
      "저자: 히가시노 게이고 지음, 민경욱 옮김\n",
      "- 추천 이유: 히가시노 게이고의 블랙 코미디 추리소설집으로, ...\n",
      "2025-04-07 17:28:17,199 - INFO - --- Turn 2 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "[Literature]\n",
      "이런 책들은 어떠신가요? 마음에 드는 책이 있다면 더 자세히 알려드릴게요.\n",
      "\n",
      "1. \n",
      "표지: https://image.aladin.co.kr/product/25415/94/cover500/k702633114_1.jpg\n",
      "제목: 추리소설가의 살인사건\n",
      "저자: 히가시노 게이고 지음, 민경욱 옮김\n",
      "- 추천 이유: 히가시노 게이고의 블랙 코미디 추리소설집으로, 추리 소설가, 편집자, 독자를 주제로 한 8개의 단편으로 구성되어 있다. 작가는 자신이 '추리소설가'라는 점을 활용하여 독특한 이야기를 선보이며, 빠른 호흡과 날카로운 유머로 독자를 사로잡는다. 특히, 첫 번째 수록작인 \"세금 대책 살인사건\"은 세금 문제를 다룬 경쾌한 추리물로, 많은 독자들에게 사랑받고 있다.\n",
      "\n",
      "2. \n",
      "표지: https://image.aladin.co.kr/product/24265/94/cover500/8990982898_2.jpg\n",
      "제목: 흑소 소설\n",
      "저자: 히가시노 게이고 지음, 이혁재 옮김\n",
      "- 추천 이유: 미스터리의 제왕 히가시노 게이고가 선보인 유머 소설 시리즈 중 하나로, 흑소라는 제목처럼 웃음 속에 인간과 사회의 비합리와 부조리를 향한 섬뜩한 풍자를 담고 있다. 특히 작가는 출판계와 문단의 뒷이야기를 다루며 일본 출판계의 상업 만능 풍조를 비판하며, 이외에도 일본 사회의 다양한 문제들을 풍자와 야유를 통해 꼬집는다. 또한 각 작품 속 인물들은 웃기지만 마냥 웃을 수만은 없는 우리 자신의 모습을 비추고 있어 깊은 여운을 남긴다.\n",
      "\n",
      "3. \n",
      "표지: https://image.aladin.co.kr/product/26427/0/cover500/k182738525_1.jpg\n",
      "제목: 그녀는 다 계획이 있다\n",
      "저자: 히가시노 게이고 지음, 양윤옥 옮김\n",
      "- 추천 이유: 컴패니언 교코가 일하는 하나야 보석점 고객 감사파티 후 동료 에리가 호텔 밀실에서 살해된다. 이를 계기로 부동산회사 전무 다카미에게 접근하려는 교코는 담당 형사 시바타와 함께 에리의 과거를 파헤치며 또 다른 사건에 휘말린다.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Turn 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 17:30:29,766 - INFO - Default Milvus 연결 해제 완료.\n",
      "2025-04-07 17:30:29,766 - INFO - 프로그램 종료.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[대화 종료]\n"
     ]
    }
   ],
   "source": [
    "# --- 메인 실행 함수 ---\n",
    "nest_asyncio.apply()  # Jupyter 환경 등에서 asyncio 이벤트 루프 중첩 허용\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 이전 추가 질문 임베딩 초기화\n",
    "    previous_additional_question_embeddings.clear()\n",
    "\n",
    "    # 페르소나 선택\n",
    "    print(\"페르소나를 선택해주세요:\")\n",
    "    print(\"1. 예술/문학 (감성적, 문학적 표현)\")\n",
    "    print(\"2. 과학/기술 (논리적, 정확한 정보)\")\n",
    "    print(\"3. 범용/일반 (친절, 균형잡힌 정보)\")\n",
    "\n",
    "    pipeline = None\n",
    "    while pipeline is None:\n",
    "        choice = input(\"원하는 페르소나 번호를 입력하세요 (1, 2, 3): \").strip()\n",
    "        pipeline_map = {\n",
    "            \"1\": LiteratureRAGPipeline,\n",
    "            \"2\": ScienceRAGPipeline,\n",
    "            \"3\": GeneralRAGPipeline,\n",
    "        }\n",
    "        if choice in pipeline_map:\n",
    "            PipelineClass = pipeline_map[choice]\n",
    "            try:\n",
    "                # 선택된 페르소나 클래스로 파이프라인 인스턴스 생성\n",
    "                pipeline = PipelineClass(\n",
    "                    llm=llm_clova,\n",
    "                    embeddings=ncp_embeddings,\n",
    "                    vectorstore=vectorstore,  # Milvus\n",
    "                    es_store=es_store,  # Elasticsearch\n",
    "                    retriever=merged_hybrid_retriever,  # 최종 리트리버\n",
    "                    documents=documents,  # 전체 원본 문서 목록\n",
    "                )\n",
    "                logger.info(f\"선택된 페르소나: {pipeline.config['persona']}\")\n",
    "                print(f\"\\n'{pipeline.config['persona']}' 페르소나로 대화를 시작합니다.\")\n",
    "                print(\n",
    "                    \"대화를 종료하려면 'quit', 'exit', '종료', '그만' 중 하나를 입력하세요.\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # 파이프라인 초기화 실패 시\n",
    "                logger.critical(\n",
    "                    f\"파이프라인 초기화 중 치명적 오류 발생: {e}\", exc_info=True\n",
    "                )\n",
    "                print(\"오류: 파이프라인을 초기화할 수 없습니다. 로그를 확인하세요.\")\n",
    "                return  # 프로그램 종료\n",
    "        else:\n",
    "            print(\"잘못된 선택입니다. 1, 2, 3 중 하나를 입력해주세요.\")\n",
    "\n",
    "    # 대화형 세션 실행\n",
    "    try:\n",
    "        # 파이프라인의 interactive_multi_turn_qa 메소드를 비동기로 실행\n",
    "        asyncio.run(pipeline.interactive_multi_turn_qa())\n",
    "    except Exception as e:\n",
    "        # 메인 실행 루프에서 예외 발생 시 로깅\n",
    "        logger.critical(f\"메인 실행 루프에서 치명적 오류 발생: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        # 프로그램 종료 전 Milvus 연결 해제 시도\n",
    "        try:\n",
    "            # 기본 Milvus 연결('default')이 있다면 해제\n",
    "            if connections.get_connection_addr(\"default\"):\n",
    "                connections.disconnect(\"default\")\n",
    "                logger.info(\"Default Milvus 연결 해제 완료.\")\n",
    "        except Exception as e:\n",
    "            # 연결 해제 실패는 경고로 처리\n",
    "            logger.warning(f\"Milvus 연결 해제 중 오류 발생 (무시 가능): {e}\")\n",
    "        logger.info(\"프로그램 종료.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kill_the_RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
