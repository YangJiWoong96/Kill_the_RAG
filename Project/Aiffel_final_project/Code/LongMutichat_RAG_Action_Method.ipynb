{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "from langchain_community.chat_models import ChatClovaX\n",
    "from pymilvus import connections, utility\n",
    "from langchain_community.vectorstores.milvus import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text는 아래와 같은 형태로 들어가서 청크\n",
    "\n",
    "# 제목 : [값]\n",
    "# 분류 : [값]\n",
    "# 저자 : [값]\n",
    "# 저자소가 : [값]\n",
    "# 책 소개 : [값]\n",
    "# 목차 : [값]\n",
    "# 출판사리뷰 : [값]\n",
    "\n",
    "# 임베딩 pkl에 포함된 메타데이터 컬럼과 (임베딩,원본text)로 묶인 컬럼\n",
    "\n",
    "# metadata_columns = ['ISBN', '페이지', '가격', '제목', '저자']\n",
    "# vector_doc_columns = ['제목', '분류', '저자','저자소개', '책소개', '목차', '출판사리뷰','추천사']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가: cosine_similarity 임포트 및 추가 질문 임베딩 기록용 리스트\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "previous_additional_question_embeddings = []\n",
    "\n",
    "\n",
    "def is_similar_question(new_emb, prev_embeds, threshold=0.65):\n",
    "    if not prev_embeds:\n",
    "        return False\n",
    "    sim_scores = cosine_similarity([new_emb], prev_embeds)[0]\n",
    "    max_score = max(sim_scores)\n",
    "    print(f\"[중복 유사도 판단] Max = {max_score:.3f}\")\n",
    "    return max_score > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정 및 Milvus/임베딩 초기화\n",
    "load_dotenv(dotenv_path=r\"C:\\Kill_the_RAG\\Project\\Aiffel_final_project\\.env\")\n",
    "\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_KEY\"] = os.getenv(\"NCP_CLOVASTUDIO_API_KEY\")\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_URL\"] = os.getenv(\n",
    "    \"NCP_CLOVASTUDIO_API_URL\", \"https://clovastudio.stream.ntruss.com/\"\n",
    ")\n",
    "\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=os.getenv(\"MILVUS_HOST\", \"localhost\"),\n",
    "    port=os.getenv(\"MILVUS_PORT\", \"19530\"),\n",
    ")\n",
    "\n",
    "ncp_embeddings = ClovaXEmbeddings(model=\"bge-m3\")\n",
    "llm_clova = ChatClovaX(model=\"HCX-003\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 데이터 불러오기\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 파일 및 문서 구성\n",
    "embedding_file = r\"C:\\Kill_the_RAG\\Project\\Aiffel_final_project\\Code\\Data\\semifinal_embedding\\embedding_semifinal.pkl\"\n",
    "if os.path.exists(embedding_file):\n",
    "    with open(embedding_file, \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "    all_text_embedding_pairs = saved_data[\"embeddings\"]\n",
    "    all_metadata_list = saved_data[\"metadata\"]\n",
    "    print(\"임베딩 데이터 불러오기\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"임베딩 파일을 찾을 수 없습니다: {embedding_file}\")\n",
    "\n",
    "metadata_mapping = {\n",
    "    \"ISBN\": \"ISBN\",\n",
    "    \"페이지\": \"page\",\n",
    "    \"가격\": \"price\",\n",
    "    \"제목\": \"title\",\n",
    "    \"저자\": \"author\",\n",
    "    \"분류\": \"category\",\n",
    "    \"저자소개\": \"author_intro\",\n",
    "    \"책소개\": \"book_intro\",\n",
    "    \"목차\": \"table_of_contents\",\n",
    "    \"출판사리뷰\": \"publisher_review\",\n",
    "    \"추천사\": \"recommendation\",\n",
    "}\n",
    "\n",
    "all_metadata_list_mapped = []\n",
    "for meta in all_metadata_list:\n",
    "    mapped_meta = {metadata_mapping.get(key, key): value for key, value in meta.items()}\n",
    "    all_metadata_list_mapped.append(mapped_meta)\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=pair[0], metadata=meta)\n",
    "    for pair, meta in zip(all_text_embedding_pairs, all_metadata_list_mapped)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_39704\\1961100548.py:6: LangChainDeprecationWarning: The class `Milvus` was deprecated in LangChain 0.2.0 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-milvus package and should be used instead. To use it run `pip install -U :class:`~langchain-milvus` and import as `from :class:`~langchain_milvus import MilvusVectorStore``.\n",
      "  vectorstore = Milvus(\n"
     ]
    }
   ],
   "source": [
    "# Milvus 벡터 DB 생성\n",
    "collection_name = \"book_rag_db\"\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)\n",
    "\n",
    "vectorstore = Milvus(\n",
    "    embedding_function=ncp_embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "    auto_id=True,\n",
    ")\n",
    "\n",
    "texts = [pair[0] for pair in all_text_embedding_pairs]\n",
    "embeds = [pair[1] for pair in all_text_embedding_pairs]\n",
    "\n",
    "\n",
    "def precomputed_embed_documents(cls, input_texts):\n",
    "    if input_texts != texts:\n",
    "        raise ValueError(\n",
    "            \"ERROR : 입력 텍스트 순서가 사전 계산된 임베딩과 일치하지 않음\"\n",
    "        )\n",
    "    return embeds\n",
    "\n",
    "\n",
    "ClovaXEmbeddings.embed_documents = classmethod(precomputed_embed_documents)\n",
    "vectorstore.add_texts(\n",
    "    texts=texts, metadatas=all_metadata_list_mapped, embeddings=embeds\n",
    ")\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "dpr_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_clova, retriever=dense_retriever, return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸 함수\n",
    "def extract_field(text, field_name):\n",
    "    pattern = rf\"{re.escape(field_name)}\\s*:\\s*(.*)\"\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "\n",
    "MIN_INFO_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision_prompt_template = PromptTemplate(\n",
    "#     template=\"\"\"\n",
    "# [대화 맥락]\n",
    "# 사용자 대화 내역:\n",
    "# {{ history }}\n",
    "# 사용자의 최신 질문: \"{{ query }}\"\n",
    "\n",
    "# [역할 및 목표]\n",
    "# {{ role_instructions }}\n",
    "# 현재 대화 상황과 질문의 맥락을 분석하여 아래 중 하나의 행동을 출력해라:\n",
    "# - \"추천\": 사용자가 책 추천을 명확히 요청한 경우, 추가 정보 없이 바로 추천을 진행. & 추가 질문에서 책 추천을 원한다는 답변에 긍정적으로 응답한 경우, 바로 추천을 진행.\n",
    "# - \"추가 질문\": 책 추천을 위해 더 세부적인 선호도 정보(예: 작가, 시대, 책을 찾는 목적, 사전지식 등)가 필요하면, 구체적인 질문을 던져서 정보를 요청.\n",
    "# - 질문에 대해서 사용자가 \"모호한\", \"부정적인\" 답변을 할 경우 넘어가라.\n",
    "# - \"~~비슷한\" 이라고 사용자가 답변할 경우, 쿼리에 그대로 반영하는것이 아닌 너의 지식정보를 활용해서 특징을 쿼리로 반영하라.\n",
    "#     - 예시 : 히가시노 게이고 작가랑 비슷한 -> 미스터리, 추리 소설\n",
    "\n",
    "# [최종 출력 형식 - 반드시 아래 내용만 출력]\n",
    "# {% raw %}\n",
    "# 행동: \"{{행동 (추천/추가 질문)}}\"\n",
    "# 추천 책 정보: \"{{책 제목 및 상세 정보, 정보 충분 시; 정보 부족 시 빈 문자열}}\"\n",
    "# 추가 질문: \"{{추가 질문, 정보 보완 필요 시; 충분하면 빈 문자열}}\"\n",
    "# {% endraw %}\n",
    "# \"\"\",\n",
    "#     input_variables=[\"history\", \"query\", \"role_instructions\"],\n",
    "#     template_format=\"jinja2\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "현재 대화 상황과 질문의 맥락을 분석하여, 아래 중 하나의 행동만을 출력해라:\n",
    "- \"추천\": 사용자가 책 추천을 명확히 요청한 경우와 사용자 선호도가 충분한 경우 멀티챗 답변을 생성하지 말고 검색에 들어갈 것. \n",
    "- \"추가 질문\": 책 추천을 위해 더 세부적인 선호도 정보가 필요하면, 구체적인 추가 질문을 출력할 것. \n",
    "출력 형식 (반드시 아래 내용만 출력): \n",
    "행동: \"<추천 또는 추가 질문>\"\n",
    "추가 질문: \"<추가 질문 행동의 경우 추가 질문을, 추천 행동인 경우 빈 문자열>\"\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"role_instructions\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "final_query_generation_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "\n",
    "[페르소나 정보]\n",
    "{{ persona_info }}\n",
    "\n",
    "[사용자 선호도]\n",
    "{{ preferences }}\n",
    "\n",
    "위 정보를 바탕으로, 사용자 선호도에 포함된 모든 키워드를 반드시 반영하여, 책 추천에 유용한 최종 검색 쿼리만을 생성해라.\n",
    "출력 형식:\n",
    "쿼리: <최종 검색 쿼리>\n",
    "- 반드시 위 형식만을 사용하고, 추가 설명이나 안내 문구는 포함하지 마라.\n",
    "- \"최종 검색 쿼리\"를 질문 형태로 작성하지 않는다.\n",
    "- '추가 질문'이라는 표현은 \"최종 검색 쿼리\"에 절대 사용하지 않는다.\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 페르소나 프롬프트\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 관심 분야와 요구를 분석하여, 명확하고 구체적인 정보로 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다. 사용자의 관심사와 목적을 파악하여, 다양한 분야의 책을 적절하게 추천해라. 문학, 과학 외에도 자기계발, 역사, 에세이, 경제경영 등 모든 장르에 유연하게 대응해라.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_invoke(chain: LLMChain, vars_dict: dict, step_name: str) -> dict:\n",
    "    try:\n",
    "        print(f\"\\n[디버그] {step_name} 호출 전 변수: {vars_dict}\")\n",
    "        result = await asyncio.to_thread(chain.invoke, vars_dict)\n",
    "        print(f\"[디버그] {step_name} 결과: {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"[에러] {step_name}에서 예외 발생: {str(e)}\")\n",
    "        return {\"text\": \"\"}\n",
    "\n",
    "\n",
    "async def async_invoke_llm(prompt: str, step_name: str) -> str:\n",
    "    try:\n",
    "        print(f\"\\n[디버그] {step_name} 프롬프트 호출:\\n{prompt}\")\n",
    "        response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
    "        result_text = response.text().strip()\n",
    "        print(f\"[디버그] {step_name} 응답: {result_text}\")\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        print(f\"[에러] {step_name}에서 예외 발생: {str(e)}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunnableSequence import (공식 체인 통합 방식)\n",
    "import contextlib\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "\n",
    "\n",
    "class SummarizeFinalQueryChain:\n",
    "    async def __call__(self, input_data: dict) -> dict:\n",
    "        query = input_data.get(\"final_query\") or input_data.get(\"text\", \"\")\n",
    "        prompt = f\"다음 내용을 하나의 자연스러운 문장으로 정제해줘:\\n{query}\\n정제된 검색 쿼리:\"\n",
    "        result_text = await async_invoke_llm(prompt, \"최종 쿼리 정제\")\n",
    "        return {\"text\": result_text.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRAGPipeline:\n",
    "    def __init__(self, config, llm, retriever, qa_chain, documents):\n",
    "        self.config = config\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        self.qa_chain = qa_chain\n",
    "        self.documents = documents\n",
    "        self.query_history = []\n",
    "        self.user_preferences = defaultdict(list)\n",
    "        self.preferences_text = \"\"\n",
    "        self.decision_chain = LLMChain(llm=self.llm, prompt=decision_prompt_template)\n",
    "        self.final_query_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=final_query_generation_template\n",
    "        )\n",
    "\n",
    "    async def summarize_user_preferences(self, existing_preferences, new_input):\n",
    "        prompt = (\n",
    "            f\"다음 사용자 선호도 내용들을 하나의 자연스러운 문장으로 요약해줘:\\n\"\n",
    "            f\"기존 선호도: {existing_preferences}\\n\"\n",
    "            f\"새로운 입력: {new_input}\\n\"\n",
    "            f\"요약된 선호도:\"\n",
    "        )\n",
    "        return await async_invoke_llm(prompt, \"사용자 선호도 요약\")\n",
    "\n",
    "    async def summarize_final_query(self, query):\n",
    "        prompt = (\n",
    "            f\"다음 내용을 하나의 자연스러운 문장으로 정제해줘:\\n\"\n",
    "            f\"{query}\\n\"\n",
    "            f\"정제된 검색 쿼리:\"\n",
    "        )\n",
    "        return await async_invoke_llm(prompt, \"최종 쿼리 정제\")\n",
    "\n",
    "    def robust_parse_decision_response(self, response_text):\n",
    "        action_match = re.search(r\"행동\\s*[:：]\\s*\\\"?([^\\\"\\n]+)\\\"?\", response_text)\n",
    "        action = action_match.group(1).strip() if action_match else None\n",
    "\n",
    "        book_info_match = re.search(\n",
    "            r\"추천\\s*책\\s*정보\\s*[:：]\\s*\\\"?([^\\\"\\n]+)\\\"?\", response_text\n",
    "        )\n",
    "        book_info = book_info_match.group(1).strip() if book_info_match else \"\"\n",
    "\n",
    "        follow_match = re.search(\n",
    "            r\"추가\\s*질문\\s*[:：]\\s*\\\"?([^\\\"\\n]+)\\\"?\", response_text\n",
    "        )\n",
    "        additional_question = follow_match.group(1).strip() if follow_match else \"\"\n",
    "        return action, book_info, additional_question\n",
    "\n",
    "    async def get_final_query(self, final_query_vars):\n",
    "        composite_final_chain = RunnableSequence(\n",
    "            *[self.final_query_generation_chain, SummarizeFinalQueryChain()]\n",
    "        )\n",
    "        composite_result = await composite_final_chain.ainvoke(final_query_vars)\n",
    "        final_query = composite_result.get(\"text\", \"\").strip()\n",
    "        return final_query\n",
    "\n",
    "    async def generate_answer(self, query):\n",
    "        author_match = re.search(r\"(?:저자|작가)\\s*[:：]\\s*(\\S+)\", query)\n",
    "        if author_match:\n",
    "            author_name = author_match.group(1).strip().lower()\n",
    "            dense_results = self.qa_chain.invoke(query)[\"source_documents\"]\n",
    "            keyword_results = [\n",
    "                doc\n",
    "                for doc in self.documents\n",
    "                if doc.metadata.get(\"author\", \"\").strip().lower() == author_name\n",
    "            ]\n",
    "            source_docs = list(\n",
    "                {\n",
    "                    doc.metadata.get(\"ISBN\"): doc\n",
    "                    for doc in (dense_results + keyword_results)\n",
    "                    if doc.metadata.get(\"ISBN\")\n",
    "                }.values()\n",
    "            )\n",
    "        else:\n",
    "            result = self.qa_chain.invoke(query)\n",
    "            source_docs = result[\"source_documents\"]\n",
    "\n",
    "        retrieved_isbns = set()\n",
    "        for doc in source_docs:\n",
    "            isbn = doc.metadata.get(\"ISBN\")\n",
    "            if isbn:\n",
    "                retrieved_isbns.add(isbn)\n",
    "\n",
    "        aggregated_docs = []\n",
    "        for isbn in retrieved_isbns:\n",
    "            book_docs = [\n",
    "                doc for doc in self.documents if doc.metadata.get(\"ISBN\") == isbn\n",
    "            ]\n",
    "            if not book_docs:\n",
    "                continue\n",
    "            aggregated_text = \"\\n\".join([doc.page_content for doc in book_docs])\n",
    "            aggregated_docs.append(\n",
    "                Document(page_content=aggregated_text, metadata=book_docs[0].metadata)\n",
    "            )\n",
    "\n",
    "        formatted_answers = []\n",
    "        for doc in aggregated_docs:\n",
    "            metadata = doc.metadata\n",
    "            title = metadata.get(\"title\") or extract_field(doc.page_content, \"제목\")\n",
    "            author = metadata.get(\"author\") or extract_field(doc.page_content, \"저자\")\n",
    "            aggregated_text = doc.page_content\n",
    "            book_intro = extract_field(aggregated_text, \"책소개\")\n",
    "            publisher_review = extract_field(aggregated_text, \"출판사리뷰\")\n",
    "            recommendation_field = extract_field(aggregated_text, \"추천사\")\n",
    "\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "                selected_info = book_intro\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "                selected_info = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "                selected_info = recommendation_field\n",
    "            else:\n",
    "                selected_info = \"\"\n",
    "\n",
    "            if not selected_info:\n",
    "                reason = \"추천 정보 생성 불가\"\n",
    "            else:\n",
    "                reason_prompt = (\n",
    "                    f\"다음 정보와 <최종 검색 쿼리>를 참고하여, 이 책이 추천되는 이유를 100글자 이내로 명확하게 요약해라.\"\n",
    "                    f\"책의 주요 특징과 강점을 설명해라.\\n\\n정보:\\n{selected_info}\"\n",
    "                )\n",
    "                generated_reason = await async_invoke_llm(\n",
    "                    reason_prompt, \"추천 이유 생성\"\n",
    "                )\n",
    "                if (\n",
    "                    not generated_reason\n",
    "                    or len(generated_reason) < 10\n",
    "                    or \"추천 정보 생성 불가\" in generated_reason\n",
    "                ):\n",
    "                    reason = \"추천 정보 생성 불가\"\n",
    "                else:\n",
    "                    reason = generated_reason\n",
    "\n",
    "            formatted = f\"책 제목: {title}\\n저자: {author}\\n추천 이유: {reason}\"\n",
    "            formatted_answers.append(formatted)\n",
    "\n",
    "        answer = \"\\n\\n\".join(formatted_answers)\n",
    "        refined_answer = await async_invoke_llm(\n",
    "            f\"아래 원본 추천 결과를 읽고, 각 책의 정보를 다음 형식에 맞춰 재작성해라.\\n\\n형식:\\n책 제목: <책 제목>\\n저자: <저자>\\n추천 이유: <추천 이유>\\n\\n원본 추천 결과:\\n{answer}\\n\\n출력 시, 반드시 위 형식만을 사용하고 불필요한 안내 문구는 포함하지 말아라.\",\n",
    "            \"추천 결과 재정제\",\n",
    "        )\n",
    "        return refined_answer, None\n",
    "\n",
    "    def print_chat_history(self):\n",
    "        print(\"-\" * 50)\n",
    "        # 최근 4개 발화만 출력\n",
    "        for line in self.query_history[-4:]:\n",
    "            if line.startswith(\"사용자:\"):\n",
    "                print(f\"[사용자] {line.split(':', 1)[1].strip()}\")\n",
    "            elif line.startswith(\"챗봇:\"):\n",
    "                print(f\"[챗봇] {line.split(':', 1)[1].strip()}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    async def search_and_generate_answer(self, user_query, force_recommendation=False):\n",
    "        self.preferences_text = \" \".join(self.user_preferences[\"preferences\"])\n",
    "        query_summary = \"\\n\".join(self.query_history[-5:])\n",
    "\n",
    "        if self.config.get(\"persona\") == \"Literature\":\n",
    "            persona_info = \"감성, 현재 기분, 선호하는 문학 장르 및 작가 정보\"\n",
    "        elif self.config.get(\"persona\") == \"Science\":\n",
    "            persona_info = \"초심자 여부, 관심 분야, 구체적인 기술 정보\"\n",
    "        elif self.config.get(\"persona\") == \"General\":\n",
    "            persona_info = \"장르, 책을 찾는 이유, 독서 취향 정보\"\n",
    "        else:\n",
    "            persona_info = \"\"\n",
    "\n",
    "        if force_recommendation:\n",
    "            action = \"추천\"\n",
    "            print(\"[디버그] force_recommendation 적용: 추천 행동으로 전환합니다.\")\n",
    "        else:\n",
    "            prompt_vars = {\n",
    "                \"history\": query_summary,\n",
    "                \"query\": user_query,\n",
    "                \"role_instructions\": self.config[\"role_instructions\"],\n",
    "            }\n",
    "            decision_result = await async_invoke(\n",
    "                self.decision_chain, prompt_vars, \"행동 결정\"\n",
    "            )\n",
    "            decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "            print(f\"\\n[디버그] Decision 응답: {decision_text}\")\n",
    "            action, _, additional_question = self.robust_parse_decision_response(\n",
    "                decision_text\n",
    "            )\n",
    "            print(f\"[디버그] 행동: {action}\")\n",
    "\n",
    "        if action == \"추가 질문\":\n",
    "            try:\n",
    "                add_q_emb = ncp_embeddings.embed_query(additional_question)\n",
    "            except Exception as e:\n",
    "                print(f\"[에러] 추가 질문 임베딩 생성 중 문제 발생: {str(e)}\")\n",
    "                add_q_emb = None\n",
    "            if add_q_emb is not None and is_similar_question(\n",
    "                add_q_emb, previous_additional_question_embeddings\n",
    "            ):\n",
    "                print(\"[정보] 동일 추가 질문이 재입력되어 추천 행동으로 전환합니다.\")\n",
    "                return await self.search_and_generate_answer(\n",
    "                    user_query, force_recommendation=True\n",
    "                )\n",
    "            else:\n",
    "                if add_q_emb is not None:\n",
    "                    previous_additional_question_embeddings.append(add_q_emb)\n",
    "\n",
    "            # 중복 삽입 방지 로직 (챗봇 발화)\n",
    "            if not (\n",
    "                self.query_history\n",
    "                and self.query_history[-1] == f\"챗봇: {additional_question}\"\n",
    "            ):\n",
    "                self.query_history.append(f\"챗봇: {additional_question}\")\n",
    "\n",
    "            self.print_chat_history()\n",
    "            raw_user_input = input(\"[사용자] \")\n",
    "\n",
    "            # 중복 삽입 방지 로직 (사용자 발화)\n",
    "            if not (\n",
    "                self.query_history\n",
    "                and self.query_history[-1] == f\"사용자: {raw_user_input}\"\n",
    "            ):\n",
    "                self.query_history.append(f\"사용자: {raw_user_input}\")\n",
    "\n",
    "            if self.preferences_text:\n",
    "                updated_pref = await self.summarize_user_preferences(\n",
    "                    self.preferences_text, raw_user_input\n",
    "                )\n",
    "            else:\n",
    "                updated_pref = raw_user_input\n",
    "            self.preferences_text = updated_pref\n",
    "            print(f\"\\n[디버그] 업데이트된 사용자 선호도: {self.preferences_text}\")\n",
    "\n",
    "            updated_prompt_vars = {\n",
    "                \"history\": \"\\n\".join(self.query_history[-5:]),\n",
    "                \"query\": user_query,\n",
    "                \"role_instructions\": self.config[\"role_instructions\"],\n",
    "            }\n",
    "            if len(self.preferences_text.split()) >= 10:\n",
    "                print(\"[디버그] 충분한 선호도가 수집되어 추천으로 전환합니다.\")\n",
    "                action = \"추천\"\n",
    "            else:\n",
    "                decision_result = await async_invoke(\n",
    "                    self.decision_chain, updated_prompt_vars, \"재결정\"\n",
    "                )\n",
    "                decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "                print(f\"\\n[디버그] 재결정 응답: {decision_text}\")\n",
    "                action, _, additional_question = self.robust_parse_decision_response(\n",
    "                    decision_text\n",
    "                )\n",
    "                print(f\"[디버그] 재결정 행동: {action}\")\n",
    "\n",
    "            if action == \"추가 질문\":\n",
    "                # 중복 삽입 방지 로직 (챗봇 발화)\n",
    "                if not (\n",
    "                    self.query_history\n",
    "                    and self.query_history[-1] == f\"챗봇: {additional_question}\"\n",
    "                ):\n",
    "                    self.query_history.append(f\"챗봇: {additional_question}\")\n",
    "                return additional_question\n",
    "\n",
    "            elif action == \"추천\":\n",
    "                final_query_vars = {\n",
    "                    \"history\": updated_prompt_vars[\"history\"],\n",
    "                    \"query\": user_query,\n",
    "                    \"persona_info\": persona_info,\n",
    "                    \"preferences\": self.preferences_text,\n",
    "                }\n",
    "                final_query = await self.get_final_query(final_query_vars)\n",
    "\n",
    "        elif action == \"추천\":\n",
    "            final_query_vars = {\n",
    "                \"history\": query_summary,\n",
    "                \"query\": user_query,\n",
    "                \"persona_info\": persona_info,\n",
    "                \"preferences\": self.preferences_text,\n",
    "            }\n",
    "            final_query = await self.get_final_query(final_query_vars)\n",
    "\n",
    "        else:\n",
    "            final_query_vars = {\n",
    "                \"history\": query_summary,\n",
    "                \"query\": user_query,\n",
    "                \"persona_info\": persona_info,\n",
    "                \"preferences\": self.preferences_text,\n",
    "            }\n",
    "            final_query = await self.get_final_query(final_query_vars)\n",
    "\n",
    "        print(f\"\\n[디버그] 최종 검색 쿼리: {final_query}\")\n",
    "        answer, _ = await self.generate_answer(final_query)\n",
    "        return answer\n",
    "\n",
    "    async def interactive_multi_turn_qa(self):\n",
    "        self.print_chat_history()\n",
    "        while True:\n",
    "            user_query = input(\"[사용자] \")\n",
    "            if user_query.lower() == \"quit\":\n",
    "                print(\"\\n[대화 저장 중...]\")\n",
    "                print(\"대화 저장 완료\")\n",
    "                import sys\n",
    "\n",
    "                sys.exit()\n",
    "\n",
    "            # 중복 삽입 방지 로직 (사용자 발화)\n",
    "            if not (\n",
    "                self.query_history and self.query_history[-1] == f\"사용자: {user_query}\"\n",
    "            ):\n",
    "                self.query_history.append(f\"사용자: {user_query}\")\n",
    "\n",
    "            answer = await self.search_and_generate_answer(user_query)\n",
    "            if answer is not None:\n",
    "                # 중복 삽입 방지 로직 (챗봇 발화)\n",
    "                if not (\n",
    "                    self.query_history and self.query_history[-1] == f\"챗봇: {answer}\"\n",
    "                ):\n",
    "                    self.query_history.append(f\"챗봇: {answer}\")\n",
    "\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"[사용자] {user_query}\")\n",
    "                print(f\"[챗봇] {answer}\")\n",
    "                print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페르소나별 파이프라인 클래스\n",
    "class LiteratureRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents):\n",
    "        config = {\"persona\": \"Literature\", \"role_instructions\": literature_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents)\n",
    "\n",
    "\n",
    "class ScienceRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents):\n",
    "        config = {\"persona\": \"Science\", \"role_instructions\": science_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents)\n",
    "\n",
    "\n",
    "class GeneralRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents):\n",
    "        config = {\"persona\": \"General\", \"role_instructions\": general_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페르소나 선택:\n",
      "1. 예술/문학\n",
      "2. 과학/기술\n",
      "3. 범용/일반\n",
      "--------------------------------------------------\n",
      "[챗봇] 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 행동 결정 호출 전 변수: {'history': '챗봇: 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\\n사용자: 오늘 너무 심심해.', 'query': '오늘 너무 심심해.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.'}\n",
      "[디버그] 행동 결정 결과: {'history': '챗봇: 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\\n사용자: 오늘 너무 심심해.', 'query': '오늘 너무 심심해.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.', 'text': '행동: \"추가 질문\"\\n추가 질문: 심심하실 때 주로 읽으시는 장르나 분위기를 알려주시면 그에 맞는 책을 추천해드릴게요!'}\n",
      "\n",
      "[디버그] Decision 응답: 행동: \"추가 질문\"\n",
      "추가 질문: 심심하실 때 주로 읽으시는 장르나 분위기를 알려주시면 그에 맞는 책을 추천해드릴게요!\n",
      "[디버그] 행동: 추가 질문\n",
      "--------------------------------------------------\n",
      "[챗봇] 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\n",
      "[사용자] 오늘 너무 심심해.\n",
      "[챗봇] 심심하실 때 주로 읽으시는 장르나 분위기를 알려주시면 그에 맞는 책을 추천해드릴게요!\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 업데이트된 사용자 선호도: 스릴러 추천해줘.\n",
      "\n",
      "[디버그] 재결정 호출 전 변수: {'history': '챗봇: 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\\n사용자: 오늘 너무 심심해.\\n챗봇: 심심하실 때 주로 읽으시는 장르나 분위기를 알려주시면 그에 맞는 책을 추천해드릴게요!\\n사용자: 스릴러 추천해줘.', 'query': '오늘 너무 심심해.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.'}\n",
      "[디버그] 재결정 결과: {'history': '챗봇: 안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\\n사용자: 오늘 너무 심심해.\\n챗봇: 심심하실 때 주로 읽으시는 장르나 분위기를 알려주시면 그에 맞는 책을 추천해드릴게요!\\n사용자: 스릴러 추천해줘.', 'query': '오늘 너무 심심해.', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.', 'text': '행동: \"추천\"'}\n",
      "\n",
      "[디버그] 재결정 응답: 행동: \"추천\"\n",
      "[디버그] 재결정 행동: 추천\n",
      "\n",
      "[디버그] 최종 쿼리 정제 프롬프트 호출:\n",
      "다음 내용을 하나의 자연스러운 문장으로 정제해줘:\n",
      "쿼리 : 스릴러 소설 추천\n",
      "정제된 검색 쿼리:\n",
      "[디버그] 최종 쿼리 정제 응답: 스릴러 장르의 소설 추천해주세요.\n",
      "\n",
      "[디버그] 최종 검색 쿼리: 스릴러 장르의 소설 추천해주세요.\n",
      "\n",
      "[디버그] 추천 이유 생성 프롬프트 호출:\n",
      "다음 정보와 <최종 검색 쿼리>를 참고하여, 이 책이 추천되는 이유를 100글자 이내로 명확하게 요약해라.책의 주요 특징과 강점을 설명해라.\n",
      "\n",
      "정보:\n",
      "데뷔작 『초크맨』이 원고 공개 2주 만에 26개국에 판매되고 장르소설 대가들의 극찬을 받으며 스릴러계의 ‘괴물 신인’으로 떠오른 작가 C. J. 튜더의 의 세 번째 작품이다. 전작 『초크맨』과 『애니가 돌아왔다』가 과거와 현재를 넘나드는 구성과 신선한 소재로 독자들의 이목을 사로잡았다면 『디 아더 피플』은 강렬한 도입부와 씨줄과 날줄을 촘촘히 엮어놓은 듯한 탄탄한 구성으로 찬사를 받았다. 게이브는 월요일 저녁 퇴근 시간, 차를 몰고 집으로 돌아가던 길에 차량 정체로 고속도로 위에서 꼼짝 없이 발이 묶인다. 이때 그의 바로 앞에서 꾸물꾸물 기어가던 차의 뒤 유리창 너머로 여자아이의 얼굴이 나타난다. 여자아이가 입 모양으로 “아빠!”라고 말하는 게 보인다. 그의 다섯 살 난 딸 이지였다. 그런데 경찰이 게이브에게 전화를 걸어 아내와 딸이 ‘집에서’ 살해당했다는 뜻밖의 소식을 전한다. 그로부터 3년 뒤, 딸의 시신을 확인하고 장례까지 치렀지만 게이브는 딸이 살아 있다는 희망을 포기하지 않는다. 캠핑용 밴에서 숙식을 해결하고, 고속도로를 달리며 딸을 납치해간 차량을 밤낮으로 찾는 생활을 계속한다. 그러던 도중, 호수에 버려진 3년 전 그 차를 찾아낸다. 하다못해 아이의 시신이라도 발견할 수 있지 않을까 하는 마음으로 차 안을 살펴보는데, 그 안에서 발견된 건 신원미상의 남성 시신과, ‘디 아더 피플’이라고 적힌 수첩이었다. 다크 웹에서 음성적으로 운영되며, 요청한 의뢰가 실행되면 반드시 신세를 갚아야 하는 대리 복수 조직 ‘디 아더 피플’. 게이브는 몇 번의 시도 끝에 디 아더 피플 사이트에 접속하는 데 성공하고, 자신에게 일어난 많은 일들, 곁에 있는 많은 사람들이 디 아더 피플과 연관되어 있다는 충격적인 사실을 알게 된다.\n",
      "[디버그] 추천 이유 생성 응답: 과거와 현재를 넘나드는 구성과 독특한 소재로 인기를 끈 작가 C.J. 튜더의 신작으로, 강렬한 도입부와 탄탄한 구성이 돋보이는 작품이다. 가족을 잃은 남자가 범인을 추적하며 마주하는 진실을 그리고 있으며, 스릴 넘치는 전개와 예상치 못한 결말이 인상적이다.\n",
      "\n",
      "[디버그] 추천 이유 생성 프롬프트 호출:\n",
      "다음 정보와 <최종 검색 쿼리>를 참고하여, 이 책이 추천되는 이유를 100글자 이내로 명확하게 요약해라.책의 주요 특징과 강점을 설명해라.\n",
      "\n",
      "정보:\n",
      "악마들의 눈동자에는 거짓과 사악함이 비쳤고, 그녀의 눈동자에는 슬픔과 의지가 어려 있었으며, 나의 눈동자에는 그녀가 있었다. . . 평온하지만 재미없는 삶을 살고 있던 세인. 그러던 그에게 어느 날 갑자기 경찰에게 전화 한 통이 걸려 온다. 7년 만에 들은 그 이름 ‘카즈미 사와다.’ 마음속 깊이 묻어 뒀던 그녀가 쪽지 한 장만을 남기고 실종됐다. 쪽지에 쓰인 내용은 단 두 단어. ‘세인, 마할로.’ 이 쪽지가 의미하는 것은 무엇일까? 세인은 이 쪽지의 의미를 알 것 같았다. 아니 알았다. 7년 전, 하와이에서의 마지막 날 밤에 일어난 그 일과 관련이 있음을…. 그런데 앞이 보이지 않는다. 어딘 가에 묶인 채 앞을 볼 수도, 소리를 낼 수도 없다. 머리 위로 똑똑 떨어지는 물방울이 세인의 생각도 똑 하고 끊어 버린다. 세인, 카즈미에게 무슨 일이 일어난 것일까. 7년 전 그날, 하와이에서 어떤 일이 있었던 걸까….\n",
      "[디버그] 추천 이유 생성 응답: <최종 검색 쿼리>: 추리소설 추천, 반전 있는 소설 추천\n",
      "- 납치당한 주인공이 범인을 추적하는 이야기로 긴장감 넘치는 전개와 예상치 못한 반전이 인상적이다. \n",
      "- 인물들의 감정 묘사가 섬세하며, 스토리 구성이 탄탄해 추리소설을 좋아하는 독자들에게 추천한다.\n",
      "\n",
      "[디버그] 추천 이유 생성 프롬프트 호출:\n",
      "다음 정보와 <최종 검색 쿼리>를 참고하여, 이 책이 추천되는 이유를 100글자 이내로 명확하게 요약해라.책의 주요 특징과 강점을 설명해라.\n",
      "\n",
      "정보:\n",
      "기이하고도 놀라운 피터 스완슨의 세계에 오신 것을 환영합니다! 보스턴의 한 추리소설 전문 서점을 운영하며 하루하루 성실히 살아가고 있는 맬컴 커쇼. 어느 날 FBI 요원이 그를 찾아와 ‘당신이 몇 년 전 서점 블로그에 올린 포스팅을 기억하는가’라고 질문한다. 지금까지 발표된 범죄소설 가운데 가장 똑똑하고 독창적이면서 실패할 확률이 없는 살인을 저지른 여덟 작품을 모아놓은 포스팅인데, 누군가 이를 따라 범죄를 저지르고 있다는 것이다. 만약 그 책들에 나오는 살인 방법을 성공적으로 모방했다면 범인은 결코 잡히지 않을 것이다. 처음에는 낯모르는 이들이 살해당했으나 곧 그의 타깃에 서점 단골손님도 포함되고, 어쩌면 커쇼의 아내의 죽음과도 연관이 있는 것 같다. 살인자의 손길은 치밀하고도 지능적으로 점점 커쇼를 향해 다가오는데…. 범인은 대체 누구이며 왜 이런 일을 저지르는 것일까? “메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가 ([퍼블리셔스 위클리])”라는 극찬과 함께 단숨에 길리언 플린과 같은 스릴러 소설계 신예 거장 반열에 오른 피터 스완슨. 국내 독자 10만 명을 만족시킨 전작 『죽여 마땅한 사람들』 등 흡입력 있는 스릴러 작품을 주로 선보이던 그가 이번에는 탄탄한 구성과 짜임새 높은 촘촘한 전개로 전작과 또 다른 맛을 선보인다. 범인과 주인공의 쫓고 쫓기는 추리, 주인공의 유려한 심리 묘사, 곳곳에서 하나둘 새어나오는 놀라운 진실과 배신, 예상을 뒤엎는 기이한 반전들이 주는 서늘함은 스릴러 소설 독자들을 매료시키기에 충분하다.\n",
      "[디버그] 추천 이유 생성 응답: <최종 검색 쿼리>: 피터 스완슨 신작 도서 추천 이유\n",
      "\n",
      "추천 이유: 메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가인 피터 스완슨의 신작도서로, 뛰어난 심리묘사와 치밀한 전개, 서늘한 반전이 매력적인 스릴러 소설이기 때문입니다.\n",
      "\n",
      "[디버그] 추천 결과 재정제 프롬프트 호출:\n",
      "아래 원본 추천 결과를 읽고, 각 책의 정보를 다음 형식에 맞춰 재작성해라.\n",
      "\n",
      "형식:\n",
      "책 제목: <책 제목>\n",
      "저자: <저자>\n",
      "추천 이유: <추천 이유>\n",
      "\n",
      "원본 추천 결과:\n",
      "책 제목: 리더스원 디 아더 피플\n",
      "저자: C.J.튜더 지음, 이은선 옮김\n",
      "추천 이유: 과거와 현재를 넘나드는 구성과 독특한 소재로 인기를 끈 작가 C.J. 튜더의 신작으로, 강렬한 도입부와 탄탄한 구성이 돋보이는 작품이다. 가족을 잃은 남자가 범인을 추적하며 마주하는 진실을 그리고 있으며, 스릴 넘치는 전개와 예상치 못한 결말이 인상적이다.\n",
      "\n",
      "책 제목: 레인보우 스테이트 살인사건\n",
      "저자: 윤민채 지음\n",
      "추천 이유: <최종 검색 쿼리>: 추리소설 추천, 반전 있는 소설 추천\n",
      "- 납치당한 주인공이 범인을 추적하는 이야기로 긴장감 넘치는 전개와 예상치 못한 반전이 인상적이다. \n",
      "- 인물들의 감정 묘사가 섬세하며, 스토리 구성이 탄탄해 추리소설을 좋아하는 독자들에게 추천한다.\n",
      "\n",
      "책 제목: 여덟 건의 완벽한 살인\n",
      "저자: 피터 스완슨 저/노진선 역 지음\n",
      "추천 이유: <최종 검색 쿼리>: 피터 스완슨 신작 도서 추천 이유\n",
      "\n",
      "추천 이유: 메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가인 피터 스완슨의 신작도서로, 뛰어난 심리묘사와 치밀한 전개, 서늘한 반전이 매력적인 스릴러 소설이기 때문입니다.\n",
      "\n",
      "출력 시, 반드시 위 형식만을 사용하고 불필요한 안내 문구는 포함하지 말아라.\n",
      "[디버그] 추천 결과 재정제 응답: 책 제목: 디 아더 피플\n",
      "저자: C.J.튜더 지음, 이은선 옮김\n",
      "추천 이유: 과거와 현재를 넘나드는 구성과 독특한 소재로 인기를 끈 작가 C.J. 튜더의 신작으로, 강렬한 도입부와 탄탄한 구성이 돋보인다. 가족을 잃은 남자가 범인을 추적하며 마주하는 진실을 그리고 있으며, 스릴 넘치는 전개와 예상치 못한 결말이 인상적이다.\n",
      "\n",
      "책 제목: 레인보우 스테이트 살인사건\n",
      "저자: 윤민채 지음\n",
      "추천 이유: 납치당한 주인공이 범인을 추적하는 이야기로 긴장감 넘치는 전개와 예상치 못한 반전이 인상적이며, 인물들의 감정 묘사가 섬세하다. 또한 스토리 구성이 탄탄해 추리소설을 좋아하는 독자들에게 추천한다.\n",
      "\n",
      "책 제목: 여덟 건의 완벽한 살인\n",
      "저자: 피터 스완슨 저/노진선 역 지음\n",
      "추천 이유: 메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가인 피터 스완슨의 신작도서로, 뛰어난 심리묘사와 치밀한 전개, 서늘한 반전이 매력적인 스릴러 소설이다.\n",
      "--------------------------------------------------\n",
      "[사용자] 오늘 너무 심심해.\n",
      "[챗봇] 책 제목: 디 아더 피플\n",
      "저자: C.J.튜더 지음, 이은선 옮김\n",
      "추천 이유: 과거와 현재를 넘나드는 구성과 독특한 소재로 인기를 끈 작가 C.J. 튜더의 신작으로, 강렬한 도입부와 탄탄한 구성이 돋보인다. 가족을 잃은 남자가 범인을 추적하며 마주하는 진실을 그리고 있으며, 스릴 넘치는 전개와 예상치 못한 결말이 인상적이다.\n",
      "\n",
      "책 제목: 레인보우 스테이트 살인사건\n",
      "저자: 윤민채 지음\n",
      "추천 이유: 납치당한 주인공이 범인을 추적하는 이야기로 긴장감 넘치는 전개와 예상치 못한 반전이 인상적이며, 인물들의 감정 묘사가 섬세하다. 또한 스토리 구성이 탄탄해 추리소설을 좋아하는 독자들에게 추천한다.\n",
      "\n",
      "책 제목: 여덟 건의 완벽한 살인\n",
      "저자: 피터 스완슨 저/노진선 역 지음\n",
      "추천 이유: 메스처럼 예리한 문체로 냉정한 악의 본질을 탐구하는 작가인 피터 스완슨의 신작도서로, 뛰어난 심리묘사와 치밀한 전개, 서늘한 반전이 매력적인 스릴러 소설이다.\n",
      "--------------------------------------------------\n",
      "\n",
      "[대화 저장 중...]\n",
      "대화 저장 완료\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def main():\n",
    "    previous_additional_question_embeddings.clear()\n",
    "    print(\"페르소나 선택:\")\n",
    "    print(\"1. 예술/문학\")\n",
    "    print(\"2. 과학/기술\")\n",
    "    print(\"3. 범용/일반\")\n",
    "    choice = input(\"원하는 페르소나 번호를 입력하세요 (1 또는 2): \").strip()\n",
    "    if choice == \"1\":\n",
    "        pipeline = LiteratureRAGPipeline(\n",
    "            llm_clova, dense_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "        greeting = \"안녕하세요~ 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 추천해드릴까요?\"\n",
    "    elif choice == \"2\":\n",
    "        pipeline = ScienceRAGPipeline(\n",
    "            llm_clova, dense_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "        greeting = \"안녕하십니까. 정확하고 논리적인 과학/기술 도서 추천 챗봇입니다. 관심 있는 기술 분야에 대해 편하게 이야기해 주세요.\"\n",
    "    elif choice == \"3\":\n",
    "        pipeline = GeneralRAGPipeline(\n",
    "            llm_clova, dense_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "        greeting = \"안녕하세요! 범용/일반 도서 추천 챗봇입니다. 관심 있는 분야에 대해 편하게 이야기해 주세요.\"\n",
    "    else:\n",
    "        print(\"잘못된 선택입니다. 기본 예술/문학 페르소나로 실행합니다.\")\n",
    "        pipeline = GeneralRAGPipeline(\n",
    "            llm_clova, dense_retriever, dpr_qa_chain, documents\n",
    "        )\n",
    "        greeting = \"안녕하세요! 범용/일반 도서 추천 챗봇입니다. 관심 있는 분야에 대해 편하게 이야기해 주세요.\"\n",
    "\n",
    "    # 첫 챗봇 발화도 중복 기록 방지\n",
    "    if not (\n",
    "        pipeline.query_history and pipeline.query_history[-1] == f\"챗봇: {greeting}\"\n",
    "    ):\n",
    "        pipeline.query_history.append(f\"챗봇: {greeting}\")\n",
    "\n",
    "    asyncio.run(pipeline.interactive_multi_turn_qa())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"코딩 관련 책?\"\n",
    "# vectorstore.similarity_search(query, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kill_the_RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
