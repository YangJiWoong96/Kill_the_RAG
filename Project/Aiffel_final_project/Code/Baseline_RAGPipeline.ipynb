{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "from langchain_community.chat_models import ChatClovaX\n",
    "from pymilvus import connections, utility\n",
    "from langchain_community.vectorstores.milvus import Milvus\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정 및 Milvus/임베딩 초기화\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Kill_the_RAG\\Project\\Aiffel_final_project\\.env\")\n",
    "\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_KEY\"] = os.getenv(\"NCP_CLOVASTUDIO_API_KEY\")\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_URL\"] = os.getenv(\n",
    "    \"NCP_CLOVASTUDIO_API_URL\", \"https://clovastudio.stream.ntruss.com/\"\n",
    ")\n",
    "\n",
    "connections.connect(\n",
    "    alias=\"default\",\n",
    "    host=os.getenv(\"MILVUS_HOST\", \"localhost\"),\n",
    "    port=os.getenv(\"MILVUS_PORT\", \"19530\"),\n",
    ")\n",
    "\n",
    "ncp_embeddings = ClovaXEmbeddings(model=\"bge-m3\")\n",
    "llm_clova = ChatClovaX(model=\"HCX-003\", max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 데이터 불러오기\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 파일 및 문서 구성\n",
    "\n",
    "embedding_file = r\"C:\\Kill_the_RAG\\Project\\Aiffel_final_project\\Code\\Data\\semifinal_embedding\\embedding_semifinal.pkl\"\n",
    "if os.path.exists(embedding_file):\n",
    "    with open(embedding_file, \"rb\") as f:\n",
    "        saved_data = pickle.load(f)\n",
    "    all_text_embedding_pairs = saved_data[\"embeddings\"]\n",
    "    all_metadata_list = saved_data[\"metadata\"]\n",
    "    print(\"임베딩 데이터 불러오기\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"임베딩 파일을 찾을 수 없습니다: {embedding_file}\")\n",
    "\n",
    "metadata_mapping = {\n",
    "    \"ISBN\": \"ISBN\",\n",
    "    \"페이지\": \"page\",\n",
    "    \"가격\": \"price\",\n",
    "    \"제목\": \"title\",\n",
    "    \"저자\": \"author\",\n",
    "    \"분류\": \"category\",\n",
    "    \"저자소개\": \"author_intro\",\n",
    "    \"책소개\": \"book_intro\",\n",
    "    \"목차\": \"table_of_contents\",\n",
    "    \"출판사리뷰\": \"publisher_review\",\n",
    "    \"추천사\": \"recommendation\",\n",
    "}\n",
    "\n",
    "all_metadata_list_mapped = []\n",
    "for meta in all_metadata_list:\n",
    "    mapped_meta = {metadata_mapping.get(key, key): value for key, value in meta.items()}\n",
    "    all_metadata_list_mapped.append(mapped_meta)\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=pair[0], metadata=meta)\n",
    "    for pair, meta in zip(all_text_embedding_pairs, all_metadata_list_mapped)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_25152\\1961100548.py:6: LangChainDeprecationWarning: The class `Milvus` was deprecated in LangChain 0.2.0 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-milvus package and should be used instead. To use it run `pip install -U :class:`~langchain-milvus` and import as `from :class:`~langchain_milvus import MilvusVectorStore``.\n",
      "  vectorstore = Milvus(\n"
     ]
    }
   ],
   "source": [
    "# Milvus 벡터 DB 생성\n",
    "collection_name = \"book_rag_db\"\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)\n",
    "\n",
    "vectorstore = Milvus(\n",
    "    embedding_function=ncp_embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "    auto_id=True,\n",
    ")\n",
    "\n",
    "texts = [pair[0] for pair in all_text_embedding_pairs]\n",
    "embeds = [pair[1] for pair in all_text_embedding_pairs]\n",
    "\n",
    "\n",
    "def precomputed_embed_documents(cls, input_texts):\n",
    "    if input_texts != texts:\n",
    "        raise ValueError(\n",
    "            \"ERROR : 입력 텍스트 순서가 사전 계산된 임베딩과 일치하지 않음\"\n",
    "        )\n",
    "    return embeds\n",
    "\n",
    "\n",
    "ClovaXEmbeddings.embed_documents = classmethod(precomputed_embed_documents)\n",
    "vectorstore.add_texts(\n",
    "    texts=texts, metadatas=all_metadata_list_mapped, embeddings=embeds\n",
    ")\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "dpr_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_clova, retriever=dense_retriever, return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유틸\n",
    "\n",
    "\n",
    "def extract_field(text, field_name):\n",
    "\n",
    "    pattern = rf\"{re.escape(field_name)}\\s*:\\s*(.*)\"\n",
    "    match = re.search(pattern, text)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "\n",
    "MIN_INFO_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공용 & 페르소나별 프롬프트 템플릿\n",
    "\n",
    "decision_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "현재 대화 상황과 질문의 맥락을 분석하여 아래 중 하나의 행동을 출력해라:\n",
    "- \"추천\": 사용자가 책 추천을 명확히 요청한 경우, 추가 정보 없이 바로 추천을 진행. & 추가 질문에서 책 추천을 원한다는 답변에 긍정적으로 응답한 경우, 바로 추천을 진행.\n",
    "- \"추가 질문\": 책 추천을 위해 더 세부적인 선호도 정보(예: 작가, 시대, 장르 등)가 필요하면, 구체적인 질문을 던져서 정보를 요청. & 충분한 사용자 정보를 수집했다고 판단할 경우, 추천을 원하냐고 질의.\n",
    "- 질문에 대해서 사용자가 \"모호한\", \"부정적인\" 답변을 할 경우 넘어가라.\n",
    "- \"~~비슷한\" 이라고 사용자가 답변할 경우, 쿼리에 그대로 반영하는것이 아닌 너의 지식정보를 활용해서 특징을 쿼리로 반영하라.\n",
    "    - 예시 : 히가시노 게이고 작가랑 비슷한 -> 미스터리, 추리 소설\n",
    "\n",
    "[최종 출력 형식 - 반드시 아래 내용만 출력]\n",
    "{% raw %}\n",
    "행동: \"{{행동 (추천/추가 질문}}\"\n",
    "추천 책 정보: \"{{책 제목 및 상세 정보, 정보 충분 시; 정보 부족 시 빈 문자열}}\"\n",
    "추가 질문: \"{{추가 질문, 정보 보완 필요 시; 충분하면 빈 문자열}}\"\n",
    "{% endraw %}\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"role_instructions\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "final_query_generation_template = PromptTemplate(\n",
    "    template=\"\"\"\"\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "\n",
    "[페르소나 정보]\n",
    "{{ persona_info }}\n",
    "\n",
    "[사용자 선호도]\n",
    "{{ preferences }}\n",
    "\n",
    "위 정보를 바탕으로, 책 추천에 활용 가능한 핵심 선호도 정보(예: 장르, 주제, 분위기 등)를 반영하여 자연스러운 한 문장의 \"최종 검색 쿼리\"를 작성해라.\n",
    "\n",
    "- \"최종 검색 쿼리\"는 반드시 \"추천 해줘\"로 끝나도록 한다.\n",
    "- \"최종 검색 쿼리\"를 질문 형태로 작성하지 않는다.\n",
    "- '추가 질문'이라는 표현은 \"최종 검색 쿼리\"에 절대 사용하지 않는다.\n",
    "\n",
    "최종 출력 형식:\n",
    "쿼리: <최종 검색 쿼리>\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 페르소나 프롬프트\n",
    "\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 관심 분야와 요구를 분석하여, 명확하고 구체적인 정보로 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다.사용자의 관심사와 목적을 파악하여, 다양한 분야의 책을 적절하게 추천해라. 문학, 과학 외에도 자기계발, 역사, 에세이, 경제경영 등 모든 장르에 유연하게 대응해라.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 임베딩 기록용 리스트\n",
    "previous_question_embeddings = []\n",
    "\n",
    "\n",
    "def is_similar_question(new_emb, prev_embeds, threshold=0.88):\n",
    "    if not prev_embeds:\n",
    "        return False\n",
    "    sim_scores = cosine_similarity([new_emb], prev_embeds)[0]\n",
    "    max_score = max(sim_scores)\n",
    "    print(f\"[중복 유사도 판단] Max = {max_score:.3f}\")\n",
    "    return max_score > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비동기 체인 구성 & 디버깅 로깅 함수\n",
    "\n",
    "\n",
    "async def async_invoke(chain: LLMChain, vars_dict: dict, step_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    체인 호출을 비동기로 수행하고, 단계별 디버깅 출력과 예외 처리를 수행합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        print(f\"\\n[디버그] {step_name} 호출 전 변수: {vars_dict}\")\n",
    "\n",
    "        # 동기 함수인 llm.invoke를 비동기로 실행 (to_thread 사용)\n",
    "        result = await asyncio.to_thread(chain.invoke, vars_dict)\n",
    "        print(f\"[디버그] {step_name} 결과: {result}\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"[에러] {step_name}에서 예외 발생: {str(e)}\")\n",
    "\n",
    "        return {\"text\": \"\"}\n",
    "\n",
    "\n",
    "async def async_invoke_llm(prompt: str, step_name: str) -> str:\n",
    "    \"\"\"\n",
    "    단일 프롬프트 문자열을 llm.invoke로 비동기 호출하여 결과를 반환합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        print(f\"\\n[디버그] {step_name} 프롬프트 호출:\\n{prompt}\")\n",
    "        response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
    "        result_text = response.text().strip()\n",
    "        print(f\"[디버그] {step_name} 응답: {result_text}\")\n",
    "\n",
    "        return result_text\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        print(f\"[에러] {step_name}에서 예외 발생: {str(e)}\")\n",
    "\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseRAGPipeline 클래스 (체인 구성 추가 + 디버깅 방식 변경 + 비동기 방식)\n",
    "\n",
    "\n",
    "class BaseRAGPipeline:\n",
    "\n",
    "    def __init__(self, config, llm, retriever, qa_chain, documents, embedding_model):\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.llm = llm\n",
    "\n",
    "        self.retriever = retriever\n",
    "\n",
    "        self.qa_chain = qa_chain\n",
    "\n",
    "        self.documents = documents\n",
    "\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        self.query_history = []\n",
    "\n",
    "        self.user_preferences = defaultdict(list)\n",
    "\n",
    "        self.preferences_text = \"\"\n",
    "\n",
    "        self.decision_chain = LLMChain(llm=self.llm, prompt=decision_prompt_template)\n",
    "\n",
    "        self.final_query_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=final_query_generation_template\n",
    "        )\n",
    "\n",
    "    async def summarize_user_preferences(self, existing_preferences, new_input):\n",
    "\n",
    "        prompt = (\n",
    "            f\"다음 사용자 선호도 내용들을 하나의 자연스러운 문장으로 요약해라:\\n\"\n",
    "            f\"기존 선호도: {existing_preferences}\\n\"\n",
    "            f\"새로운 입력: {new_input}\\n\"\n",
    "            f\"요약된 선호도:\"\n",
    "        )\n",
    "\n",
    "        return await async_invoke_llm(prompt, \"사용자 선호도 요약\")\n",
    "\n",
    "    async def summarize_final_query(self, query):\n",
    "\n",
    "        prompt = (\n",
    "            f\"다음 내용을 하나의 자연스러운 문장으로 정제해라:\\n\"\n",
    "            f\"{query}\\n\"\n",
    "            f\"정제된 검색 쿼리:\"\n",
    "        )\n",
    "\n",
    "        return await async_invoke_llm(prompt, \"최종 쿼리 정제\")\n",
    "\n",
    "    def robust_parse_decision_response(self, response_text):\n",
    "\n",
    "        action_match = re.search(r\"행동\\s*[:：]\\s*\\\"?([^\\\"\\n]+)\\\"?\", response_text)\n",
    "\n",
    "        action = action_match.group(1).strip() if action_match else None\n",
    "\n",
    "        book_info_match = re.search(\n",
    "            r\"추천\\s*책\\s*정보\\s*[:：]\\s*\\\"?([^\\\"\\n]+)\\\"?\", response_text\n",
    "        )\n",
    "\n",
    "        book_info = book_info_match.group(1).strip() if book_info_match else \"\"\n",
    "\n",
    "        follow_match = re.search(\n",
    "            r\"추가\\s*질문\\s*[:：]\\s*\\\"?([^\\\"\\n]+)\\\"?\", response_text\n",
    "        )\n",
    "\n",
    "        additional_question = follow_match.group(1).strip() if follow_match else \"\"\n",
    "\n",
    "        return action, book_info, additional_question\n",
    "\n",
    "    async def generate_answer(self, query):\n",
    "\n",
    "        # Keyword - author 기준 필터링 : 아직 미구현\n",
    "\n",
    "        author_match = re.search(r\"(?:저자|작가)\\s*[:：]\\s*(\\S+)\", query)\n",
    "\n",
    "        if author_match:\n",
    "\n",
    "            author_name = author_match.group(1).strip().lower()\n",
    "\n",
    "            dense_results = self.qa_chain.invoke(query)[\"source_documents\"]\n",
    "\n",
    "            keyword_results = [\n",
    "                doc\n",
    "                for doc in self.documents\n",
    "                if doc.metadata.get(\"author\", \"\").strip().lower() == author_name\n",
    "            ]\n",
    "\n",
    "            source_docs = list(\n",
    "                {\n",
    "                    doc.metadata.get(\"ISBN\"): doc\n",
    "                    for doc in (dense_results + keyword_results)\n",
    "                    if doc.metadata.get(\"ISBN\")\n",
    "                }.values()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "\n",
    "            result = self.qa_chain.invoke(query)\n",
    "\n",
    "            source_docs = result[\"source_documents\"]\n",
    "\n",
    "        retrieved_isbns = set()\n",
    "\n",
    "        for doc in source_docs:\n",
    "\n",
    "            isbn = doc.metadata.get(\"ISBN\")\n",
    "\n",
    "            if isbn:\n",
    "\n",
    "                retrieved_isbns.add(isbn)\n",
    "\n",
    "        aggregated_docs = []\n",
    "\n",
    "        for isbn in retrieved_isbns:\n",
    "\n",
    "            book_docs = [\n",
    "                doc for doc in self.documents if doc.metadata.get(\"ISBN\") == isbn\n",
    "            ]\n",
    "\n",
    "            if not book_docs:\n",
    "                continue\n",
    "\n",
    "            aggregated_text = \"\\n\".join([doc.page_content for doc in book_docs])\n",
    "\n",
    "            aggregated_docs.append(\n",
    "                Document(page_content=aggregated_text, metadata=book_docs[0].metadata)\n",
    "            )\n",
    "\n",
    "        formatted_answers = []\n",
    "\n",
    "        for doc in aggregated_docs:\n",
    "\n",
    "            metadata = doc.metadata\n",
    "\n",
    "            title = metadata.get(\"title\") or extract_field(doc.page_content, \"제목\")\n",
    "\n",
    "            author = metadata.get(\"author\") or extract_field(doc.page_content, \"저자\")\n",
    "\n",
    "            aggregated_text = doc.page_content\n",
    "\n",
    "            book_intro = extract_field(aggregated_text, \"책소개\")\n",
    "\n",
    "            publisher_review = extract_field(aggregated_text, \"출판사리뷰\")\n",
    "\n",
    "            recommendation_field = extract_field(aggregated_text, \"추천사\")\n",
    "\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "\n",
    "                selected_info = book_intro\n",
    "\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "\n",
    "                selected_info = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "\n",
    "                selected_info = recommendation_field\n",
    "\n",
    "            else:\n",
    "\n",
    "                selected_info = \"\"\n",
    "\n",
    "            if not selected_info:\n",
    "\n",
    "                reason = \"추천 정보 생성 불가\"\n",
    "\n",
    "            else:\n",
    "\n",
    "                reason_prompt = (\n",
    "                    f\"다음 정보와 '최종 검색 쿼리'를 참고하여, 이 책이 추천되는 이유를 명확하게 요약해라. \"\n",
    "                    f\"책의 주요 특징과 강점을 중심으로 설명해라.\\n\\n정보:\\n{selected_info}\"\n",
    "                )\n",
    "\n",
    "                generated_reason = await async_invoke_llm(\n",
    "                    reason_prompt, \"추천 이유 생성\"\n",
    "                )\n",
    "                if (\n",
    "                    not generated_reason\n",
    "                    or len(generated_reason) < 10\n",
    "                    or \"추천 정보 생성 불가\" in generated_reason\n",
    "                ):\n",
    "\n",
    "                    reason = \"추천 정보 생성 불가\"\n",
    "\n",
    "                else:\n",
    "\n",
    "                    reason = generated_reason\n",
    "\n",
    "            formatted = f\"책 제목: {title}\\n저자: {author}\\n추천 이유: {reason}\"\n",
    "\n",
    "            formatted_answers.append(formatted)\n",
    "\n",
    "        answer = \"\\n\\n\".join(formatted_answers)\n",
    "\n",
    "        refined_answer = await async_invoke_llm(\n",
    "            f\"아래 원본 추천 결과를 읽고 사용자 선호도를 바탕으로, 각 책의 정보를 다음 형식에 맞춰 재작성해라.\\n\\n형식:\\n책 제목: <책 제목>\\n저자: <저자>\\n추천 이유: <추천 이유>\\n\\n원본 추천 결과:\\n{answer}\\n\\n출력 시, 반드시 위 형식만을 사용하고 불필요한 안내 문구는 포함하지 말아라.\",\n",
    "            \"추천 결과 재정제\",\n",
    "        )\n",
    "\n",
    "        return refined_answer, None\n",
    "\n",
    "    def print_chat_history(self):\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        for line in self.query_history[-4:]:\n",
    "\n",
    "            if line.startswith(\"사용자:\"):\n",
    "\n",
    "                print(f\"[사용자] {line.split(':', 1)[1].strip()}\")\n",
    "\n",
    "            elif line.startswith(\"챗봇:\"):\n",
    "\n",
    "                print(f\"[챗봇] {line.split(':', 1)[1].strip()}\")\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    async def search_and_generate_answer(self, user_query):\n",
    "\n",
    "        self.preferences_text = \" \".join(self.user_preferences[\"preferences\"])\n",
    "\n",
    "        query_summary = \"\\n\".join(self.query_history[-5:])\n",
    "\n",
    "        if self.config.get(\"persona\") == \"Literature\":\n",
    "\n",
    "            persona_info = \"감성, 현재 기분, 선호하는 문학 장르 및 작가 정보\"\n",
    "\n",
    "        elif self.config.get(\"persona\") == \"Science\":\n",
    "\n",
    "            persona_info = \"초심자 여부, 관심 분야, 구체적인 기술 정보\"\n",
    "\n",
    "        else:\n",
    "\n",
    "            persona_info = \"\"\n",
    "\n",
    "        followup_count = 0\n",
    "\n",
    "        max_followup = 2\n",
    "\n",
    "        previous_questions = []\n",
    "\n",
    "        while True:\n",
    "\n",
    "            prompt_vars = {\n",
    "                \"history\": query_summary,\n",
    "                \"query\": user_query,\n",
    "                \"role_instructions\": self.config[\"role_instructions\"],\n",
    "            }\n",
    "\n",
    "            decision_result = await async_invoke(\n",
    "                self.decision_chain, prompt_vars, \"행동 결정\"\n",
    "            )\n",
    "\n",
    "            decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "\n",
    "            print(f\"\\n[디버그] Decision 응답: {decision_text}\")\n",
    "\n",
    "            action, book_info, additional_question = (\n",
    "                self.robust_parse_decision_response(decision_text)\n",
    "            )\n",
    "\n",
    "            print(f\"[디버그] 행동: {action}\")\n",
    "\n",
    "            # 중복 질문 방지 + 최대 질문 횟수 제한\n",
    "            if action == \"추가 질문\":\n",
    "\n",
    "                if followup_count >= max_followup:\n",
    "\n",
    "                    print(\"[최대 보충 질문 수 초과 → 추천으로 전환합니다]\")\n",
    "\n",
    "                    action = \"추천\"\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # 유사 질문 판단 (추가 질문일 경우)\n",
    "                    new_emb = np.array(\n",
    "                        self.embedding_model.embed_query(additional_question)\n",
    "                    ).reshape(1, -1)\n",
    "\n",
    "                    prev_embs = [\n",
    "                        np.array(self.embedding_model.embed_query(q)).reshape(1, -1)\n",
    "                        for q in previous_questions\n",
    "                    ]\n",
    "\n",
    "                    # 로그 추가: 각 유사도 확인\n",
    "                    for i, emb in enumerate(prev_embs):\n",
    "\n",
    "                        similarity = cosine_similarity(new_emb, emb)[0][0]\n",
    "\n",
    "                        print(\n",
    "                            f\"[유사도 체크] '{additional_question}' vs 이전 질문[{i}] '{previous_questions[i]}' → 유사도: {similarity:.4f}\"\n",
    "                        )\n",
    "\n",
    "                    # 판단 조건\n",
    "                    if any(\n",
    "                        cosine_similarity(new_emb, emb)[0][0] > 0.8 for emb in prev_embs\n",
    "                    ):\n",
    "\n",
    "                        print(\"[유사한 질문 감지 → 추천으로 전환합니다]\")\n",
    "\n",
    "                        action = \"추천\"\n",
    "\n",
    "                    else:\n",
    "                        previous_questions.append(additional_question)\n",
    "\n",
    "                        self.query_history.append(f\"챗봇: {additional_question}\")\n",
    "\n",
    "                        self.print_chat_history()\n",
    "\n",
    "                        print(f\"[챗봇] {additional_question}\")\n",
    "\n",
    "                        raw_user_input = input(\"[사용자] \")\n",
    "\n",
    "                        self.query_history.append(f\"사용자: {raw_user_input}\")\n",
    "\n",
    "                        followup_count += 1\n",
    "\n",
    "                        if self.preferences_text:\n",
    "                            updated_pref = await self.summarize_user_preferences(\n",
    "                                self.preferences_text, raw_user_input\n",
    "                            )\n",
    "                        else:\n",
    "                            updated_pref = raw_user_input\n",
    "\n",
    "                        self.preferences_text = updated_pref\n",
    "\n",
    "                        print(\n",
    "                            f\"\\n[디버그] 업데이트된 사용자 선호도: {self.preferences_text}\"\n",
    "                        )\n",
    "\n",
    "                        if len(self.preferences_text.split()) >= 10:\n",
    "\n",
    "                            print(\n",
    "                                \"[디버그] 충분한 선호도가 수집되어 추천으로 전환합니다.\"\n",
    "                            )\n",
    "\n",
    "                            action = \"추천\"\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            continue\n",
    "\n",
    "            if action == \"추천\":\n",
    "\n",
    "                final_query_vars = {\n",
    "                    \"history\": \"\\n\".join(self.query_history[-5:]),\n",
    "                    \"query\": user_query,\n",
    "                    \"persona_info\": persona_info,\n",
    "                    \"preferences\": self.preferences_text,\n",
    "                }\n",
    "\n",
    "                final_query_result = await async_invoke(\n",
    "                    self.final_query_generation_chain,\n",
    "                    final_query_vars,\n",
    "                    \"최종 쿼리 생성\",\n",
    "                )\n",
    "\n",
    "                final_response_text = final_query_result.get(\"text\", \"\").strip()\n",
    "\n",
    "                if final_response_text.startswith(\"추가 질문:\"):\n",
    "\n",
    "                    print(\"[논리 오류] 추천 결정 후 추가 질문이 생성됨 → fallback 적용\")\n",
    "\n",
    "                    final_query = await self.summarize_final_query(\n",
    "                        f\"{self.preferences_text} 기반으로 책 추천 받고 싶어\"\n",
    "                    )\n",
    "                elif final_response_text.startswith(\"쿼리:\"):\n",
    "\n",
    "                    final_query = final_response_text[len(\"쿼리:\") :].strip()\n",
    "\n",
    "                else:\n",
    "\n",
    "                    final_query = await self.summarize_final_query(final_response_text)\n",
    "\n",
    "                print(f\"\\n[디버그] 최종 검색 쿼리: {final_query}\")\n",
    "\n",
    "                answer, _ = await self.generate_answer(final_query)\n",
    "\n",
    "                return answer\n",
    "\n",
    "            # fallback\n",
    "            print(\"[fallback] 예상치 못한 흐름입니다. 기본 추천 쿼리로 전환합니다]\")\n",
    "\n",
    "            fallback_query = await self.summarize_final_query(\n",
    "                f\"{self.preferences_text} 기반으로 책 추천 받고 싶어\"\n",
    "            )\n",
    "\n",
    "            answer, _ = await self.generate_answer(fallback_query)\n",
    "\n",
    "            return answer\n",
    "\n",
    "    async def interactive_multi_turn_qa(self):\n",
    "\n",
    "        self.print_chat_history()\n",
    "\n",
    "        while True:\n",
    "\n",
    "            user_query = input(\"[사용자] \")\n",
    "\n",
    "            if user_query.lower() == \"quit\":\n",
    "\n",
    "                print(\"\\n[대화 저장 중...]\")\n",
    "\n",
    "                print(\"대화 저장 완료\")\n",
    "\n",
    "                import sys\n",
    "\n",
    "                sys.exit()\n",
    "\n",
    "            self.query_history.append(f\"사용자: {user_query}\")\n",
    "\n",
    "            answer = await self.search_and_generate_answer(user_query)\n",
    "\n",
    "            if answer is not None:\n",
    "\n",
    "                self.query_history.append(f\"챗봇: {answer}\")\n",
    "\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "                print(f\"[사용자] {user_query}\")\n",
    "\n",
    "                print(f\"[챗봇] {answer}\")\n",
    "\n",
    "                print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 페르소나별 파이프라인 클래스\n",
    "\n",
    "\n",
    "class LiteratureRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents, embedding_model):\n",
    "        config = {\"persona\": \"Literature\", \"role_instructions\": literature_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents, embedding_model)\n",
    "\n",
    "\n",
    "class ScienceRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents, embedding_model):\n",
    "        config = {\"persona\": \"Science\", \"role_instructions\": science_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents, embedding_model)\n",
    "\n",
    "\n",
    "class GeneralRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, retriever, qa_chain, documents, embedding_model):\n",
    "        config = {\"persona\": \"General\", \"role_instructions\": general_role}\n",
    "        super().__init__(config, llm, retriever, qa_chain, documents, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 저는 도서 추천 챗봇입니다. 아래 관심 분야 중 하나를 선택해주세요.\n",
      "1. 예술/문학\n",
      "2. 과학/기술\n",
      "3. 기본/범용\n",
      "--------------------------------------------------\n",
      "[챗봇] 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\n",
      "--------------------------------------------------\n",
      "\n",
      "[디버그] 행동 결정 호출 전 변수: {'history': '챗봇: 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\\n사용자: 심심해', 'query': '심심해', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.'}\n",
      "[디버그] 행동 결정 결과: {'history': '챗봇: 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\\n사용자: 심심해', 'query': '심심해', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.', 'text': '행동: 추가 질문 \\n추가 질문 : 심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?'}\n",
      "\n",
      "[디버그] Decision 응답: 행동: 추가 질문 \n",
      "추가 질문 : 심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?\n",
      "[디버그] 행동: 추가 질문\n",
      "--------------------------------------------------\n",
      "[챗봇] 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\n",
      "[사용자] 심심해\n",
      "[챗봇] 심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?\n",
      "--------------------------------------------------\n",
      "[챗봇] 심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?\n",
      "\n",
      "[디버그] 업데이트된 사용자 선호도: 판타지 소설 책\n",
      "\n",
      "[디버그] 행동 결정 호출 전 변수: {'history': '챗봇: 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\\n사용자: 심심해', 'query': '심심해', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.'}\n",
      "[디버그] 행동 결정 결과: {'history': '챗봇: 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\\n사용자: 심심해', 'query': '심심해', 'role_instructions': '너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 섬세하게 파악하여, 감성적인 언어로 책을 추천해라.', 'text': '행동: \"추가 질문\"\\n추가 질문 : 심심하실 때 주로 어떤 분야의 책을 읽으시나요? 예를 들어, 로맨스, 판타지, 에세이 등 다양한 분야가 있습니다.'}\n",
      "\n",
      "[디버그] Decision 응답: 행동: \"추가 질문\"\n",
      "추가 질문 : 심심하실 때 주로 어떤 분야의 책을 읽으시나요? 예를 들어, 로맨스, 판타지, 에세이 등 다양한 분야가 있습니다.\n",
      "[디버그] 행동: 추가 질문\n",
      "[유사도 체크] '심심하실 때 주로 어떤 분야의 책을 읽으시나요? 예를 들어, 로맨스, 판타지, 에세이 등 다양한 분야가 있습니다.' vs 이전 질문[0] '심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?' → 유사도: 0.8066\n",
      "[유사한 질문 감지 → 추천으로 전환합니다]\n",
      "\n",
      "[디버그] 최종 쿼리 생성 호출 전 변수: {'history': '챗봇: 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\\n사용자: 심심해\\n챗봇: 심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?\\n사용자: 판타지 소설 책', 'query': '심심해', 'persona_info': '감성, 현재 기분, 선호하는 문학 장르 및 작가 정보', 'preferences': '판타지 소설 책'}\n",
      "[디버그] 최종 쿼리 생성 결과: {'history': '챗봇: 안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\\n사용자: 심심해\\n챗봇: 심심하실 때 주로 읽으시는 장르나 관심 있는 주제가 있으신가요?\\n사용자: 판타지 소설 책', 'query': '심심해', 'persona_info': '감성, 현재 기분, 선호하는 문학 장르 및 작가 정보', 'preferences': '판타지 소설 책', 'text': '쿼리 : 판타지 소설 책 추천 해줘'}\n",
      "\n",
      "[디버그] 최종 쿼리 정제 프롬프트 호출:\n",
      "다음 내용을 하나의 자연스러운 문장으로 정제해라:\n",
      "쿼리 : 판타지 소설 책 추천 해줘\n",
      "정제된 검색 쿼리:\n",
      "[디버그] 최종 쿼리 정제 응답: 판타지 소설 책 추천해줘.\n",
      "\n",
      "[디버그] 최종 검색 쿼리: 판타지 소설 책 추천해줘.\n",
      "\n",
      "[디버그] 추천 이유 생성 프롬프트 호출:\n",
      "다음 정보와 '최종 검색 쿼리'를 참고하여, 이 책이 추천되는 이유를 명확하게 요약해라. 책의 주요 특징과 강점을 중심으로 설명해라.\n",
      "\n",
      "정보:\n",
      "이 책은 인문철학 교육서이다. 이 책은 인문철학을 시작하려는 사람에게 상당히 적합한 책이다. 이 책은 인문철학을 깊이 전공하는 전문가에게도 자못 적합한 책이다. 이 책은 모든 학생이 공부할 수 있는 책이다. 이 책은 삶의 목표를 찾고 있는 사람에게 괜찮은 책이다. 이 책은 세상을 이끌려는 리더에게 그런대로 적합한 책이다. 이 책은 학생들을 가르치는 교육자에게 꽤 적합한 책이다. 이 책은 삶을 뒤돌아보는 이들에게 때때로 적합한 책이다. 이 책은 무슨 책을 읽어야 할지 모르는 사람들에게 나쁘지 않은 책이다. 이 책은 자신이 부족해 보일 때 조금 용기를 주는 책이다. 이 책은 누군가 거만한 사람에게 선물하면 좋은 책이다. 이 책은 소중한 사람들과 같이 공부하기에 제법 적합한 책이다. 이 책은 차분히 삶을 디자인하려는 사람에게 조금은 도움이 되는 책이다.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mrun(pipeline\u001b[38;5;241m.\u001b[39minteractive_multi_turn_qa())\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 38\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mquery_history\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m챗봇: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgreeting\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# nest_asyncio으로 비동기 작업을 추가?해야함 - asyncio.run() or get_event_loop().run_until_complete() 모두 사용 가능\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minteractive_multi_turn_qa\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32mc:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     heappop(scheduled)\n\u001b[0;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32mc:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\selectors.py:323\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32mc:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 314\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect(r, w, w, timeout)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 추가 비동기 작업 허용\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# 메인 함수 -비동기 실행\n",
    "def main():\n",
    "    print(\n",
    "        \"안녕하세요! 저는 도서 추천 챗봇입니다. 아래 관심 분야 중 하나를 선택해주세요.\"\n",
    "    )\n",
    "    # print(\"페르소나 선택:\")\n",
    "    print(\"1. 예술/문학\")\n",
    "    print(\"2. 과학/기술\")\n",
    "    print(\"3. 기본/범용\")\n",
    "    choice = input(\"원하는 페르소나 번호를 입력하세요 (1 또는 2 또는 3): \").strip()\n",
    "    if choice == \"1\":\n",
    "        pipeline = LiteratureRAGPipeline(\n",
    "            llm_clova,\n",
    "            dense_retriever,\n",
    "            dpr_qa_chain,\n",
    "            documents,\n",
    "            embedding_model=ncp_embeddings,\n",
    "        )\n",
    "        greeting = \"안녕하세요! 감성적이고 문학적인 도서 추천 챗봇입니다. 어떤 책을 읽고 싶으신가요?\"\n",
    "    elif choice == \"2\":\n",
    "        pipeline = ScienceRAGPipeline(\n",
    "            llm_clova,\n",
    "            dense_retriever,\n",
    "            dpr_qa_chain,\n",
    "            documents,\n",
    "            embedding_model=ncp_embeddings,\n",
    "        )\n",
    "        greeting = \"안녕하십니까. 정확하고 논리적인 과학/기술 도서 추천 챗봇입니다. 관심 있는 분야에 대해 편하게 이야기해 주세요.\"\n",
    "    elif choice == \"3\":\n",
    "        pipeline = GeneralRAGPipeline(\n",
    "            llm_clova,\n",
    "            dense_retriever,\n",
    "            dpr_qa_chain,\n",
    "            documents,\n",
    "            embedding_model=ncp_embeddings,\n",
    "        )\n",
    "        greeting = \"안녕하세요! 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇입니다. 어떤 책을 찾으시나요?\"\n",
    "    else:\n",
    "        print(\"잘못된 선택입니다. 기본/범용 페르소나로 실행합니다.\")\n",
    "        pipeline = GeneralRAGPipeline(\n",
    "            llm_clova,\n",
    "            dense_retriever,\n",
    "            dpr_qa_chain,\n",
    "            documents,\n",
    "            embedding_model=ncp_embeddings,\n",
    "        )\n",
    "        greeting = \"안녕하세요! 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇입니다. 어떤 책을 찾으시나요?\"\n",
    "\n",
    "    pipeline.query_history.append(f\"챗봇: {greeting}\")\n",
    "\n",
    "    # nest_asyncio으로 비동기 작업을 추가?해야함 - asyncio.run() or get_event_loop().run_until_complete() 모두 사용 가능\n",
    "    asyncio.run(pipeline.interactive_multi_turn_qa())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/Users/mj/Library/CloudStorage/OneDrive-개인/AI_study/aiffelthon_clabi/data/aiffel_book_250318_semifinal(filled_contents).csv\"\n",
    ")\n",
    "\n",
    "# 제목에서 누워서 읽는 법학"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>분류</th>\n",
       "      <th>제목</th>\n",
       "      <th>부제</th>\n",
       "      <th>저자</th>\n",
       "      <th>발행자</th>\n",
       "      <th>발행일</th>\n",
       "      <th>페이지</th>\n",
       "      <th>가격</th>\n",
       "      <th>표지</th>\n",
       "      <th>책소개</th>\n",
       "      <th>저자소개</th>\n",
       "      <th>목차</th>\n",
       "      <th>출판사리뷰</th>\n",
       "      <th>추천사</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>9791130699554</td>\n",
       "      <td>['국내도서 &gt; 소설/시/희곡 &gt; 역사소설', '국내도서 &gt; 소설/시/희곡 &gt; 한국...</td>\n",
       "      <td>토지 9</td>\n",
       "      <td>3부 1권</td>\n",
       "      <td>박경리 저 지음</td>\n",
       "      <td>다산책방</td>\n",
       "      <td>2023-06-06T15:00:00.000Z</td>\n",
       "      <td>516</td>\n",
       "      <td>17000</td>\n",
       "      <td>https://image.aladin.co.kr/product/31830/75/co...</td>\n",
       "      <td>54년 만에 현대적 감각으로 재탄생한 우리 시대 최고의 고전 ‘토지’! “어떠한 역...</td>\n",
       "      <td>저 : 박경리 (Park, Kyung-Ree,朴景利,박금이) 1926년 10월 28...</td>\n",
       "      <td>제1편 만세(萬歲) 이후\\n1장 끈 떨어진 연\\n2장 전주행(全州行)\\n3장 겨울 ...</td>\n",
       "      <td>“제 삶이 평탄했다면 글을 쓰지 않았을 것입니다. 삶이 문학보다 먼저지요.” 고전의...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0           ISBN  \\\n",
       "13          14  9791130699554   \n",
       "\n",
       "                                                   분류    제목     부제        저자  \\\n",
       "13  ['국내도서 > 소설/시/희곡 > 역사소설', '국내도서 > 소설/시/희곡 > 한국...  토지 9  3부 1권  박경리 저 지음   \n",
       "\n",
       "     발행자                       발행일  페이지     가격  \\\n",
       "13  다산책방  2023-06-06T15:00:00.000Z  516  17000   \n",
       "\n",
       "                                                   표지  \\\n",
       "13  https://image.aladin.co.kr/product/31830/75/co...   \n",
       "\n",
       "                                                  책소개  \\\n",
       "13  54년 만에 현대적 감각으로 재탄생한 우리 시대 최고의 고전 ‘토지’! “어떠한 역...   \n",
       "\n",
       "                                                 저자소개  \\\n",
       "13  저 : 박경리 (Park, Kyung-Ree,朴景利,박금이) 1926년 10월 28...   \n",
       "\n",
       "                                                   목차  \\\n",
       "13  제1편 만세(萬歲) 이후\\n1장 끈 떨어진 연\\n2장 전주행(全州行)\\n3장 겨울 ...   \n",
       "\n",
       "                                                출판사리뷰  추천사  \n",
       "13  “제 삶이 평탄했다면 글을 쓰지 않았을 것입니다. 삶이 문학보다 먼저지요.” 고전의...  NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"제목\"].str.contains(\"토지 9\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"코딩 관련 책?\"\n",
    "# vectorstore.similarity_search(query, k=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kill_the_RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
