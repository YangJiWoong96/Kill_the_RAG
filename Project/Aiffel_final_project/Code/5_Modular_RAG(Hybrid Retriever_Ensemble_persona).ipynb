{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from typing import List, Dict, Any, Optional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "from langchain_community.chat_models import ChatClovaX\n",
    "from pymilvus import connections, utility\n",
    "from langchain_community.vectorstores.milvus import Milvus\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_elasticsearch import ElasticsearchRetriever\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로깅 설정\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBNMergingRetriever\n",
    "\n",
    "\n",
    "class ISBNMergingRetriever(BaseRetriever):\n",
    "    \"\"\"\n",
    "    검색된 Document 리스트를 ISBN 기준으로 그룹화하고,\n",
    "    같은 ISBN을 가진 문서들의 page_content를 병합하며,\n",
    "    그룹 내에서 가장 정보가 많은 메타데이터를 대표로 사용합니다.\n",
    "    \"\"\"\n",
    "\n",
    "    base_retriever: BaseRetriever\n",
    "\n",
    "    def _extract_isbn(self, doc: Document) -> Optional[str]:\n",
    "        try:\n",
    "            for key in [\"ISBN\", \"isbn\"]:\n",
    "                if key in doc.metadata:\n",
    "                    isbn_val = doc.metadata[key]\n",
    "                    return str(isbn_val).replace(\".0\", \"\").strip() if isbn_val else None\n",
    "\n",
    "            inner_meta = doc.metadata.get(\"metadata\", {})\n",
    "            if isinstance(inner_meta, dict):\n",
    "                for key in [\"ISBN\", \"isbn\"]:\n",
    "                    if key in inner_meta:\n",
    "                        isbn_val = inner_meta[key]\n",
    "                        return (\n",
    "                            str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                            if isbn_val\n",
    "                            else None\n",
    "                        )\n",
    "\n",
    "                inner_inner_meta = inner_meta.get(\"metadata\", {})\n",
    "                if isinstance(inner_inner_meta, dict):\n",
    "                    for key in [\"ISBN\", \"isbn\"]:\n",
    "                        if key in inner_inner_meta:\n",
    "                            isbn_val = inner_inner_meta[key]\n",
    "                            return (\n",
    "                                str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                                if isbn_val\n",
    "                                else None\n",
    "                            )\n",
    "\n",
    "            source_meta = doc.metadata.get(\"_source\", {}).get(\"metadata\", {})\n",
    "            if isinstance(source_meta, dict):\n",
    "                for key in [\"ISBN\", \"isbn\"]:\n",
    "                    if key in source_meta:\n",
    "                        isbn_val = source_meta[key]\n",
    "                        return (\n",
    "                            str(isbn_val).replace(\".0\", \"\").strip()\n",
    "                            if isbn_val\n",
    "                            else None\n",
    "                        )\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"[ISBN 추출 오류] Metadata: {doc.metadata}, Error: {e}\")\n",
    "\n",
    "        logger.debug(f\"ISBN 추출 실패 - Metadata: {doc.metadata}\")\n",
    "        return None\n",
    "\n",
    "    def _get_best_metadata(self, doc_list: List[Document]) -> Dict[str, Any]:\n",
    "        best_meta = {}\n",
    "        max_score = -1\n",
    "        required_keys = {\"title\", \"author\", \"ISBN\"}\n",
    "        for doc in doc_list:\n",
    "            current_meta = doc.metadata\n",
    "            score = 0\n",
    "            keys_lower = {k.lower() for k in current_meta.keys()}\n",
    "            required_keys_lower = {rk.lower() for rk in required_keys}\n",
    "            score += sum(\n",
    "                1\n",
    "                for req_key in required_keys_lower\n",
    "                if req_key in keys_lower\n",
    "                and current_meta.get(\n",
    "                    next((k for k in current_meta if k.lower() == req_key), None)\n",
    "                )\n",
    "            )\n",
    "            score += len(current_meta) * 0.1\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_meta = current_meta\n",
    "\n",
    "        if best_meta:\n",
    "            logger.debug(\n",
    "                f\"선택된 최적 메타데이터 (Score: {max_score:.2f}): {best_meta}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"ISBN 그룹 내에서 유효한 메타데이터를 찾지 못함. 첫 번째 문서 메타데이터 사용 시도.\"\n",
    "            )\n",
    "            if doc_list:\n",
    "                best_meta = doc_list[0].metadata\n",
    "\n",
    "        return dict(best_meta)\n",
    "\n",
    "    def _merge_documents_by_isbn(\n",
    "        self, docs: List[Document], is_async=False\n",
    "    ) -> List[Document]:\n",
    "        grouped = defaultdict(list)\n",
    "        merged_docs = []\n",
    "        logger.info(\n",
    "            f\"[{'Async' if is_async else 'Sync'}] 병합 전 입력 문서 수: {len(docs)}\"\n",
    "        )\n",
    "        for idx, doc in enumerate(docs):\n",
    "            isbn = self._extract_isbn(doc)\n",
    "            if isbn:\n",
    "                grouped[isbn].append(doc)\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"[{'Async' if is_async else 'Sync'}] Doc {idx} ISBN 추출 실패 - Metadata: {doc.metadata}\"\n",
    "                )\n",
    "\n",
    "        for isbn, doc_list in grouped.items():\n",
    "            merged_meta = self._get_best_metadata(doc_list)\n",
    "            combined_text = \"\\n\\n---\\n\\n\".join(\n",
    "                d.page_content for d in doc_list if d.page_content\n",
    "            ).strip()\n",
    "            if combined_text:\n",
    "                logger.debug(f\"ISBN {isbn} 병합: 최종 사용될 메타데이터: {merged_meta}\")\n",
    "                merged_docs.append(\n",
    "                    Document(page_content=combined_text, metadata=merged_meta)\n",
    "                )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"[{'Async' if is_async else 'Sync'}] ISBN {isbn} 병합 후 내용 없음. 제외됨. 사용된 메타데이터: {merged_meta}\"\n",
    "                )\n",
    "\n",
    "        logger.info(\n",
    "            f\"[{'Async' if is_async else 'Sync'}] ISBN 병합 그룹 수: {len(grouped)}\"\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"[{'Async' if is_async else 'Sync'}] 병합 후 최종 문서 수: {len(merged_docs)}\"\n",
    "        )\n",
    "        return merged_docs\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        try:\n",
    "            docs = self.base_retriever.get_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"기본 리트리버 동기 검색 오류: '{query}' → {e}\", exc_info=True\n",
    "            )\n",
    "            docs = []\n",
    "        logger.info(f\"Sync 검색 결과 총 문서 수: {len(docs)}\")\n",
    "        return self._merge_documents_by_isbn(docs, is_async=False)\n",
    "\n",
    "    async def _aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        try:\n",
    "            docs = await self.base_retriever.aget_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"기본 리트리버 비동기 검색 오류: '{query}' → {e}\", exc_info=True\n",
    "            )\n",
    "            docs = []\n",
    "        logger.info(f\"Async 검색 결과 총 문서 수: {len(docs)}\")\n",
    "        return self._merge_documents_by_isbn(docs, is_async=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text는 아래와 같은 형태로 들어가서 청크\n",
    "\n",
    "# 제목 : [값]\n",
    "# 분류 : [값]\n",
    "# 저자 : [값]\n",
    "# 저자소개 : [값]\n",
    "# 책 소개 : [값]\n",
    "# 목차 : [값]\n",
    "# 출판사리뷰 : [값]\n",
    "\n",
    "# 임베딩 pkl에 포함된 메타데이터 컬럼과 (임베딩,원본text)로 묶인 컬럼\n",
    "\n",
    "# 메타데이터 및 벡터 문서 컬럼 설정\n",
    "\n",
    "# metadata_columns = [\n",
    "#     \"ISBN\",\n",
    "#     \"페이지\",\n",
    "#     \"가격\",\n",
    "#     \"제목\",\n",
    "#     \"부제\",\n",
    "#     \"저자\",\n",
    "#     \"분류\",\n",
    "#     \"목차\",\n",
    "#     \"발행자\",\n",
    "#     \"표지\",\n",
    "# ]\n",
    "# vector_doc_columns = [\n",
    "#     \"제목\",\n",
    "#     \"부제\",\n",
    "#     \"분류\",\n",
    "#     \"저자\",\n",
    "#     \"저자소개\",\n",
    "#     \"책소개\",\n",
    "#     \"출판사리뷰\",\n",
    "#     \"추천사\",\n",
    "#     \"목차\",\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Util Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar_question(new_emb, prev_embeds, threshold=0.65):\n",
    "    if not prev_embeds:\n",
    "        return False\n",
    "    sim_scores = cosine_similarity([new_emb], prev_embeds)[0]\n",
    "    max_score = np.max(sim_scores)\n",
    "    logger.info(\n",
    "        f\"[질문 유사도 판단] Max Similarity = {max_score:.3f} (Threshold = {threshold})\"\n",
    "    )\n",
    "    return max_score > threshold\n",
    "\n",
    "\n",
    "def extract_field(text, field_name):\n",
    "    pattern = rf\"^\\s*{re.escape(field_name)}\\s*[:：]\\s*(.*?)\\s*$\"\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        match = re.search(pattern, line, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 환경설정 & 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 20:15:36,375 - INFO - ClovaX 임베딩 및 Chat 모델 초기화 완료\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"NCP_CLOVASTUDIO_API_KEY\")\n",
    "api_url = os.getenv(\"NCP_CLOVASTUDIO_API_URL\", \"https://clovastudio.stream.ntruss.com/\")\n",
    "milvus_host = os.getenv(\"MILVUS_HOST\", \"localhost\")\n",
    "milvus_port = os.getenv(\"MILVUS_PORT\", \"19530\")\n",
    "es_url = os.getenv(\"ELASTICSEARCH_URL\", \"http://localhost:9200\")\n",
    "es_index_name = \"book_bm25_index_v2\"\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"NCP_CLOVASTUDIO_API_KEY 환경 변수가 설정되지 않았습니다.\")\n",
    "if not api_url:\n",
    "    raise ValueError(\"NCP_CLOVASTUDIO_API_URL 환경 변수가 설정되지 않았습니다.\")\n",
    "if not es_url:\n",
    "    raise ValueError(\"ELASTICSEARCH_URL 환경 변수가 설정되지 않았습니다.\")\n",
    "\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_KEY\"] = api_key\n",
    "os.environ[\"NCP_CLOVASTUDIO_API_URL\"] = api_url\n",
    "\n",
    "try:\n",
    "    ncp_embeddings = ClovaXEmbeddings(model=\"bge-m3\")\n",
    "    llm_clova = ChatClovaX(model=\"HCX-003\", max_tokens=2048)\n",
    "    logger.info(\"ClovaX 임베딩 및 Chat 모델 초기화 완료\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"ClovaX 모델 초기화 실패: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 20:18:38,576 - INFO - 임베딩 데이터 로드 완료: 116218개\n",
      "2025-04-07 20:19:21,944 - INFO - 총 116218개의 Document 객체 생성 완료.\n"
     ]
    }
   ],
   "source": [
    "embedding_file = r\"C:\\Kill_the_RAG\\Project\\Aiffel_final_project\\Code\\Data\\final_embedding\\final_embedding.pkl\"\n",
    "if os.path.exists(embedding_file):\n",
    "    try:\n",
    "        with open(embedding_file, \"rb\") as f:\n",
    "            saved_data = pickle.load(f)\n",
    "        all_text_embedding_pairs = [\n",
    "            (v[\"text\"], v[\"embedding\"])\n",
    "            for v in saved_data.values()\n",
    "            if \"text\" in v and \"embedding\" in v\n",
    "        ]\n",
    "        all_metadata_list = [\n",
    "            v[\"metadata\"] for v in saved_data.values() if \"metadata\" in v\n",
    "        ]\n",
    "        if len(all_text_embedding_pairs) != len(all_metadata_list):\n",
    "            logger.warning(\n",
    "                f\"로드된 텍스트/임베딩 쌍({len(all_text_embedding_pairs)})과 메타데이터({len(all_metadata_list)}) 개수 불일치.\"\n",
    "            )\n",
    "            min_len = min(len(all_text_embedding_pairs), len(all_metadata_list))\n",
    "            all_text_embedding_pairs = all_text_embedding_pairs[:min_len]\n",
    "            all_metadata_list = all_metadata_list[:min_len]\n",
    "            logger.info(f\"데이터를 {min_len}개로 조정하여 계속 진행.\")\n",
    "        logger.info(f\"임베딩 데이터 로드 완료: {len(all_text_embedding_pairs)}개\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"임베딩 파일 로드 실패: {e}\", exc_info=True)\n",
    "        raise\n",
    "else:\n",
    "    raise FileNotFoundError(f\"임베딩 파일을 찾을 수 없음: {embedding_file}\")\n",
    "\n",
    "metadata_mapping = {\n",
    "    \"ISBN\": \"ISBN\",\n",
    "    \"페이지\": \"page\",\n",
    "    \"가격\": \"price\",\n",
    "    \"제목\": \"title\",\n",
    "    \"부제\": \"subtitle\",\n",
    "    \"저자\": \"author\",\n",
    "    \"분류\": \"category\",\n",
    "    \"저자소개\": \"author_intro\",\n",
    "    \"책소개\": \"book_intro\",\n",
    "    \"목차\": \"table_of_contents\",\n",
    "    \"출판사리뷰\": \"publisher_review\",\n",
    "    \"추천사\": \"recommendation\",\n",
    "    \"발행자\": \"publisher\",\n",
    "    \"표지\": \"book_cover\",\n",
    "}\n",
    "\n",
    "\n",
    "def clean_metadata(meta: dict) -> dict:\n",
    "    cleaned = {}\n",
    "    target_keys = list(metadata_mapping.values())\n",
    "    original_to_target = {\n",
    "        k_orig: k_target for k_orig, k_target in metadata_mapping.items()\n",
    "    }\n",
    "    for target_key in target_keys:\n",
    "        original_key = next(\n",
    "            (k for k, v in original_to_target.items() if v == target_key), None\n",
    "        )\n",
    "        value = (\n",
    "            meta.get(original_key)\n",
    "            if original_key and original_key in meta\n",
    "            else meta.get(target_key)\n",
    "        )\n",
    "        if pd.isna(value):\n",
    "            cleaned[target_key] = 0 if target_key in [\"page\", \"price\"] else \"\"\n",
    "        elif target_key == \"ISBN\":\n",
    "            try:\n",
    "                str_value = str(value).strip()\n",
    "                cleaned[target_key] = (\n",
    "                    str_value[:-2] if str_value.endswith(\".0\") else str_value\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"ISBN 값 '{value}' 처리 중 오류 발생: {e}\")\n",
    "                cleaned[target_key] = str(value).strip()\n",
    "        elif target_key == \"subtitle\":\n",
    "            cleaned[target_key] = str(value)\n",
    "        elif target_key in [\"page\", \"price\"]:\n",
    "            try:\n",
    "                cleaned[target_key] = int(float(value))\n",
    "            except (ValueError, TypeError):\n",
    "                logger.warning(\n",
    "                    f\"'{target_key}' 값 '{value}' 정수 변환 실패. 0으로 설정.\"\n",
    "                )\n",
    "                cleaned[target_key] = 0\n",
    "        else:\n",
    "            cleaned[target_key] = str(value)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "documents = []\n",
    "for i, (pair, meta) in enumerate(zip(all_text_embedding_pairs, all_metadata_list)):\n",
    "    try:\n",
    "        cleaned_meta = clean_metadata(meta)\n",
    "        documents.append(Document(page_content=pair[0], metadata=cleaned_meta))\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            f\"{i}번째 데이터 처리 중 오류 발생: {e}. 메타데이터: {meta}\", exc_info=True\n",
    "        )\n",
    "logger.info(f\"총 {len(documents)}개의 Document 객체 생성 완료.\")\n",
    "\n",
    "texts = [doc.page_content for doc in documents]\n",
    "embeds = [pair[1] for pair in all_text_embedding_pairs[: len(documents)]]\n",
    "metadatas = [doc.metadata for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 20:19:31,407 - INFO - Milvus 유틸리티 함수용 임시 연결 설정 완료 (alias: utility_check_conn).\n",
      "2025-04-07 20:19:31,435 - WARNING - 기존 Milvus 컬렉션 'book_rag_db_v_no_sq'을 삭제.\n",
      "2025-04-07 20:19:31,575 - INFO - Milvus 유틸리티 함수용 임시 연결 해제 완료 (alias: utility_check_conn).\n",
      "2025-04-07 20:19:31,584 - INFO - Langchain Milvus 인스턴스 초기화 및 연결 설정 완료 (컬렉션: 'book_rag_db_v_no_sq').\n",
      "2025-04-07 20:19:31,605 - INFO - 사전 계산된 임베딩 사용: 116218개\n",
      "2025-04-07 20:21:44,923 - INFO - Milvus에 116218개의 텍스트와 임베딩 추가 완료.\n",
      "2025-04-07 20:21:45,328 - INFO - ClovaXEmbeddings.embed_documents 메소드 원상 복구 완료.\n"
     ]
    }
   ],
   "source": [
    "# Milvus Vector DB\n",
    "collection_name = \"book_rag_db_v_no_sq\"\n",
    "temp_conn_alias = \"utility_check_conn\"\n",
    "try:\n",
    "    connections.connect(alias=temp_conn_alias, host=milvus_host, port=milvus_port)\n",
    "    logger.info(\n",
    "        f\"Milvus 유틸리티 함수용 임시 연결 설정 완료 (alias: {temp_conn_alias}).\"\n",
    "    )\n",
    "    if utility.has_collection(collection_name, using=temp_conn_alias):\n",
    "        logger.warning(f\"기존 Milvus 컬렉션 '{collection_name}'을 삭제.\")\n",
    "        utility.drop_collection(collection_name, using=temp_conn_alias)\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Milvus 컬렉션 '{collection_name}'이(가) 존재하지 않음. 새로 생성.\"\n",
    "        )\n",
    "except Exception as e:\n",
    "    logger.error(f\"Milvus 유틸리티 함수 실행 중 오류 발생: {e}\", exc_info=True)\n",
    "finally:\n",
    "    try:\n",
    "        if connections.get_connection_addr(temp_conn_alias):\n",
    "            connections.disconnect(temp_conn_alias)\n",
    "            logger.info(\n",
    "                f\"Milvus 유틸리티 함수용 임시 연결 해제 완료 (alias: {temp_conn_alias}).\"\n",
    "            )\n",
    "    except Exception as disconnect_e:\n",
    "        logger.warning(f\"Milvus 임시 연결 해제 중 오류 (무시 가능): {disconnect_e}\")\n",
    "\n",
    "try:\n",
    "    vectorstore = Milvus(\n",
    "        embedding_function=ncp_embeddings,\n",
    "        collection_name=collection_name,\n",
    "        connection_args={\"host\": milvus_host, \"port\": milvus_port},\n",
    "        auto_id=True,\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Langchain Milvus 인스턴스 초기화 및 연결 설정 완료 (컬렉션: '{collection_name}').\"\n",
    "    )\n",
    "    original_embed_documents = ClovaXEmbeddings.embed_documents\n",
    "\n",
    "    def precomputed_embed_documents(cls, input_texts: List[str]) -> List[List[float]]:\n",
    "        if len(input_texts) == len(texts) and all(\n",
    "            t1 == t2 for t1, t2 in zip(input_texts, texts)\n",
    "        ):\n",
    "            logger.info(f\"사전 계산된 임베딩 사용: {len(embeds)}개\")\n",
    "            return embeds\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"입력 텍스트가 사전 계산된 데이터와 불일치. ClovaX API를 통해 임베딩 수행.\"\n",
    "            )\n",
    "            return original_embed_documents.__func__(cls, input_texts)\n",
    "\n",
    "    ClovaXEmbeddings.embed_documents = classmethod(precomputed_embed_documents)\n",
    "    vectorstore.add_texts(texts=texts, metadatas=metadatas)\n",
    "    logger.info(f\"Milvus에 {len(texts)}개의 텍스트와 임베딩 추가 완료.\")\n",
    "    ClovaXEmbeddings.embed_documents = original_embed_documents\n",
    "    logger.info(\"ClovaXEmbeddings.embed_documents 메소드 원상 복구 완료.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Milvus 데이터 추가 중 오류 발생: {e}\", exc_info=True)\n",
    "    if (\n",
    "        \"original_embed_documents\" in locals()\n",
    "        and hasattr(ClovaXEmbeddings, \"embed_documents\")\n",
    "        and ClovaXEmbeddings.embed_documents != original_embed_documents\n",
    "    ):\n",
    "        ClovaXEmbeddings.embed_documents = original_embed_documents\n",
    "        logger.info(\n",
    "            \"오류 발생 후 ClovaXEmbeddings.embed_documents 메소드 원상 복구 시도 완료.\"\n",
    "        )\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 20:21:47,137 - INFO - Elasticsearch 연결 시도 중: http://localhost:9200...\n",
      "2025-04-07 20:21:50,275 - INFO - HEAD http://localhost:9200/ [status:200 duration:2.496s]\n",
      "2025-04-07 20:21:50,276 - INFO - Elasticsearch 연결 성공\n",
      "2025-04-07 20:21:50,423 - INFO - HEAD http://localhost:9200/book_bm25_index_v2 [status:200 duration:0.143s]\n",
      "2025-04-07 20:21:50,424 - WARNING - 기존 Elasticsearch 인덱스 'book_bm25_index_v2' 삭제 중...\n",
      "C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_7132\\3927000290.py:10: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es_client.indices.delete(index=es_index_name, ignore=[400, 404])\n",
      "2025-04-07 20:22:00,845 - INFO - DELETE http://localhost:9200/book_bm25_index_v2 [status:200 duration:9.916s]\n",
      "2025-04-07 20:22:00,867 - INFO - 기존 Elasticsearch 인덱스 'book_bm25_index_v2' 삭제 완료.\n",
      "2025-04-07 20:22:00,956 - INFO - Langchain ElasticsearchStore 인스턴스 초기화 완료 (인덱스: 'book_bm25_index_v2', BM25 검색 전용).\n",
      "2025-04-07 20:22:00,956 - INFO - Elasticsearch에 문서 인덱싱 시작 (총 116218개)...\n",
      "2025-04-07 20:22:48,123 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:13.723s]\n",
      "2025-04-07 20:22:50,466 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.265s]\n",
      "2025-04-07 20:22:52,111 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.572s]\n",
      "2025-04-07 20:22:53,508 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.340s]\n",
      "2025-04-07 20:22:54,298 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.758s]\n",
      "2025-04-07 20:22:54,983 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.626s]\n",
      "2025-04-07 20:22:55,218 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.205s]\n",
      "2025-04-07 20:22:55,785 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.530s]\n",
      "2025-04-07 20:22:56,118 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.259s]\n",
      "2025-04-07 20:22:56,463 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.289s]\n",
      "2025-04-07 20:22:57,339 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.832s]\n",
      "2025-04-07 20:22:57,569 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.196s]\n",
      "2025-04-07 20:22:57,822 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.220s]\n",
      "2025-04-07 20:22:58,034 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.179s]\n",
      "2025-04-07 20:22:58,307 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.242s]\n",
      "2025-04-07 20:22:58,590 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.247s]\n",
      "2025-04-07 20:22:58,817 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.196s]\n",
      "2025-04-07 20:22:59,033 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.183s]\n",
      "2025-04-07 20:22:59,312 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.245s]\n",
      "2025-04-07 20:22:59,560 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.211s]\n",
      "2025-04-07 20:22:59,817 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.220s]\n",
      "2025-04-07 20:23:00,038 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.186s]\n",
      "2025-04-07 20:23:00,249 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.170s]\n",
      "2025-04-07 20:23:00,513 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.211s]\n",
      "2025-04-07 20:23:00,770 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 20:23:00,986 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.183s]\n",
      "2025-04-07 20:23:01,296 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.279s]\n",
      "2025-04-07 20:23:01,543 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.198s]\n",
      "2025-04-07 20:23:01,843 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.259s]\n",
      "2025-04-07 20:23:02,336 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.454s]\n",
      "2025-04-07 20:23:02,688 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.319s]\n",
      "2025-04-07 20:23:03,033 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.299s]\n",
      "2025-04-07 20:23:03,371 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.291s]\n",
      "2025-04-07 20:23:03,671 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.271s]\n",
      "2025-04-07 20:23:03,949 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.238s]\n",
      "2025-04-07 20:23:04,234 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.253s]\n",
      "2025-04-07 20:23:04,497 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.204s]\n",
      "2025-04-07 20:23:04,775 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.234s]\n",
      "2025-04-07 20:23:05,093 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.277s]\n",
      "2025-04-07 20:23:05,438 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.292s]\n",
      "2025-04-07 20:23:05,684 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.205s]\n",
      "2025-04-07 20:23:05,918 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.200s]\n",
      "2025-04-07 20:23:06,171 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 20:23:06,396 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.193s]\n",
      "2025-04-07 20:23:06,691 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.236s]\n",
      "2025-04-07 20:23:06,933 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.200s]\n",
      "2025-04-07 20:23:07,180 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.208s]\n",
      "2025-04-07 20:23:07,444 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.229s]\n",
      "2025-04-07 20:23:07,782 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.285s]\n",
      "2025-04-07 20:23:07,983 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.166s]\n",
      "2025-04-07 20:23:08,271 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.246s]\n",
      "2025-04-07 20:23:08,500 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.192s]\n",
      "2025-04-07 20:23:08,736 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.208s]\n",
      "2025-04-07 20:23:08,935 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.169s]\n",
      "2025-04-07 20:23:09,191 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.214s]\n",
      "2025-04-07 20:23:09,446 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.224s]\n",
      "2025-04-07 20:23:09,762 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 20:23:10,411 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.608s]\n",
      "2025-04-07 20:23:11,039 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.592s]\n",
      "2025-04-07 20:23:11,786 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.707s]\n",
      "2025-04-07 20:23:12,690 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.867s]\n",
      "2025-04-07 20:23:13,626 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.905s]\n",
      "2025-04-07 20:23:14,464 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.798s]\n",
      "2025-04-07 20:23:15,220 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.715s]\n",
      "2025-04-07 20:23:15,968 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.712s]\n",
      "2025-04-07 20:23:16,985 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.974s]\n",
      "2025-04-07 20:23:17,959 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.939s]\n",
      "2025-04-07 20:23:19,383 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.382s]\n",
      "2025-04-07 20:23:20,402 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.925s]\n",
      "2025-04-07 20:23:21,541 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.083s]\n",
      "2025-04-07 20:23:22,273 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.683s]\n",
      "2025-04-07 20:23:23,014 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.713s]\n",
      "2025-04-07 20:23:23,693 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.642s]\n",
      "2025-04-07 20:23:24,425 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.684s]\n",
      "2025-04-07 20:23:25,218 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.768s]\n",
      "2025-04-07 20:23:25,904 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.639s]\n",
      "2025-04-07 20:23:26,696 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.758s]\n",
      "2025-04-07 20:23:28,547 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.815s]\n",
      "2025-04-07 20:23:31,402 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.804s]\n",
      "2025-04-07 20:23:35,858 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:4.357s]\n",
      "2025-04-07 20:23:36,373 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.437s]\n",
      "2025-04-07 20:23:36,636 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.225s]\n",
      "2025-04-07 20:23:37,011 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.326s]\n",
      "2025-04-07 20:23:40,660 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:3.579s]\n",
      "2025-04-07 20:23:42,560 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.857s]\n",
      "2025-04-07 20:23:43,282 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.667s]\n",
      "2025-04-07 20:23:45,323 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.965s]\n",
      "2025-04-07 20:23:45,692 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 20:23:45,957 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.206s]\n",
      "2025-04-07 20:23:46,261 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.214s]\n",
      "2025-04-07 20:23:46,539 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.235s]\n",
      "2025-04-07 20:23:46,832 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.253s]\n",
      "2025-04-07 20:23:47,155 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.285s]\n",
      "2025-04-07 20:23:47,599 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.396s]\n",
      "2025-04-07 20:23:48,197 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.509s]\n",
      "2025-04-07 20:23:49,763 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.487s]\n",
      "2025-04-07 20:23:50,281 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.381s]\n",
      "2025-04-07 20:23:50,771 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.373s]\n",
      "2025-04-07 20:23:52,262 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.455s]\n",
      "2025-04-07 20:23:52,934 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.633s]\n",
      "2025-04-07 20:23:53,351 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.377s]\n",
      "2025-04-07 20:23:53,668 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.279s]\n",
      "2025-04-07 20:23:54,075 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.344s]\n",
      "2025-04-07 20:23:54,754 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.599s]\n",
      "2025-04-07 20:23:55,344 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.542s]\n",
      "2025-04-07 20:23:55,619 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.231s]\n",
      "2025-04-07 20:23:59,379 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:3.714s]\n",
      "2025-04-07 20:23:59,782 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.361s]\n",
      "2025-04-07 20:24:00,425 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.560s]\n",
      "2025-04-07 20:24:00,911 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.381s]\n",
      "2025-04-07 20:24:01,907 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.932s]\n",
      "2025-04-07 20:24:02,648 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.689s]\n",
      "2025-04-07 20:24:03,018 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.320s]\n",
      "2025-04-07 20:24:03,383 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.323s]\n",
      "2025-04-07 20:24:03,799 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.342s]\n",
      "2025-04-07 20:24:04,194 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.359s]\n",
      "2025-04-07 20:24:04,458 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.224s]\n",
      "2025-04-07 20:24:04,866 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.375s]\n",
      "2025-04-07 20:24:05,235 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.331s]\n",
      "2025-04-07 20:24:05,488 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.213s]\n",
      "2025-04-07 20:24:05,734 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.213s]\n",
      "2025-04-07 20:24:06,649 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.875s]\n",
      "2025-04-07 20:24:06,922 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 20:24:07,321 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.326s]\n",
      "2025-04-07 20:24:07,646 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.284s]\n",
      "2025-04-07 20:24:08,055 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.300s]\n",
      "2025-04-07 20:24:08,361 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.239s]\n",
      "2025-04-07 20:24:08,627 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 20:24:08,912 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.234s]\n",
      "2025-04-07 20:24:09,208 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.248s]\n",
      "2025-04-07 20:24:09,505 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.238s]\n",
      "2025-04-07 20:24:09,828 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.258s]\n",
      "2025-04-07 20:24:10,488 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.609s]\n",
      "2025-04-07 20:24:10,770 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.232s]\n",
      "2025-04-07 20:24:11,112 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.300s]\n",
      "2025-04-07 20:24:11,407 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.248s]\n",
      "2025-04-07 20:24:12,044 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.598s]\n",
      "2025-04-07 20:24:12,365 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.279s]\n",
      "2025-04-07 20:24:12,630 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.216s]\n",
      "2025-04-07 20:24:13,106 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.441s]\n",
      "2025-04-07 20:24:13,464 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.314s]\n",
      "2025-04-07 20:24:13,760 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.237s]\n",
      "2025-04-07 20:24:14,009 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.208s]\n",
      "2025-04-07 20:24:14,335 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 20:24:14,780 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.410s]\n",
      "2025-04-07 20:24:15,049 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.222s]\n",
      "2025-04-07 20:24:15,353 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.257s]\n",
      "2025-04-07 20:24:15,815 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.407s]\n",
      "2025-04-07 20:24:16,060 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.196s]\n",
      "2025-04-07 20:24:16,375 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 20:24:16,659 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.241s]\n",
      "2025-04-07 20:24:17,071 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.376s]\n",
      "2025-04-07 20:24:17,327 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.229s]\n",
      "2025-04-07 20:24:17,675 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.305s]\n",
      "2025-04-07 20:24:18,003 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.291s]\n",
      "2025-04-07 20:24:18,278 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.237s]\n",
      "2025-04-07 20:24:18,606 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.279s]\n",
      "2025-04-07 20:24:18,979 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.337s]\n",
      "2025-04-07 20:24:19,281 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.273s]\n",
      "2025-04-07 20:24:19,529 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.203s]\n",
      "2025-04-07 20:24:19,785 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.220s]\n",
      "2025-04-07 20:24:20,075 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.237s]\n",
      "2025-04-07 20:24:20,355 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.233s]\n",
      "2025-04-07 20:24:20,626 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.244s]\n",
      "2025-04-07 20:24:20,936 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.269s]\n",
      "2025-04-07 20:24:21,256 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.285s]\n",
      "2025-04-07 20:24:21,552 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.258s]\n",
      "2025-04-07 20:24:21,887 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.282s]\n",
      "2025-04-07 20:24:22,261 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.331s]\n",
      "2025-04-07 20:24:22,621 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.296s]\n",
      "2025-04-07 20:24:22,905 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.221s]\n",
      "2025-04-07 20:24:23,202 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.255s]\n",
      "2025-04-07 20:24:23,415 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.182s]\n",
      "2025-04-07 20:24:23,645 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.200s]\n",
      "2025-04-07 20:24:23,902 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.223s]\n",
      "2025-04-07 20:24:24,099 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.173s]\n",
      "2025-04-07 20:24:24,295 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.172s]\n",
      "2025-04-07 20:24:24,571 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.241s]\n",
      "2025-04-07 20:24:24,815 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 20:24:25,010 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.165s]\n",
      "2025-04-07 20:24:25,345 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.308s]\n",
      "2025-04-07 20:24:27,097 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:1.721s]\n",
      "2025-04-07 20:24:27,558 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.429s]\n",
      "2025-04-07 20:24:27,807 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.224s]\n",
      "2025-04-07 20:24:28,021 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.189s]\n",
      "2025-04-07 20:24:28,265 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.210s]\n",
      "2025-04-07 20:24:28,519 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.225s]\n",
      "2025-04-07 20:24:28,854 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.308s]\n",
      "2025-04-07 20:24:29,103 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.218s]\n",
      "2025-04-07 20:24:29,532 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.392s]\n",
      "2025-04-07 20:24:29,778 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.214s]\n",
      "2025-04-07 20:24:30,010 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.202s]\n",
      "2025-04-07 20:24:30,235 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.196s]\n",
      "2025-04-07 20:24:30,474 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.210s]\n",
      "2025-04-07 20:24:30,779 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.276s]\n",
      "2025-04-07 20:24:31,022 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.211s]\n",
      "2025-04-07 20:24:31,283 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.231s]\n",
      "2025-04-07 20:25:50,988 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.300s]\n",
      "2025-04-07 20:25:51,320 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.216s]\n",
      "2025-04-07 20:25:51,589 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.176s]\n",
      "2025-04-07 20:25:51,815 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.165s]\n",
      "2025-04-07 20:25:52,070 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.188s]\n",
      "2025-04-07 20:25:52,322 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.192s]\n",
      "2025-04-07 20:25:52,645 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.266s]\n",
      "2025-04-07 20:25:52,995 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.295s]\n",
      "2025-04-07 20:25:53,269 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.167s]\n",
      "2025-04-07 20:25:53,552 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.204s]\n",
      "2025-04-07 20:25:53,849 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.238s]\n",
      "2025-04-07 20:25:54,117 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.195s]\n",
      "2025-04-07 20:25:54,405 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.217s]\n",
      "2025-04-07 20:25:54,648 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.179s]\n",
      "2025-04-07 20:25:54,912 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.196s]\n",
      "2025-04-07 20:25:55,205 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.230s]\n",
      "2025-04-07 20:25:55,686 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.403s]\n",
      "2025-04-07 20:25:55,999 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.253s]\n",
      "2025-04-07 20:25:56,279 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.215s]\n",
      "2025-04-07 20:25:56,537 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.198s]\n",
      "2025-04-07 20:25:56,796 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.192s]\n",
      "2025-04-07 20:25:57,138 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.229s]\n",
      "2025-04-07 20:25:57,417 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.218s]\n",
      "2025-04-07 20:25:57,749 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.263s]\n",
      "2025-04-07 20:25:58,412 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.577s]\n",
      "2025-04-07 20:26:01,364 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:2.576s]\n",
      "2025-04-07 20:26:02,451 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.652s]\n",
      "2025-04-07 20:26:03,765 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.856s]\n",
      "2025-04-07 20:26:04,370 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.375s]\n",
      "2025-04-07 20:26:05,715 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.950s]\n",
      "2025-04-07 20:26:06,286 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.505s]\n",
      "2025-04-07 20:26:06,770 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.386s]\n",
      "2025-04-07 20:26:07,227 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.382s]\n",
      "2025-04-07 20:26:07,628 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.344s]\n",
      "2025-04-07 20:26:08,087 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.387s]\n",
      "2025-04-07 20:26:08,202 - INFO - PUT http://localhost:9200/_bulk [status:200 duration:0.087s]\n",
      "2025-04-07 20:26:08,204 - INFO - Elasticsearch 벌크 인덱싱 시도 완료: 116218 문서 성공.\n",
      "2025-04-07 20:26:09,146 - INFO - POST http://localhost:9200/book_bm25_index_v2/_refresh [status:200 duration:0.940s]\n",
      "2025-04-07 20:26:09,147 - INFO - Elasticsearch 인덱스 'book_bm25_index_v2' 새로고침 완료.\n",
      "2025-04-07 20:26:09,164 - INFO - Dense retriever (Milvus 벡터 검색) 설정 완료 (k=5).\n",
      "2025-04-07 20:26:09,181 - INFO - HEAD http://localhost:9200/ [status:200 duration:0.013s]\n",
      "2025-04-07 20:26:09,183 - INFO - Sparse retriever (Elasticsearch BM25) 설정 완료 (ElasticsearchRetriever 직접 사용, metadata_field 지정).\n",
      "2025-04-07 20:26:09,185 - INFO - Hybrid ensemble retriever 설정 완료 (Direct ES BM25: 0.5, Milvus Vector: 0.5).\n",
      "2025-04-07 20:26:09,187 - INFO - ISBN Merging Retriever 설정 완료 (Hybrid 결과 기반).\n",
      "2025-04-07 20:26:09,384 - INFO - RetrievalQA 체인 설정 완료 (Merged Hybrid Retriever 사용).\n"
     ]
    }
   ],
   "source": [
    "# Elasticsearch store 설정\n",
    "try:\n",
    "    logger.info(f\"Elasticsearch 연결 시도 중: {es_url}...\")\n",
    "    es_client = Elasticsearch(hosts=[es_url], request_timeout=120)\n",
    "    if not es_client.ping():\n",
    "        raise ConnectionError(\"Elasticsearch 연결 실패. 서버 상태 및 URL 확인 필요.\")\n",
    "    logger.info(\"Elasticsearch 연결 성공\")\n",
    "    if es_client.indices.exists(index=es_index_name):\n",
    "        logger.warning(f\"기존 Elasticsearch 인덱스 '{es_index_name}' 삭제 중...\")\n",
    "        es_client.indices.delete(index=es_index_name, ignore=[400, 404])\n",
    "        logger.info(f\"기존 Elasticsearch 인덱스 '{es_index_name}' 삭제 완료.\")\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Elasticsearch 인덱스 '{es_index_name}' 존재하지 않음. 새로 생성됩니다.\"\n",
    "        )\n",
    "    es_store = ElasticsearchStore(\n",
    "        index_name=es_index_name,\n",
    "        es_connection=es_client,\n",
    "        strategy=ElasticsearchStore.ExactRetrievalStrategy(),\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"Langchain ElasticsearchStore 인스턴스 초기화 완료 (인덱스: '{es_index_name}', BM25 검색 전용).\"\n",
    "    )\n",
    "    logger.info(f\"Elasticsearch에 문서 인덱싱 시작 (총 {len(texts)}개)...\")\n",
    "    actions = [\n",
    "        {\n",
    "            \"_index\": es_index_name,\n",
    "            \"_source\": {\"text\": texts[i], \"metadata\": metadatas[i]},\n",
    "        }\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    "    indexed_count, errors = helpers.bulk(es_client, actions, raise_on_error=False)\n",
    "    logger.info(f\"Elasticsearch 벌크 인덱싱 시도 완료: {indexed_count} 문서 성공.\")\n",
    "    if errors:\n",
    "        logger.error(\n",
    "            f\"Elasticsearch 벌크 인덱싱 중 오류 발생: {len(errors)}개 문서 실패.\"\n",
    "        )\n",
    "        for i, error in enumerate(errors[:5]):\n",
    "            logger.error(f\"  실패 {i+1}: {error}\")\n",
    "    es_client.indices.refresh(index=es_index_name)\n",
    "    logger.info(f\"Elasticsearch 인덱스 '{es_index_name}' 새로고침 완료.\")\n",
    "except ConnectionError as ce:\n",
    "    logger.error(f\"Elasticsearch 연결 실패: {ce}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(\n",
    "        f\"Elasticsearch 설정 또는 데이터 추가 중 오류 발생: {e}\", exc_info=True\n",
    "    )\n",
    "    raise\n",
    "\n",
    "dense_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "logger.info(\"Dense retriever (Milvus 벡터 검색) 설정 완료 (k=5).\")\n",
    "try:\n",
    "    if \"es_client\" not in locals() or not es_client.ping():\n",
    "        raise ConnectionError(\n",
    "            \"Elasticsearch client가 준비되지 않았거나 연결할 수 없습니다.\"\n",
    "        )\n",
    "    sparse_retriever = ElasticsearchRetriever(\n",
    "        es_client=es_client,\n",
    "        index_name=es_index_name,\n",
    "        body_func=lambda query: {\n",
    "            \"size\": 5,\n",
    "            \"query\": {\"match\": {\"text\": {\"query\": query}}},\n",
    "        },\n",
    "        content_field=\"text\",\n",
    "        metadata_field=\"metadata\",\n",
    "    )\n",
    "    logger.info(\n",
    "        \"Sparse retriever (Elasticsearch BM25) 설정 완료 (ElasticsearchRetriever 직접 사용, metadata_field 지정).\"\n",
    "    )\n",
    "except ConnectionError as ce:\n",
    "    logger.error(f\"Elasticsearch 클라이언트 오류: {ce}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"ElasticsearchRetriever 직접 설정 중 오류 발생: {e}\", exc_info=True)\n",
    "    raise\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(\n",
    "    retrievers=[sparse_retriever, dense_retriever], weights=[0.5, 0.5], c=60\n",
    ")\n",
    "logger.info(\n",
    "    \"Hybrid ensemble retriever 설정 완료 (Direct ES BM25: 0.5, Milvus Vector: 0.5).\"\n",
    ")\n",
    "merged_hybrid_retriever = ISBNMergingRetriever(base_retriever=hybrid_retriever)\n",
    "logger.info(\"ISBN Merging Retriever 설정 완료 (Hybrid 결과 기반).\")\n",
    "dpr_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_clova, retriever=merged_hybrid_retriever, return_source_documents=True\n",
    ")\n",
    "logger.info(\"RetrievalQA 체인 설정 완료 (Merged Hybrid Retriever 사용).\")\n",
    "\n",
    "MIN_INFO_LENGTH = 10\n",
    "previous_additional_question_embeddings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 사용자 선호도 추출 프롬프트 (원본)\n",
    "extract_pref_prompt_v2 = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "다음 사용자 발화에서 사용자의 선호도 및 책에 대한 요구사항을 아래 JSON 형식으로 추출해라. 각 항목은 관련된 정보가 명확할 때만 명확한 항목에 포함(예: 소설 -> category)하고, 없다면 빈 리스트 [] 또는 빈 문자열 \"\"로 남겨라. 여러 개가 추출될 수 있는 항목은 리스트로 추출하라.\n",
    "사용자 입력에서 모호한 정보는 implicit info로 포함해라.\n",
    "존재하지 않는 사용자 선호도 정보는 임의로 생성하지 마라.\n",
    "\n",
    "입력: {{ text }}\n",
    "\n",
    "출력 형식 (JSON, 다른 설명 없이 JSON만 출력):\n",
    "{\n",
    "    \"title\": [<!-- 추출된 책 제목 -->],\n",
    "    \"author\": [<!-- 추출된 책 저자 -->],\n",
    "    \"category\": [<!-- 추출된 책 분류/장르 (예: 소설, 에세이, 기술 등) -->],\n",
    "    \"author_intro\": [<!-- 저자 특성 언급/요구사항 -->],\n",
    "    \"book_intro\": [<!-- 줄거리 관련 언급/요구사항 -->],\n",
    "    \"table_of_contents\": [<!-- 세부적인 키워드 언급/요구사항 -->],\n",
    "    \"purpose\": [<!-- 사용자의 독서 목적/이유 (예: 재미, 학습, 시간 때우기, 기분 등) -->],\n",
    "    \"implicit info\": [<!-- 추천해야 할 책에 대한 암시적 정보/특징/분위기 (예: 밝은 분위기, 특정 상황에 어울리는 책, 최신 기술 동향 등) -->]\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 페르소나별 선호도 추출 프롬프트\n",
    "literature_pref_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 다음 사용자 발화에서 **오직 명시적으로 드러난** 문학적 감성 및 책 요구사항만 추출하여 아래 JSON 형식으로 **정확히** 구조화하라.\n",
    "\n",
    "**추출 지침:**\n",
    "1.  **문학적 초점:** 분위기, 문체, 감정선, 작가의 표현 방식, 시대적 배경 등 문학적 요소에 집중하라.\n",
    "2.  **명확성 원칙:** 발화 내용에 명확히 언급된 정보만 해당 필드에 포함시켜라. (예: \"헤르만 헤세\" -> author)\n",
    "3.  **형식 엄수:** 반드시 아래 명시된 JSON 키와 리스트/문자열 형식을 따라야 한다.\n",
    "4.  **정보 부재 처리:** 해당 정보가 없으면 **절대로 임의로 생성하지 말고**, 빈 리스트 `[]` 또는 빈 문자열 `\"\"`로 남겨라.\n",
    "5.  **모호성 처리:** 사용자 의도가 명확하지 않거나 암시적인 정보는 `implicit info` 필드에 문자열로 기록하라. 추론은 금지한다.\n",
    "6.  **리스트 활용:** 제목, 저자 등 여러 개일 수 있는 항목은 반드시 리스트 형식으로 추출하라.\n",
    "\n",
    "**사용자 입력:** {{ text }}\n",
    "\n",
    "**출력 (JSON 객체 외 다른 텍스트 절대 금지):**\n",
    "{\n",
    "    \"title\": [],\n",
    "    \"author\": [],\n",
    "    \"category\": [],\n",
    "    \"author_intro\": [],\n",
    "    \"book_intro\": [],\n",
    "    \"table_of_contents\": [],\n",
    "    \"purpose\": [],\n",
    "    \"implicit info\": []\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "science_pref_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 다음 사용자 발화에서 **오직 명시적으로 드러난** 객관적 사실, 논리적 요구사항, 기술적 명세만 추출하여 아래 JSON 형식으로 **정확히** 구조화하라.\n",
    "\n",
    "**추출 지침:**\n",
    "1.  **과학/기술 초점:** 정확한 정보, 기술 용어, 데이터, 논리적 근거, 전문 분야, 난이도 등에 집중하라.\n",
    "2.  **명확성 원칙:** 발화 내용에 명확히 언급된 정보만 해당 필드에 포함시켜라. (예: \"파이썬 머신러닝\" -> category, table_of_contents)\n",
    "3.  **형식 엄수:** 반드시 아래 명시된 JSON 키와 리스트/문자열 형식을 따라야 한다.\n",
    "4.  **정보 부재 처리:** 해당 정보가 없으면 **절대로 임의로 생성하지 말고**, 빈 리스트 `[]` 또는 빈 문자열 `\"\"`로 남겨라.\n",
    "5.  **모호성 처리:** 사용자 의도가 명확하지 않거나 암시적인 정보는 `implicit info` 필드에 문자열로 기록하라. 추론은 금지한다.\n",
    "6.  **리스트 활용:** 제목, 저자 등 여러 개일 수 있는 항목은 반드시 리스트 형식으로 추출하라.\n",
    "\n",
    "**사용자 입력:** {{ text }}\n",
    "\n",
    "**출력 (JSON 객체 외 다른 텍스트 절대 금지):**\n",
    "{\n",
    "    \"title\": [],\n",
    "    \"author\": [],\n",
    "    \"category\": [],\n",
    "    \"author_intro\": [],\n",
    "    \"book_intro\": [],\n",
    "    \"table_of_contents\": [],\n",
    "    \"purpose\": [],\n",
    "    \"implicit info\": []\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_pref_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 다음 사용자 발화에서 **오직 명시적으로 드러난** 선호도 및 책 요구사항만 추출하여 아래 JSON 형식으로 **정확히** 구조화하라.\n",
    "\n",
    "**추출 지침:**\n",
    "1.  **균형적 초점:** 장르, 저자, 내용, 목적, 분위기 등 다양한 측면의 요구사항을 포착하라.\n",
    "2.  **명확성 원칙:** 발화 내용에 명확히 언급된 정보만 해당 필드에 포함시켜라. (예: \"재미있는 소설\" -> purpose, category)\n",
    "3.  **형식 엄수:** 반드시 아래 명시된 JSON 키와 리스트/문자열 형식을 따라야 한다.\n",
    "4.  **정보 부재 처리:** 해당 정보가 없으면 **절대로 임의로 생성하지 말고**, 빈 리스트 `[]` 또는 빈 문자열 `\"\"`로 남겨라.\n",
    "5.  **모호성 처리:** 사용자 의도가 명확하지 않거나 암시적인 정보는 `implicit info` 필드에 문자열로 기록하라. 추론은 금지한다.\n",
    "6.  **리스트 활용:** 제목, 저자 등 여러 개일 수 있는 항목은 반드시 리스트 형식으로 추출하라.\n",
    "\n",
    "**사용자 입력:** {{ text }}\n",
    "\n",
    "**출력 (JSON 객체 외 다른 텍스트 절대 금지):**\n",
    "{\n",
    "    \"title\": [],\n",
    "    \"author\": [],\n",
    "    \"category\": [],\n",
    "    \"author_intro\": [],\n",
    "    \"book_intro\": [],\n",
    "    \"table_of_contents\": [],\n",
    "    \"purpose\": [],\n",
    "    \"implicit info\": []\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 2. 선호도 통합 프롬프트\n",
    "consolidate_pref_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_preferences\", \"new_preferences\"],\n",
    "    template=\"\"\"\n",
    "기존에 수집된 사용자 선호도 정보와 새로 추출된 선호도 정보가 주어졌다. 두 정보를 지능적으로 통합하여 중복을 제거하고 관련 내용을 요약/결합하여 최종 선호도 목록을 생성해라.\n",
    "\n",
    "[기존 선호도]\n",
    "{{ existing_preferences }}\n",
    "\n",
    "[새로운 선호도]\n",
    "{{ new_preferences }}\n",
    "\n",
    "[통합된 최종 선호도 목록]\n",
    "(아래 목록 형태로만 출력, 각 항목은 문자열 리스트)\n",
    "- 항목1: [\"통합 내용1\", \"통합 내용2\"]\n",
    "- 항목2: [\"통합 내용3\"]\n",
    "...\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 3. Decision Prompt\n",
    "decision_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"history\", \"query\", \"preferences\", \"role_instructions\"],\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "수집된 사용자 선호도:\n",
    "{{ preferences }}\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "\n",
    "현재 대화 상황, 질문, 수집된 선호도를 분석하여 아래 두 가지 행동 중 하나만 결정하고 필요한 정보를 생성해라.\n",
    "- \"추천\": 사용자가 명시적으로 추천을 요청했거나, 사용자의 선호도 정보(예: 카테고리, 저자, 목적, 책 줄거리, 사용자 수준, 분위기 등)를 반드시 3개 이상 수집했을 때 추천.\n",
    "- \"추가 질문\": 정보가 부족하거나 모호할 때, 더 구체적인 선호도 정보를 얻기 위한 추가 질문을 생성.\n",
    "\n",
    "[출력 형식] (반드시 아래 형식만 정확히 따를 것)\n",
    "행동: <추천 또는 추가 질문>\n",
    "추가 질문: <\"추가 질문\" 행동일 경우 구체적인 질문 생성, \"추천\"일 경우 빈 문자열>\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 4. Final Query Generation Prompt - 원본\n",
    "final_query_generation_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "\n",
    "[페르소나 정보]\n",
    "{{ persona_info }}\n",
    "\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "위 정보를 전부 활용하여, 도서 검색에 가장 유용한 **핵심 키워드 중심의 최종 검색 쿼리**를 한 문장으로 작성하라.\n",
    "오직 검색 쿼리 문장만 출력하라.\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "literature_final_query_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "**명령:** 아래 제공된 모든 정보를 **반드시 종합적으로 분석**하여, 문학 도서 검색에 최적화된 **핵심 키워드 중심의 최종 검색 쿼리**를 **단 한 문장**으로 생성하라.\n",
    "\n",
    "**입력 정보:**\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "[페르소나 정보]\n",
    "{{ persona_info }} (감성, 분위기, 문체, 작가 스타일 등 문학적 요소 강조)\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "**쿼리 생성 지침:**\n",
    "1.  **정보 통합:** 모든 입력 정보(대화 맥락, 요청, 페르소나, 선호도)를 누락 없이 반영하라.\n",
    "2.  **키워드 중심:** 검색 시스템이 효과적으로 인식할 수 있는 명사, 핵심 형용사 위주로 구성하라.\n",
    "3.  **문학적 뉘앙스:** 페르소나 정보와 선호도의 감성, 분위기, 문체 관련 내용을 키워드에 포함시키되, 검색 효율성을 해치지 않도록 명료하게 표현하라.\n",
    "4.  **단일 문장:** 최종 결과는 오직 검색 쿼리 한 문장이어야 한다.\n",
    "\n",
    "**출력 (오직 최종 검색 쿼리 한 문장, 다른 설명 절대 금지):**\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "science_final_query_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "**명령:** 아래 제공된 모든 정보를 **반드시 종합적으로 분석**하여, 과학/기술 도서 검색에 최적화된 **정확하고 구체적인 키워드 중심의 최종 검색 쿼리**를 **단 한 문장**으로 생성하라.\n",
    "\n",
    "**입력 정보:**\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "[페르소나 정보]\n",
    "정확하고 논리적인 분석, 최신 기술 동향, 전문 지식, 데이터 기반 접근\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "**쿼리 생성 지침:**\n",
    "1.  **정보 통합:** 모든 입력 정보(대화 맥락, 요청, 페르소나, 선호도)를 누락 없이 반영하라.\n",
    "2.  **키워드 중심:** 검색 시스템이 효과적으로 인식할 수 있는 전문 용어, 기술 명칭, 핵심 개념 위주로 구성하라.\n",
    "3.  **정확성/구체성:** 페르소나 정보와 선호도의 기술 분야, 난이도, 최신성 요구 등을 명확한 키워드로 반영하라.\n",
    "4.  **단일 문장:** 최종 결과는 오직 검색 쿼리 한 문장이어야 한다.\n",
    "\n",
    "**출력 (오직 최종 검색 쿼리 한 문장, 다른 설명 절대 금지):**\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_final_query_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "**명령:** 아래 제공된 모든 정보를 **반드시 종합적으로 분석**하여, 범용 도서 검색에 가장 유용한 **핵심 키워드 중심의 최종 검색 쿼리**를 **단 한 문장**으로 생성하라.\n",
    "\n",
    "**입력 정보:**\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "[페르소나 정보]\n",
    "{{ persona_info }} (친절, 균형잡힌 정보, 다양한 분야 포괄)\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "**쿼리 생성 지침:**\n",
    "1.  **정보 통합:** 모든 입력 정보(대화 맥락, 요청, 페르소나, 선호도)를 누락 없이 반영하라.\n",
    "2.  **키워드 중심:** 검색 시스템이 효과적으로 인식할 수 있는 명확한 명사, 핵심 요구사항 키워드 위주로 구성하라.\n",
    "3.  **균형과 명료성:** 다양한 선호도를 반영하되, 가장 핵심적인 요구사항을 명확한 키워드로 표현하여 검색 효율성을 높여라.\n",
    "4.  **단일 문장:** 최종 결과는 오직 검색 쿼리 한 문장이어야 한다.\n",
    "\n",
    "**출력 (오직 최종 검색 쿼리 한 문장, 다른 설명 절대 금지):**\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 5. Refine Prompt - 원본\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "주어진 검색 쿼리를 분석하여, 검색 엔진이나 다음 단계에서 사용하기 좋은 명확하고 간결한 단일 문장으로 정제해라. 불필요한 설명 없이 오직 정제된 쿼리 문장만 출력하라.\n",
    "\n",
    "- \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 등의 표현이 있으면 해당 책/저자의 특징(예: 장르, 분위기, 핵심 소재, 작가 스타일)을 반영하여 확장하라. 단, 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "예시:\n",
    "(입력: 해리포터 시리즈물 같은 판타지 소설 알려줘)\n",
    "1. 마법학교 배경의 청소년 판타지 소설 추천\n",
    "2. 선과 악의 대결을 다룬 영국 판타지 시리즈\n",
    "3. 성장 서사를 담은 인기 판타지 소설\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "literature_refine_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]를 아래 지침에 따라 **문학적 감성을 반영**하면서도 **검색에 용이한 간결한 단일 문장**으로 정제하라.\n",
    "\n",
    "**정제 지침:**\n",
    "1.  **유사성 표현 처리:** \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 등의 표현이 있으면, 해당 대상의 **문학적 특징(장르, 문체, 감정선, 시대 등)을 분석하여 명시적인 키워드로 확장**하라. 단, 원본의 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "    *   예시 (입력: '데미안' 같은 성장 소설) -> 정제: 내면 성찰을 다루는 철학적 성장 소설 추천\n",
    "2.  **핵심 의도 유지:** 원본 쿼리의 핵심 검색 의도는 반드시 보존해야 한다.\n",
    "3.  **간결성 및 명확성:** 불필요한 수식어나 설명은 제거하고, 검색 키워드가 될 수 있는 명료한 단어 위주로 구성하라.\n",
    "4.  **문학적 표현:** 서정적이거나 감성적인 표현을 사용하되, 검색 시스템이 이해할 수 있는 수준을 유지하라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 정제된 단일 검색 쿼리 문장, 다른 설명 절대 금지):**\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "science_refine_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]를 아래 지침에 따라 **객관적이고 논리적인 표현**을 사용하여 **정확하고 간결한 단일 문장**으로 정제하라.\n",
    "\n",
    "**정제 지침:**\n",
    "1.  **유사성 표현 처리:** \"~~비슷한\", \"~ 같은\" 등의 표현이 있으면, 해당 대상의 **기술적 특징(핵심 기술, 분야, 방법론, 난이도 등)을 분석하여 명시적인 키워드로 확장**하라. 단, 원본의 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "    *   예시 (입력: '핸즈온 머신러닝' 같은 책) -> 정제: 사이킷런과 텐서플로우 예제 중심의 실습형 머신러닝 입문서 추천\n",
    "2.  **핵심 의도 유지:** 원본 쿼리의 핵심 검색 의도는 반드시 보존해야 한다.\n",
    "3.  **간결성 및 정확성:** 불필요한 표현은 제거하고, 정확한 기술 용어와 핵심 개념 위주로 구성하라.\n",
    "4.  **객관적 표현:** 주관적이거나 모호한 표현 대신, 명확하고 객관적인 과학/기술 용어를 사용하라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 정제된 단일 검색 쿼리 문장, 다른 설명 절대 금지):**\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_refine_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]를 아래 지침에 따라 **사용자 의도를 명확히 반영**하여 **친절하고 이해하기 쉬운 간결한 단일 문장**으로 정제하라.\n",
    "\n",
    "**정제 지침:**\n",
    "1.  **유사성 표현 처리:** \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 등의 표현이 있으면, 해당 대상의 **주요 특징(장르, 핵심 소재, 스타일, 목적 등)을 분석하여 명시적인 키워드로 확장**하라. 단, 원본의 책 제목이나 저자 이름은 직접 포함하지 마라.\n",
    "    *   예시 (입력: '나미야 잡화점의 기적' 같은 힐링 소설) -> 정제: 따뜻한 위로와 감동을 주는 일본 힐링 소설 추천\n",
    "2.  **핵심 의도 유지:** 원본 쿼리의 핵심 검색 의도는 반드시 보존해야 한다.\n",
    "3.  **간결성 및 명확성:** 불필요한 수식어나 모호한 표현은 제거하고, 사용자의 요구사항을 명확히 나타내는 단어 위주로 구성하라.\n",
    "4.  **친절한 표현:** 딱딱하거나 전문적이지 않은, 일반 사용자가 이해하기 쉬운 표현을 사용하라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 정제된 단일 검색 쿼리 문장, 다른 설명 절대 금지):**\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "\n",
    "# 6. Query Expansion Prompt - 원본\n",
    "query_expansion_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "주어진 원본 검색 쿼리를 바탕으로, 관련성이 높으면서도 다양한 측면을 탐색할 수 있는 확장된 검색 쿼리 3개를 생성해라. 확장된 쿼리는 원본 쿼리의 핵심 의도를 반드시 유지해야 한다. 다른 설명이나 서론 없이, 오직 번호(1., 2., 3.)가 매겨진 목록으로 한 줄에 하나씩 출력해라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "literature_expansion_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]의 **핵심 의도를 반드시 유지**하면서, **문학적 감성과 관련된 다양한 측면(유사 장르, 다른 시대, 관련 주제, 다른 작가 등)을 탐색**할 수 있는 **관련성 높은 확장 검색 쿼리 3개**를 생성하라.\n",
    "\n",
    "**확장 지침:**\n",
    "1.  **핵심 의도 유지:** 확장 쿼리는 원본 쿼리의 주제나 분위기에서 크게 벗어나서는 안 된다.\n",
    "2.  **문학적 다양성 추구:** 원본 쿼리와 관련되면서도 다른 각도(예: 다른 감정선, 문체, 배경)에서 탐색할 수 있도록 다양하게 생성하라.\n",
    "3.  **관련성:** 생성된 쿼리는 원본 쿼리와 명확한 관련성을 가져야 한다.\n",
    "4.  **형식 엄수:** **번호(1., 2., 3.)가 매겨진 목록 형식**으로, 각 줄에 확장 쿼리 하나씩만 출력하라. 다른 설명은 절대 포함하지 마라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 번호 매겨진 확장 쿼리 목록 3개, 다른 설명 절대 금지):**\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "science_expansion_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]의 **핵심 의도를 반드시 유지**하면서, **과학/기술 관련 하위 주제, 관련 기술, 응용 분야, 다른 접근법 등을 탐색**할 수 있는 **관련성 높은 확장 검색 쿼리 3개**를 생성하라.\n",
    "\n",
    "**확장 지침:**\n",
    "1.  **핵심 의도 유지:** 확장 쿼리는 원본 쿼리의 기술 분야나 주제에서 크게 벗어나서는 안 된다.\n",
    "2.  **기술적 다양성 추구:** 원본 쿼리와 관련되면서도 다른 각도(예: 심화 이론, 실용적 적용, 다른 프로그래밍 언어, 최신 연구)에서 탐색할 수 있도록 다양하게 생성하라.\n",
    "3.  **관련성:** 생성된 쿼리는 원본 쿼리와 명확한 기술적/논리적 관련성을 가져야 한다.\n",
    "4.  **형식 엄수:** **번호(1., 2., 3.)가 매겨진 목록 형식**으로, 각 줄에 확장 쿼리 하나씩만 출력하라. 다른 설명은 절대 포함하지 마라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 번호 매겨진 확장 쿼리 목록 3개, 다른 설명 절대 금지):**\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "general_expansion_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "**명령:** 주어진 [원본 검색 쿼리]의 **핵심 의도를 반드시 유지**하면서, **관련 주제, 다른 관점, 사용자의 잠재적 관심사 등 다양한 분야를 탐색**할 수 있는 **관련성 높은 확장 검색 쿼리 3개**를 생성하라.\n",
    "\n",
    "**확장 지침:**\n",
    "1.  **핵심 의도 유지:** 확장 쿼리는 원본 쿼리의 핵심 주제나 요구사항에서 크게 벗어나서는 안 된다.\n",
    "2.  **주제 다양성 추구:** 원본 쿼리와 관련되면서도 다른 각도(예: 유사하지만 다른 장르, 관련 인물 이야기, 사회적 배경)에서 탐색할 수 있도록 다양하게 생성하라.\n",
    "3.  **관련성:** 생성된 쿼리는 원본 쿼리와 명확한 관련성을 가져야 한다.\n",
    "4.  **형식 엄수:** **번호(1., 2., 3.)가 매겨진 목록 형식**으로, 각 줄에 확장 쿼리 하나씩만 출력하라. 다른 설명은 절대 포함하지 마라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "**출력 (오직 번호 매겨진 확장 쿼리 목록 3개, 다른 설명 절대 금지):**\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 7. Re_ranking Prompt\n",
    "re_ranking_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"documents\"],\n",
    "    template=\"\"\"\n",
    "사용자의 검색 쿼리는 다음과 같습니다: \"{{ query }}\"\n",
    "다음은 검색된 도서 목록입니다 (내용은 일부만 표시됨):\n",
    "{% for doc in documents %}\n",
    "{{ loop.index }}. 제목: {{ doc.metadata.get('title', '제목 없음') }}, 저자: {{ doc.metadata.get('author', '저자 없음') }}, 내용 일부: {{ doc.page_content | truncate(200) }}\n",
    "{% endfor %}\n",
    "\n",
    "위 검색 결과를 사용자의 검색 쿼리 \"{{ query }}\"와의 관련성 및 문서 내용의 충실도를 종합적으로 고려하여, 가장 관련성이 높은 도서를 목록의 맨 위로 배치하고, 결과를 도서 제목과 저자만 포함하는 다음 형식으로 출력하라.\n",
    "\n",
    "[출력 형식 예시]\n",
    "1. 제목: <가장 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "2. 제목: <두 번째 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "...\n",
    "[리랭킹된 도서 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 8. HyDE Generation Prompt\n",
    "hyde_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "다음 검색 쿼리에 완벽하게 부합하는 **이상적인 가상의 책**을 추천하고, 이를 기반으로 **간결한 요약(2-3 문장)**을 생성해라. 이 요약은 해당 쿼리로 책을 찾는 사용자가 가장 만족할 만한 내용을 담아야 한다. 오직 생성된 요약 텍스트만 출력하라.\n",
    "\n",
    "[검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[가상의 책 요약]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 9. Persona Role Instructions\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 깊이 이해하고 공감하는 말투로 문학적인 표현을 사용하여 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 지식 수준과 관심 분야를 파악하고, 최신 정보와 기술 동향을 반영하여 체계적으로 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다. 친근한 말투로 다양한 분야의 책에 대해 균형 잡힌 시각으로 정보를 제공하고, 사용자의 요구사항에 맞춰 명확하고 이해하기 쉽게 책을 추천해라.\"\n",
    "\n",
    "# 10. Hyde Keyword Prompt\n",
    "hyde_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"hyde_summary\"],\n",
    "    template=\"\"\"\n",
    "다음은 사용자의 질문에 이상적으로 부합하는 가상의 책 요약입니다:\n",
    "\"{{ hyde_summary }}\"\n",
    "\n",
    "이 요약 내용에서 **핵심 키워드 5개**를 추출하여 쉼표(,)로 구분하여 나열해라. 오직 키워드 목록만 출력하라.\n",
    "\n",
    "[핵심 키워드 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_invoke(chain: LLMChain, vars_dict: dict, step_name: str) -> dict:\n",
    "    \"\"\"LLMChain을 비동기로 실행하고 로깅\"\"\"\n",
    "    try:\n",
    "        # 입력 변수 일부 로깅\n",
    "        log_vars = {\n",
    "            k: (v[:100] + \"...\" if isinstance(v, str) and len(v) > 100 else v)\n",
    "            for k, v in vars_dict.items()\n",
    "        }\n",
    "        logger.debug(f\"[{step_name}] Chain 호출 시작. 입력 변수 일부: {log_vars}\")\n",
    "        # chain.invoke를 별도 스레드에서 실행하여 비동기 처리\n",
    "        result = await asyncio.to_thread(chain.invoke, vars_dict)\n",
    "        result_text = result.get(\"text\", \"\")\n",
    "        # 결과 텍스트 일부 로깅\n",
    "        log_result = (\n",
    "            result_text[:200] + \"...\" if len(result_text) > 200 else result_text\n",
    "        )\n",
    "        logger.debug(f\"[{step_name}] Chain 호출 완료. 결과 일부: {log_result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step_name}] Chain 호출 중 예외 발생: {e}\", exc_info=True)\n",
    "        return {\"text\": \"\"}  # 오류 시 빈 결과 반환\n",
    "\n",
    "\n",
    "async def async_invoke_llm(prompt: str, step_name: str) -> str:\n",
    "    \"\"\"LLM 직접 호출을 비동기로 실행하고 로깅\"\"\"\n",
    "    try:\n",
    "        # 프롬프트 일부 로깅\n",
    "        log_prompt = prompt[:200] + \"...\" if len(prompt) > 200 else prompt\n",
    "        logger.debug(f\"[{step_name}] LLM 호출 시작. 프롬프트 일부: {log_prompt}\")\n",
    "        # llm.invoke를 별도 스레드에서 실행\n",
    "        response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
    "\n",
    "        # 응답 객체에서 텍스트 추출\n",
    "        if hasattr(response, \"content\"):\n",
    "            result_text = response.content.strip()\n",
    "        elif isinstance(response, str):  # ChatClovaX가 문자열 직접 반환하는 경우\n",
    "            result_text = response.strip()\n",
    "        else:\n",
    "            result_text = str(response).strip()\n",
    "\n",
    "        # 응답 텍스트 일부 로깅\n",
    "        log_result = (\n",
    "            result_text[:200] + \"...\" if len(result_text) > 200 else result_text\n",
    "        )\n",
    "        logger.debug(f\"[{step_name}] LLM 호출 완료. 응답 일부: {log_result}\")\n",
    "        return result_text\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[{step_name}] LLM 호출 중 예외 발생: {e}\", exc_info=True)\n",
    "        return \"\"  # 오류 시 빈 문자열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_metadata_field(doc: Document, field: str, default: str = \"N/A\") -> str:\n",
    "    \"\"\"\n",
    "    Document의 다양한 metadata 구조에서 필드 값을 추출 (예: title, ISBN 등).\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    # Case 1: 평평한 구조\n",
    "    candidates.append(doc.metadata)\n",
    "\n",
    "    # Case 2: 1단계 중첩\n",
    "    if \"metadata\" in doc.metadata and isinstance(doc.metadata[\"metadata\"], dict):\n",
    "        candidates.append(doc.metadata[\"metadata\"])\n",
    "\n",
    "        # Case 3: 2단계 중첩\n",
    "        inner = doc.metadata[\"metadata\"]\n",
    "        if \"metadata\" in inner and isinstance(inner[\"metadata\"], dict):\n",
    "            candidates.append(inner[\"metadata\"])\n",
    "\n",
    "    # Case 4: Elasticsearch 구조 (_source.metadata)\n",
    "    if \"_source\" in doc.metadata and isinstance(doc.metadata[\"_source\"], dict):\n",
    "        source_meta = doc.metadata[\"_source\"].get(\"metadata\", {})\n",
    "        if isinstance(source_meta, dict):\n",
    "            candidates.append(source_meta)\n",
    "\n",
    "    # 실제 값 추출\n",
    "    for meta in candidates:\n",
    "        if field in meta:\n",
    "            return (\n",
    "                meta[field].strip()\n",
    "                if isinstance(meta[field], str)\n",
    "                else str(meta[field])\n",
    "            )\n",
    "\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRAGPipeline:\n",
    "    def __init__(\n",
    "        self, config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "    ):\n",
    "        self.config = config  # config에 페르소나별 템플릿 및 가중치 포함\n",
    "        self.llm = llm\n",
    "        self.embeddings = embeddings\n",
    "        self.vectorstore = vectorstore\n",
    "        self.es_store = es_store\n",
    "        self.retriever = retriever\n",
    "        self.documents = documents\n",
    "\n",
    "        self.user_history: List[str] = []\n",
    "        self.llm_history: List[str] = []\n",
    "        self.user_preferences: Dict[str, List[str]] = self._initialize_preferences()\n",
    "        self.preferences_text: str = \"수집된 선호도 없음\"\n",
    "        self.preference_update_count: int = 0\n",
    "        self.last_recommendations: List[Document] = []\n",
    "        self.last_action: Optional[str] = None\n",
    "\n",
    "        # 페르소나별 프롬프트 체인 생성\n",
    "        self.extract_pref_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"pref_extraction_template\"]\n",
    "        )\n",
    "        self.decision_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"decision_template\", None)\n",
    "        )\n",
    "        self.final_query_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"final_query_template\"]\n",
    "        )\n",
    "        self.refine_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"refine_template\"]\n",
    "        )\n",
    "        self.query_expansion_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config[\"expansion_template\"]\n",
    "        )\n",
    "        self.re_ranking_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"re_ranking_template\", None)\n",
    "        )\n",
    "        self.hyde_generation_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"hyde_generation_template\", None)\n",
    "        )\n",
    "        self.hyde_keyword_chain = LLMChain(\n",
    "            llm=self.llm, prompt=self.config.get(\"hyde_keyword_template\", None)\n",
    "        )\n",
    "\n",
    "    def _initialize_preferences(self) -> Dict[str, List[str]]:\n",
    "        return {\n",
    "            \"title\": [],\n",
    "            \"author\": [],\n",
    "            \"category\": [],\n",
    "            \"author_intro\": [],\n",
    "            \"book_intro\": [],\n",
    "            \"table_of_contents\": [],\n",
    "            \"purpose\": [],\n",
    "            \"implicit info\": [],\n",
    "        }\n",
    "\n",
    "    def robust_parse_decision_response(\n",
    "        self, response_text: str\n",
    "    ) -> tuple[Optional[str], str]:\n",
    "        action = None\n",
    "        additional_question = \"\"\n",
    "        action_match = re.search(r'행동\\s*[:：]\\s*\"?([^\"\\n]+)\"?', response_text)\n",
    "        if action_match:\n",
    "            action = action_match.group(1).strip().lower()\n",
    "            if action not in [\"추천\", \"추가 질문\"]:\n",
    "                logger.warning(\n",
    "                    f\"알 수 없는 행동 값 파싱됨: '{action}'. '추가 질문'으로 처리.\"\n",
    "                )\n",
    "                action = \"추가 질문\"\n",
    "        follow_match = re.search(\n",
    "            r'추가\\s*질문\\s*[:：]\\s*\"?(.+)\"?', response_text, re.DOTALL\n",
    "        )\n",
    "        if follow_match:\n",
    "            additional_question = follow_match.group(1).strip()\n",
    "        if action == \"추가 질문\" and not additional_question:\n",
    "            additional_question = \"어떤 점이 궁금하신가요? 또는 어떤 책을 찾으시나요?\"\n",
    "            logger.warning(\n",
    "                f\"행동은 '추가 질문'이나 질문 내용 없음. 기본 질문 사용: '{additional_question}'\"\n",
    "            )\n",
    "        if not action:\n",
    "            logger.warning(\n",
    "                f\"행동 결정 파싱 실패: '{response_text}'. 기본 '추가 질문'으로 처리.\"\n",
    "            )\n",
    "            action = \"추가 질문\"\n",
    "            if not additional_question:\n",
    "                additional_question = \"요청을 이해하기 어려웠습니다. 어떤 책을 찾으시는지 다시 말씀해주시겠어요?\"\n",
    "        logger.info(\n",
    "            f\"행동 결정 파싱 결과: 행동='{action}', 추가 질문='{additional_question[:50]}...'\"\n",
    "        )\n",
    "        return action, additional_question\n",
    "\n",
    "    async def update_preferences_from_input(self, user_input: str) -> None:\n",
    "        logger.info(f\"사용자 입력에서 선호도 추출 시작: '{user_input[:100]}...'\")\n",
    "        extract_result = await async_invoke(\n",
    "            self.extract_pref_chain, {\"text\": user_input}, \"선호도 추출\"\n",
    "        )\n",
    "        extracted_text = extract_result.get(\"text\", \"{}\")\n",
    "        extracted_prefs: Dict[str, List[str]] = {}\n",
    "        try:\n",
    "            json_match = re.search(r\"\\{.*\\}\", extracted_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                extracted_prefs_raw = json.loads(json_match.group(0))\n",
    "                defined_keys = self.user_preferences.keys()\n",
    "                for key, value in extracted_prefs_raw.items():\n",
    "                    if key in defined_keys:\n",
    "                        vals_to_add = []\n",
    "                        if isinstance(value, list):\n",
    "                            vals_to_add = [\n",
    "                                str(item).strip()\n",
    "                                for item in value\n",
    "                                if item and str(item).strip()\n",
    "                            ]\n",
    "                        elif isinstance(value, str) and value.strip():\n",
    "                            vals_to_add = [value.strip()]\n",
    "                        if vals_to_add:\n",
    "                            extracted_prefs[key] = vals_to_add\n",
    "                    else:\n",
    "                        logger.warning(\n",
    "                            f\"추출된 선호도 키 '{key}'가 정의된 형식에 없음. 무시.\"\n",
    "                        )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"선호도 추출 결과에서 JSON 객체를 찾을 수 없음: {extracted_text}\"\n",
    "                )\n",
    "        except json.JSONDecodeError as e:\n",
    "            logger.error(\n",
    "                f\"선호도 추출 결과 JSON 파싱 실패: {e}. 원본 텍스트: {extracted_text}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"선호도 추출/처리 중 예외 발생: {e}\", exc_info=True)\n",
    "        if not extracted_prefs:\n",
    "            logger.info(\"새로 추출된 유효한 선호도 정보가 없음\")\n",
    "            return\n",
    "        updated_something = False\n",
    "        for key, new_values in extracted_prefs.items():\n",
    "            existing_values_set = set(self.user_preferences.get(key, []))\n",
    "            added_values = [v for v in new_values if v not in existing_values_set]\n",
    "            if added_values:\n",
    "                self.user_preferences[key].extend(added_values)\n",
    "                updated_something = True\n",
    "                logger.info(f\"선호도 업데이트됨 [{key}]: {self.user_preferences[key]}\")\n",
    "        if updated_something:\n",
    "            self.preference_update_count += 1\n",
    "            logger.info(\n",
    "                f\"선호도 업데이트 완료. 누적 업데이트 횟수: {self.preference_update_count}\"\n",
    "            )\n",
    "            self._update_preferences_text()\n",
    "        else:\n",
    "            logger.info(\"기존 선호도에서 변경된 내용 없음.\")\n",
    "\n",
    "    def _update_preferences_text(self):\n",
    "        pref_items = []\n",
    "        display_key_map = {\n",
    "            \"title\": \"관련 제목\",\n",
    "            \"author\": \"선호 저자\",\n",
    "            \"category\": \"선호 장르/분류\",\n",
    "            \"author_intro\": \"저자 관련 요구\",\n",
    "            \"book_intro\": \"내용 관련 요구\",\n",
    "            \"table_of_contents\": \"목차/키워드 요구\",\n",
    "            \"purpose\": \"독서 목적\",\n",
    "            \"implicit info\": \"기타 희망 사항/분위기\",\n",
    "        }\n",
    "        for key, values in self.user_preferences.items():\n",
    "            if values:\n",
    "                display_key = display_key_map.get(key, key)\n",
    "                pref_items.append(f\"- {display_key}: {', '.join(values)}\")\n",
    "        self.preferences_text = (\n",
    "            \"\\n\".join(pref_items) if pref_items else \"수집된 선호도 없음\"\n",
    "        )\n",
    "        logger.debug(f\"업데이트된 선호도 요약 텍스트:\\n{self.preferences_text}\")\n",
    "\n",
    "    async def get_final_query(self, current_user_query: str) -> str:\n",
    "        logger.info(\"최종 검색 쿼리 생성 시작\")\n",
    "        persona_info = self.config.get(\"persona_info\", \"기본 정보\")\n",
    "        final_query_vars = {\n",
    "            \"history\": \"\\n\".join(self.user_history[-5:] + self.llm_history[-5:]),\n",
    "            \"query\": current_user_query,\n",
    "            \"persona_info\": persona_info,\n",
    "            \"preferences\": self.preferences_text,\n",
    "        }\n",
    "        result_gen = await async_invoke(\n",
    "            self.final_query_generation_chain, final_query_vars, \"선호도 종합 쿼리 생성\"\n",
    "        )\n",
    "        generated_query = result_gen.get(\"text\", \"\").strip()\n",
    "        logger.info(f\"LLM 생성 쿼리 (정제 전): '{generated_query}'\")\n",
    "        query_to_use = generated_query\n",
    "        if generated_query:\n",
    "            refine_result = await async_invoke(\n",
    "                self.refine_chain, {\"query\": generated_query}, \"쿼리 정제\"\n",
    "            )\n",
    "            refined_query = refine_result.get(\"text\", \"\").strip().strip('\"')\n",
    "            logger.info(f\"정제된 쿼리: '{refined_query}'\")\n",
    "            negative_keywords = [\n",
    "                \"없\",\n",
    "                \"못\",\n",
    "                \"않\",\n",
    "                \"오류\",\n",
    "                \"잘못\",\n",
    "                \"알 수 없\",\n",
    "                \"죄송\",\n",
    "                \"필요\",\n",
    "            ]\n",
    "            is_invalid_refinement = (\n",
    "                not refined_query\n",
    "                or len(refined_query) < 3\n",
    "                or any(keyword in refined_query for keyword in negative_keywords)\n",
    "                or \"{\" in refined_query\n",
    "                or \"}\" in refined_query\n",
    "                or refined_query.lower() == generated_query.lower()\n",
    "            )\n",
    "            if is_invalid_refinement:\n",
    "                logger.warning(\n",
    "                    f\"정제된 쿼리('{refined_query}')가 유효하지 않아 정제 전 쿼리('{generated_query}') 사용.\"\n",
    "                )\n",
    "            else:\n",
    "                query_to_use = refined_query\n",
    "        else:\n",
    "            logger.warning(\"선호도 종합 쿼리 생성 실패. 원본 사용자 쿼리 사용.\")\n",
    "            query_to_use = current_user_query\n",
    "        if not query_to_use or len(query_to_use) < 3:\n",
    "            logger.warning(\n",
    "                f\"최종 결정된 쿼리('{query_to_use}')가 너무 짧거나 비어있어 원본 사용자 쿼리('{current_user_query}') 사용.\"\n",
    "            )\n",
    "            query_to_use = current_user_query\n",
    "        logger.info(f\"최종 결정된 검색 쿼리: '{query_to_use}'\")\n",
    "        return query_to_use\n",
    "\n",
    "    async def _summarize_chunk_with_llm(self, text: str) -> str:\n",
    "        if not text or len(text.strip()) < MIN_INFO_LENGTH:\n",
    "            return \"요약할 정보가 충분하지 않습니다.\"\n",
    "        max_len = 4000\n",
    "        truncated_text = text[:max_len].strip()\n",
    "        if not truncated_text:\n",
    "            return \"요약할 정보가 없습니다.\"\n",
    "        prompt = f\"다음 책 정보를 2~3 문장으로 핵심 내용만 명확하게 요약해줘:\\n\\n{truncated_text}\\n\\n요약:\"\n",
    "        summary = await async_invoke_llm(prompt, \"청크 요약\")\n",
    "        if (\n",
    "            not summary\n",
    "            or len(summary) < 10\n",
    "            or \"요약할 정보가\" in summary\n",
    "            or \"죄송\" in summary\n",
    "            or \"모르겠\" in summary\n",
    "        ):\n",
    "            fallback_summary = text[:300].strip() + (\"...\" if len(text) > 300 else \"\")\n",
    "            logger.warning(\n",
    "                f\"LLM 요약 실패 또는 부적절. Fallback 요약 사용: '{fallback_summary[:100]}...'\"\n",
    "            )\n",
    "            return (\n",
    "                fallback_summary\n",
    "                if fallback_summary\n",
    "                else \"별도의 상세 정보가 충분치 않습니다.\"\n",
    "            )\n",
    "        return summary\n",
    "\n",
    "    def _merge_documents_by_isbn(self, isbn: str) -> Optional[Document]:\n",
    "        if not isbn:\n",
    "            logger.warning(\"ISBN 없이 문서 병합 시도됨.\")\n",
    "            return None\n",
    "        docs_for_isbn = [\n",
    "            doc\n",
    "            for doc in self.documents\n",
    "            if str(doc.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "        ]\n",
    "        if not docs_for_isbn:\n",
    "            logger.warning(\n",
    "                f\"ISBN '{isbn}'에 해당하는 문서를 마스터 목록에서 찾을 수 없음.\"\n",
    "            )\n",
    "            return None\n",
    "        combined_text = \"\\n\\n---\\n\\n\".join(\n",
    "            doc.page_content for doc in docs_for_isbn if doc.page_content\n",
    "        ).strip()\n",
    "        merged_meta = dict(docs_for_isbn[0].metadata)\n",
    "        logger.debug(\n",
    "            f\"ISBN '{isbn}' 문서 병합 완료 (전체 원본 기준). 병합된 청크 수: {len(docs_for_isbn)}, 총 텍스트 길이: {len(combined_text)}\"\n",
    "        )\n",
    "        return Document(page_content=combined_text, metadata=merged_meta)\n",
    "\n",
    "    async def _embedding_rerank_documents(\n",
    "        self, query: str, documents: List[Document]\n",
    "    ) -> List[Document]:\n",
    "        if not documents:\n",
    "            logger.info(\"리랭킹할 문서가 없습니다.\")\n",
    "            return []\n",
    "        embedding_tasks = {\n",
    "            \"main\": asyncio.to_thread(self.embeddings.embed_query, query)\n",
    "        }\n",
    "        if self.user_preferences.get(\"author\"):\n",
    "            embedding_tasks[\"author\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"author\"][0]\n",
    "            )\n",
    "        if self.user_preferences.get(\"title\"):\n",
    "            embedding_tasks[\"title\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"title\"][0]\n",
    "            )\n",
    "        if self.user_preferences.get(\"category\"):\n",
    "            embedding_tasks[\"category\"] = asyncio.to_thread(\n",
    "                self.embeddings.embed_query, self.user_preferences[\"category\"][0]\n",
    "            )\n",
    "        query_embeddings = await asyncio.gather(*embedding_tasks.values())\n",
    "        query_embedding_map = dict(zip(embedding_tasks.keys(), query_embeddings))\n",
    "        # 페르소나별 retrieval_weights 사용 (없으면 기본값)\n",
    "        weights = self.config.get(\n",
    "            \"retrieval_weights\",\n",
    "            {\"main\": 0.1, \"author\": 0.3, \"title\": 0.1, \"category\": 0.5},\n",
    "        )\n",
    "        scored_docs = []\n",
    "        for doc in documents:\n",
    "            score_map: Dict[str, float] = {}\n",
    "            real_meta = doc.metadata.get(\"metadata\", doc.metadata)\n",
    "            doc_embedding = await asyncio.to_thread(\n",
    "                self.embeddings.embed_query, doc.page_content\n",
    "            )\n",
    "            score_map[\"main\"] = cosine_similarity(\n",
    "                [query_embedding_map[\"main\"]], [doc_embedding]\n",
    "            )[0][0]\n",
    "            author_text = real_meta.get(\"author\", \"\")\n",
    "            if author_text and \"author\" in query_embedding_map:\n",
    "                author_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, author_text\n",
    "                )\n",
    "                score_map[\"author\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"author\"]], [author_emb]\n",
    "                )[0][0]\n",
    "            title_text = real_meta.get(\"title\", \"\")\n",
    "            if title_text and \"title\" in query_embedding_map:\n",
    "                title_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, title_text\n",
    "                )\n",
    "                score_map[\"title\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"title\"]], [title_emb]\n",
    "                )[0][0]\n",
    "            category_text = real_meta.get(\"category\", \"\")\n",
    "            if category_text and \"category\" in query_embedding_map:\n",
    "                category_emb = await asyncio.to_thread(\n",
    "                    self.embeddings.embed_query, category_text\n",
    "                )\n",
    "                score_map[\"category\"] = cosine_similarity(\n",
    "                    [query_embedding_map[\"category\"]], [category_emb]\n",
    "                )[0][0]\n",
    "            valid_keys = score_map.keys()\n",
    "            total_weight = sum(weights[k] for k in valid_keys)\n",
    "            final_score = sum(\n",
    "                (weights[k] / total_weight) * score_map[k] for k in valid_keys\n",
    "            )\n",
    "            scored_docs.append((doc, final_score))\n",
    "        sorted_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "        logger.info(\"리랭킹 완료 (정규화 가중치 방식)\")\n",
    "        for i, (doc, score) in enumerate(sorted_docs):\n",
    "            title = _extract_metadata_field(doc, \"title\", default=\"제목 없음\")\n",
    "            isbn = _extract_metadata_field(doc, \"ISBN\", default=\"N/A\")\n",
    "            logger.info(\n",
    "                f\"{i+1}. 제목: {title} | ISBN: {isbn} | 점수: {round(score, 4)}\"\n",
    "            )\n",
    "        reranked_docs = [doc for doc, _ in sorted_docs]\n",
    "        logger.info(\"리랭킹 완료 (정규화 가중치 방식, metadata 이중 구조 대응).\")\n",
    "        return reranked_docs\n",
    "\n",
    "    async def _expand_query(self, query: str) -> List[str]:\n",
    "        logger.info(f\"검색 쿼리 확장 시작: '{query}'\")\n",
    "        expansion_result = await async_invoke(\n",
    "            self.query_expansion_chain, {\"query\": query}, \"검색 쿼리 확장\"\n",
    "        )\n",
    "        expanded_queries_text = expansion_result.get(\"text\", \"\").strip()\n",
    "        expanded_queries = []\n",
    "        for line in expanded_queries_text.splitlines():\n",
    "            line_stripped = line.strip()\n",
    "            if not line_stripped:\n",
    "                continue\n",
    "            query_part = re.sub(r\"^\\d+\\.\\s*\", \"\", line_stripped).strip()\n",
    "            if query_part and query_part.lower() != query.lower():\n",
    "                expanded_queries.append(query_part)\n",
    "        final_expanded_queries = expanded_queries[:3]\n",
    "        logger.info(\n",
    "            f\"생성된 확장 쿼리 ({len(final_expanded_queries)}개): {final_expanded_queries}\"\n",
    "        )\n",
    "        return final_expanded_queries\n",
    "\n",
    "    async def _retrieve_documents(\n",
    "        self, query: str, use_hyde: bool = False\n",
    "    ) -> List[Document]:\n",
    "        retrieval_query = query\n",
    "        hyde_summary = \"\"\n",
    "        if use_hyde and self.user_preferences.get(\"implicit info\"):\n",
    "            logger.info(\"HyDE 활성화: 가상 문서 요약 및 키워드 추출 시도\")\n",
    "            hyde_result = await async_invoke(\n",
    "                self.hyde_generation_chain, {\"query\": query}, \"HyDE 가상 문서 생성\"\n",
    "            )\n",
    "            hyde_summary = hyde_result.get(\"text\", \"\").strip()\n",
    "            if hyde_summary:\n",
    "                logger.info(f\"생성된 가상 문서 요약: '{hyde_summary[:200]}...'\")\n",
    "                keyword_result = await async_invoke(\n",
    "                    self.hyde_keyword_chain,\n",
    "                    {\"hyde_summary\": hyde_summary},\n",
    "                    \"HyDE 키워드 추출\",\n",
    "                )\n",
    "                hyde_keywords_text = keyword_result.get(\"text\", \"\").strip()\n",
    "                hyde_keywords = [\n",
    "                    k.strip() for k in hyde_keywords_text.split(\",\") if k.strip()\n",
    "                ]\n",
    "                if hyde_keywords:\n",
    "                    logger.info(f\"추출된 HyDE 키워드: {hyde_keywords}\")\n",
    "                    retrieval_query = f\"{query} {' '.join(hyde_keywords)}\"\n",
    "                    logger.info(f\"HyDE 적용된 검색 쿼리: '{retrieval_query}'\")\n",
    "                else:\n",
    "                    logger.warning(\n",
    "                        \"HyDE 요약에서 키워드를 추출하지 못했습니다. 원본 쿼리 사용.\"\n",
    "                    )\n",
    "            else:\n",
    "                logger.warning(\"HyDE 가상 문서 요약 생성 실패. 원본 쿼리 사용.\")\n",
    "        elif use_hyde:\n",
    "            logger.info(\"HyDE 조건 미충족 ('implicit info' 없음). 일반 쿼리 검색 수행.\")\n",
    "        else:\n",
    "            logger.info(\"일반 쿼리 검색 수행.\")\n",
    "        logger.info(f\"최종 리트리버 호출 시작 (쿼리: '{retrieval_query[:100]}...')\")\n",
    "        try:\n",
    "            retrieved_docs = await self.retriever.aget_relevant_documents(\n",
    "                retrieval_query\n",
    "            )\n",
    "            logger.info(f\"검색된 문서 수 (ISBN 병합 완료됨): {len(retrieved_docs)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(\n",
    "                f\"문서 검색 실패 (쿼리: '{retrieval_query}'): {e}\", exc_info=True\n",
    "            )\n",
    "            retrieved_docs = []\n",
    "        return retrieved_docs\n",
    "\n",
    "    async def _generate_recommendations(self, final_query: str) -> str:\n",
    "        logger.info(f\"추천 생성 시작. 최종 쿼리: '{final_query}'\")\n",
    "        use_hyde = False\n",
    "        use_expansion = False\n",
    "        has_author = bool(self.user_preferences.get(\"author\"))\n",
    "        has_title = bool(self.user_preferences.get(\"title\"))\n",
    "        has_implicit = bool(self.user_preferences.get(\"implicit info\"))\n",
    "        if not has_author and not has_title and has_implicit:\n",
    "            use_hyde = True\n",
    "            use_expansion = True\n",
    "        initial_docs = await self._retrieve_documents(final_query, use_hyde=use_hyde)\n",
    "        all_docs_to_consider = list(initial_docs)\n",
    "        processed_queries = {final_query.lower()}\n",
    "        if use_expansion:\n",
    "            expanded_queries = await self._expand_query(final_query)\n",
    "            expansion_tasks = []\n",
    "            if expanded_queries:\n",
    "                logger.info(\n",
    "                    f\"확장 쿼리 ({len(expanded_queries)}개)로 추가 검색 수행...\"\n",
    "                )\n",
    "                for eq in expanded_queries:\n",
    "                    eq_lower = eq.lower()\n",
    "                    if eq_lower not in processed_queries:\n",
    "                        expansion_tasks.append(\n",
    "                            self._retrieve_documents(eq, use_hyde=False)\n",
    "                        )\n",
    "                        processed_queries.add(eq_lower)\n",
    "                if expansion_tasks:\n",
    "                    expansion_results = await asyncio.gather(*expansion_tasks)\n",
    "                    existing_isbns = {\n",
    "                        doc.metadata.get(\"ISBN\")\n",
    "                        for doc in all_docs_to_consider\n",
    "                        if doc.metadata.get(\"ISBN\")\n",
    "                    }\n",
    "                    for docs_list in expansion_results:\n",
    "                        for doc in docs_list:\n",
    "                            isbn = doc.metadata.get(\"ISBN\")\n",
    "                            if isbn and isbn not in existing_isbns:\n",
    "                                all_docs_to_consider.append(doc)\n",
    "                                existing_isbns.add(isbn)\n",
    "        logger.info(\n",
    "            f\"초기 및 확장 검색 후 고려할 총 고유 문서 수: {len(all_docs_to_consider)}\"\n",
    "        )\n",
    "        for i, doc in enumerate(all_docs_to_consider):\n",
    "            metadata_content = doc.metadata if doc.metadata else {}\n",
    "            logger.debug(\n",
    "                f\"문서 {i+1} Metadata: {json.dumps(metadata_content, indent=2, ensure_ascii=False)}\"\n",
    "            )\n",
    "            try:\n",
    "                isbn_check = metadata_content.get(\"ISBN\", \"ISBN 키 없음\")\n",
    "                title_check = metadata_content.get(\"title\", \"Title 키 없음\")\n",
    "                logger.debug(f\"  -> 확인: ISBN='{isbn_check}', Title='{title_check}'\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  -> 메타데이터 접근 오류 발생: {e}\")\n",
    "        logger.debug(\"--- 리랭킹 입력 데이터 확인 완료 ---\")\n",
    "        if not all_docs_to_consider:\n",
    "            logger.warning(\"검색 및 확장 결과 문서를 찾지 못했습니다. 추천 생성 불가.\")\n",
    "            return \"죄송합니다, 해당 조건에 맞는 책을 찾지 못했습니다. 다른 조건으로 다시 시도해 보시겠어요?\"\n",
    "        logger.info(\"리랭킹 수행...\")\n",
    "        ranked_docs = await self._embedding_rerank_documents(\n",
    "            final_query, all_docs_to_consider\n",
    "        )\n",
    "        if not ranked_docs:\n",
    "            logger.warning(\"리랭킹 결과 유효한 문서가 없습니다. 추천 생성 불가.\")\n",
    "            return \"죄송합니다, 추천할 책을 선정하는 데 어려움이 있습니다. 잠시 후 다시 시도해주세요.\"\n",
    "        top_docs = ranked_docs[:3]\n",
    "        logger.info(f\"최종 추천 후보 문서 수: {len(top_docs)}\")\n",
    "        recommendations = []\n",
    "        self.last_recommendations = []\n",
    "        processed_isbns = set()\n",
    "        for rank, doc in enumerate(top_docs):\n",
    "            isbn = _extract_metadata_field(doc, \"ISBN\")\n",
    "            title = _extract_metadata_field(doc, \"title\", default=\"제목 없음\")\n",
    "            logger.debug(\n",
    "                f\"추천 후보 처리 중 (Rank {rank+1}): ISBN={isbn}, Title={title}\"\n",
    "            )\n",
    "            if not isbn or isbn == \"N/A\":\n",
    "                logger.warning(\n",
    "                    f\"Rank {rank+1} 추천 후보에 ISBN 없음. 건너뜀. Title: {title}\"\n",
    "                )\n",
    "                continue\n",
    "            if isbn in processed_isbns:\n",
    "                logger.warning(f\"중복 ISBN '{isbn}' 추천 목록에 이미 존재. 건너뜀.\")\n",
    "                continue\n",
    "            full_merged_doc = self._merge_documents_by_isbn(isbn)\n",
    "            if not full_merged_doc:\n",
    "                logger.error(\n",
    "                    f\"치명적 오류: 리랭킹된 문서(ISBN: {isbn})의 전체 정보를 병합하지 못했습니다. 추천 목록에서 제외.\"\n",
    "                )\n",
    "                continue\n",
    "            self.last_recommendations.append(full_merged_doc)\n",
    "            processed_isbns.add(isbn)\n",
    "            metadata = full_merged_doc.metadata\n",
    "            title = metadata.get(\"title\", \"제목 정보 없음\")\n",
    "            author = metadata.get(\"author\", \"저자 정보 없음\")\n",
    "            book_cover = metadata.get(\"book_cover\", \"표지 정보 없음\")\n",
    "            book_intro = extract_field(full_merged_doc.page_content, \"책소개\")\n",
    "            publisher_review = extract_field(full_merged_doc.page_content, \"출판사리뷰\")\n",
    "            recommendation_field = extract_field(full_merged_doc.page_content, \"추천사\")\n",
    "            text_for_summary = \"\"\n",
    "            if book_intro and len(book_intro.strip()) >= MIN_INFO_LENGTH:\n",
    "                text_for_summary = book_intro\n",
    "            elif publisher_review and len(publisher_review.strip()) >= MIN_INFO_LENGTH:\n",
    "                text_for_summary = publisher_review\n",
    "            elif (\n",
    "                recommendation_field\n",
    "                and len(recommendation_field.strip()) >= MIN_INFO_LENGTH\n",
    "            ):\n",
    "                text_for_summary = recommendation_field\n",
    "            else:\n",
    "                page_content_cleaned = re.sub(\n",
    "                    r\"^\\s*.*?\\s*[:：]\\s*\",\n",
    "                    \"\",\n",
    "                    full_merged_doc.page_content,\n",
    "                    flags=re.MULTILINE,\n",
    "                ).strip()\n",
    "                text_for_summary = page_content_cleaned[:500]\n",
    "            if text_for_summary and len(text_for_summary.strip()) >= MIN_INFO_LENGTH:\n",
    "                summary = await self._summarize_chunk_with_llm(text_for_summary)\n",
    "            else:\n",
    "                summary = \"책에 대한 상세 설명이 부족합니다.\"\n",
    "            recommendation_text = f\"{rank+1}. \\r\\n표지: {book_cover}\\r\\n제목: {title}\\r\\n저자: {author}\\r\\n- 추천 이유: {summary}\"\n",
    "            recommendations.append(recommendation_text)\n",
    "            logger.debug(f\"추천 문구 생성됨: {title}\")\n",
    "        if self.last_recommendations:\n",
    "            rec_titles = [\n",
    "                d.metadata.get(\"title\", \"N/A\") for d in self.last_recommendations\n",
    "            ]\n",
    "            logger.info(\n",
    "                f\"'_generate_recommendations' 종료. last_recommendations 업데이트 ({len(self.last_recommendations)}개): {rec_titles}\"\n",
    "            )\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"'_generate_recommendations' 종료. 최종 추천 목록(last_recommendations)이 비어있음!\"\n",
    "            )\n",
    "        if not recommendations:\n",
    "            return \"추천할 만한 책을 찾지 못했습니다. 조건을 바꿔서 다시 질문해 주시겠어요?\"\n",
    "        final_answer = \"이런 책들은 어떠신가요? 마음에 드는 책이 있다면 더 자세히 알려드릴게요.\\n\\n\" + \"\\n\\n\".join(\n",
    "            recommendations\n",
    "        )\n",
    "        logger.info(\"추천 응답 생성 완료.\")\n",
    "        return final_answer\n",
    "\n",
    "    async def handle_followup_query(self, followup_query: str) -> tuple[bool, str]:\n",
    "        logger.info(f\"후속 질문 처리 시작. Query: '{followup_query}'\")\n",
    "        if not self.last_recommendations:\n",
    "            logger.error(\n",
    "                \"handle_followup_query 진입 오류: last_recommendations가 비어 있음!\"\n",
    "            )\n",
    "            return False, \"\"\n",
    "        rec_info = []\n",
    "        for i, doc in enumerate(self.last_recommendations):\n",
    "            title = doc.metadata.get(\"title\", \"제목 없음\")\n",
    "            isbn = doc.metadata.get(\"ISBN\", \"NO_ISBN\")\n",
    "            snippet = await self._summarize_chunk_with_llm(doc.page_content[:500])\n",
    "            rec_info.append(f\"{i+1}. 제목: {title}, ISBN: {isbn}\\n   요약: {snippet}\")\n",
    "        rec_info_str = \"\\n\".join(rec_info)\n",
    "        prompt = f\"\"\"이전에 다음 책들을 추천했습니다:\n",
    "{rec_info_str}\n",
    "\n",
    "사용자의 후속 질문은 다음과 같습니다: \"{followup_query}\"\n",
    "\n",
    "이 질문이 위 추천 목록과 관련된 후속 질문인지, 아니면 완전히 새로운 질문인지 판단하고, 후속 질문이라면 그 의도를 분석하여 다음 JSON 형식 중 **하나만** 출력해라. 새로운 질문이면 {{\"action\": \"새 질문\", \"ISBN\": null, \"query\": null}} 형식으로 출력하라. **절대로 다른 설명이나 대화 없이 오직 JSON 객체 하나만 출력해야 한다.**\n",
    "[후속 질문 의도 분류 및 JSON 형식]\n",
    "- 특정 책 상세 정보 요청: {{\"action\": \"상세\", \"ISBN\": \"<요청된 책의 ISBN>\", \"query\": \"{followup_query}\"}}\n",
    "- 특정 책과 유사한 책 추천 요청: {{\"action\": \"유사\", \"ISBN\": \"<기준 책의 ISBN>\", \"query\": \"<유사성 관련 사용자 언급>\"}}\n",
    "- 추천된 책들 비교 요청: {{\"action\": \"비교\", \"ISBN\": \"<비교 대상 ISBN 목록 (쉼표 구분)>\", \"query\": \"{followup_query}\"}}\n",
    "- 추천 결과에 대한 피드백/불만: {{\"action\": \"피드백\", \"ISBN\": null, \"query\": \"{followup_query}\"}}\n",
    "- 완전히 새로운 질문: {{\"action\": \"새 질문\", \"ISBN\": null, \"query\": null}}\n",
    "[분석 결과 (JSON 객체만 출력)]\n",
    "\"\"\"\n",
    "        try:\n",
    "            result_text = await async_invoke_llm(prompt, \"후속 질문 의도 분석\")\n",
    "            logger.debug(f\"후속 질문 의도 분석 LLM 원본 응답: {result_text}\")\n",
    "            analysis_result = None\n",
    "            json_match = re.search(r\"\\{.*\\}\", result_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    analysis_result = json.loads(json_match.group(0))\n",
    "                except json.JSONDecodeError:\n",
    "                    logger.error(\n",
    "                        f\"후속 질문 의도 분석 결과 JSON 파싱 실패 (JSON 형식 오류): {result_text}\"\n",
    "                    )\n",
    "                    analysis_result = {\"action\": \"새 질문\"}\n",
    "            else:\n",
    "                if (\n",
    "                    \"새 질문\" in result_text\n",
    "                    or '\"action\": \"새 질문\"' in result_text.replace(\" \", \"\")\n",
    "                ):\n",
    "                    logger.warning(\n",
    "                        f\"후속 질문 의도 분석 JSON 객체 미발견, '새 질문' 패턴 감지: {result_text}\"\n",
    "                    )\n",
    "                    analysis_result = {\"action\": \"새 질문\"}\n",
    "                else:\n",
    "                    logger.error(\n",
    "                        f\"후속 질문 의도 분석 결과 JSON 파싱 실패 및 '새 질문' 패턴 미감지: {result_text}\"\n",
    "                    )\n",
    "                    return False, \"\"\n",
    "            action = analysis_result.get(\"action\", \"새 질문\")\n",
    "            isbn_str = analysis_result.get(\"ISBN\", \"\")\n",
    "            query_part = analysis_result.get(\"query\", followup_query)\n",
    "            logger.info(\n",
    "                f\"후속 질문 분석 결과: action='{action}', ISBN='{isbn_str}', query='{query_part[:50]}...'\"\n",
    "            )\n",
    "            if action == \"새 질문\":\n",
    "                return False, \"\"\n",
    "            isbn_list = (\n",
    "                [s.strip() for s in str(isbn_str).split(\",\") if s.strip()]\n",
    "                if isbn_str\n",
    "                else []\n",
    "            )\n",
    "            target_isbn = isbn_list[0] if isbn_list else None\n",
    "            if action == \"상세\":\n",
    "                if not target_isbn:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"어떤 책에 대해 더 알고 싶으신지 알려주시겠어요? (예: 첫 번째 책 또는 책 제목)\",\n",
    "                    )\n",
    "                target_doc = next(\n",
    "                    (\n",
    "                        doc\n",
    "                        for doc in self.last_recommendations\n",
    "                        if str(doc.metadata.get(\"ISBN\", \"\")).strip()\n",
    "                        == str(target_isbn).strip()\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "                if target_doc:\n",
    "                    logger.debug(\n",
    "                        f\"상세 정보 요청: ISBN '{target_isbn}' 문서 찾음: Title='{target_doc.metadata.get('title')}'\"\n",
    "                    )\n",
    "                    detail_prompt = f\"\"\"다음은 사용자가 문의한 '{target_doc.metadata.get(\"title\", \"해당 책\")}'에 대한 정보입니다. 이 정보를 바탕으로 사용자 질문 \"{query_part}\"에 답하거나, 특별한 질문이 없다면 책에 대해 자연스럽게 더 자세히 설명해주세요.\n",
    "[책 정보 요약]\n",
    "제목: {target_doc.metadata.get(\"title\", \"정보 없음\")}\n",
    "저자: {target_doc.metadata.get(\"author\", \"정보 없음\")}\n",
    "분류: {target_doc.metadata.get(\"category\", \"정보 없음\")}\n",
    "페이지: {target_doc.metadata.get(\"page\", \"정보 없음\")} 쪽\n",
    "가격: {target_doc.metadata.get(\"price\", \"정보 없음\")} 원\n",
    "[책 소개 및 내용 (일부)]\n",
    "{target_doc.page_content[:3000]}...\n",
    "[답변 또는 상세 설명]\n",
    "\"\"\"\n",
    "                    detailed_info = await async_invoke_llm(\n",
    "                        detail_prompt, \"후속 상세 설명 생성\"\n",
    "                    )\n",
    "                    return True, (\n",
    "                        detailed_info\n",
    "                        if detailed_info\n",
    "                        else \"죄송합니다, 요청하신 내용에 대한 추가 정보를 제공하기 어렵습니다.\"\n",
    "                    )\n",
    "                else:\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 요청하신 ISBN({target_isbn})의 책 정보를 찾을 수 없습니다. 현재 추천된 책들의 ISBN은 다음과 같습니다: {available_isbns}\",\n",
    "                    )\n",
    "            elif action == \"유사\":\n",
    "                if not target_isbn:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"어떤 책과 유사한 책을 찾으시는지 알려주시겠어요? (예: 두 번째 책 같은 스타일)\",\n",
    "                    )\n",
    "                base_doc = next(\n",
    "                    (\n",
    "                        doc\n",
    "                        for doc in self.last_recommendations\n",
    "                        if str(doc.metadata.get(\"ISBN\", \"\")).strip()\n",
    "                        == str(target_isbn).strip()\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "                if base_doc:\n",
    "                    logger.debug(\n",
    "                        f\"유사 책 요청: 기준 ISBN '{target_isbn}' 문서 찾음: Title='{base_doc.metadata.get('title')}'\"\n",
    "                    )\n",
    "                    base_title = base_doc.metadata.get(\"title\", \"\")\n",
    "                    base_author = base_doc.metadata.get(\"author\", \"\")\n",
    "                    base_category = base_doc.metadata.get(\"category\", \"\")\n",
    "                    similarity_aspects = (\n",
    "                        f\"{base_category} 장르\"\n",
    "                        if base_category\n",
    "                        else f\"'{base_title}'와 비슷한\"\n",
    "                    )\n",
    "                    if base_author:\n",
    "                        similarity_aspects += f\" {base_author} 작가 스타일\"\n",
    "                    user_refinement = (\n",
    "                        f\" 그리고 '{query_part}' 특징을 가진\"\n",
    "                        if query_part and query_part != followup_query\n",
    "                        else \"\"\n",
    "                    )\n",
    "                    new_query = f\"{similarity_aspects}{user_refinement} 책 추천\"\n",
    "                    logger.info(f\"유사 책 추천을 위한 새 쿼리 생성: {new_query}\")\n",
    "                    recommendation_result = await self._generate_recommendations(\n",
    "                        new_query\n",
    "                    )\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"네, '{base_title}'와(과) 비슷한 다른 책을 찾아볼게요.\\n\\n\"\n",
    "                        + recommendation_result,\n",
    "                    )\n",
    "                else:\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 기준이 되는 ISBN({target_isbn})의 책 정보를 찾을 수 없습니다. 현재 추천된 책들의 ISBN은 다음과 같습니다: {available_isbns}\",\n",
    "                    )\n",
    "            elif action == \"비교\":\n",
    "                if len(isbn_list) < 2:\n",
    "                    return (\n",
    "                        True,\n",
    "                        \"비교할 책을 두 권 이상 알려주시겠어요? (예: 첫 번째랑 세 번째 책 비교해주세요)\",\n",
    "                    )\n",
    "                valid_comparison_isbns = [\n",
    "                    isbn\n",
    "                    for isbn in isbn_list\n",
    "                    if any(\n",
    "                        str(d.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "                        for d in self.last_recommendations\n",
    "                    )\n",
    "                ]\n",
    "                if len(valid_comparison_isbns) < 2:\n",
    "                    available_isbns = [\n",
    "                        d.metadata.get(\"ISBN\") for d in self.last_recommendations\n",
    "                    ]\n",
    "                    return (\n",
    "                        True,\n",
    "                        f\"죄송합니다, 비교 요청하신 책({isbn_list}) 중 일부를 찾을 수 없거나 유효하지 않습니다. 현재 추천된 책 ISBN: {available_isbns}\",\n",
    "                    )\n",
    "                comparison_result = await self._handle_comparison(\n",
    "                    query_part, valid_comparison_isbns\n",
    "                )\n",
    "                return True, comparison_result\n",
    "            elif action == \"피드백\":\n",
    "                logger.info(f\"사용자 피드백/불만 처리 시도: '{query_part}'\")\n",
    "                feedback_based_query = f\"이전 추천에 대해 '{query_part}' 라는 피드백이 있었습니다. 이 점을 고려하여 다른 책을 추천해주세요.\"\n",
    "                logger.info(f\"피드백 기반 새 쿼리 생성: {feedback_based_query}\")\n",
    "                recommendation_result = await self._generate_recommendations(\n",
    "                    feedback_based_query\n",
    "                )\n",
    "                return (\n",
    "                    True,\n",
    "                    \"피드백 감사합니다. 말씀해주신 점을 바탕으로 다른 책을 찾아보겠습니다.\\n\\n\"\n",
    "                    + recommendation_result,\n",
    "                )\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"처리되지 않은 후속 질문 action: {action}. 새 질문으로 간주.\"\n",
    "                )\n",
    "                return False, \"\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"후속 질문 처리 중 예외 발생: {e}\", exc_info=True)\n",
    "            return True, \"후속 질문 처리 중 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "    async def _handle_comparison(self, query_part: str, isbn_list: List[str]) -> str:\n",
    "        logger.info(\n",
    "            f\"도서 비교 시작. ISBN 목록: {isbn_list}, 비교 관점: '{query_part}'\"\n",
    "        )\n",
    "        comparison_docs_info = []\n",
    "        for isbn in isbn_list:\n",
    "            doc = next(\n",
    "                (\n",
    "                    d\n",
    "                    for d in self.last_recommendations\n",
    "                    if str(d.metadata.get(\"ISBN\", \"\")).strip() == str(isbn).strip()\n",
    "                ),\n",
    "                None,\n",
    "            )\n",
    "            if doc:\n",
    "                metadata = doc.metadata\n",
    "                summary = await self._summarize_chunk_with_llm(doc.page_content[:2000])\n",
    "                comparison_docs_info.append(\n",
    "                    {\n",
    "                        \"title\": metadata.get(\"title\", \"제목 없음\"),\n",
    "                        \"author\": metadata.get(\"author\", \"저자 없음\"),\n",
    "                        \"summary\": summary,\n",
    "                        \"category\": metadata.get(\"category\", \"분류 없음\"),\n",
    "                        \"page\": metadata.get(\"page\", \"페이지 수 없음\"),\n",
    "                        \"price\": metadata.get(\"price\", \"가격 정보 없음\"),\n",
    "                        \"isbn\": isbn,\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                logger.error(\n",
    "                    f\"비교 오류: 유효성 검사 후에도 ISBN '{isbn}' 문서를 last_recommendations에서 찾지 못함.\"\n",
    "                )\n",
    "        if len(comparison_docs_info) < 2:\n",
    "            logger.warning(\n",
    "                f\"비교 가능한 문서가 2개 미만입니다 (찾은 문서 수: {len(comparison_docs_info)}).\"\n",
    "            )\n",
    "            return \"비교할 책 정보를 충분히 찾지 못했습니다.\"\n",
    "        comparison_prompt_template = \"\"\"다음은 사용자가 비교를 요청한 책들의 정보입니다. 사용자의 비교 요청 관점인 \"{{ query }}\"에 특히 초점을 맞춰 이 책들을 명확하게 비교 설명해주세요. 각 책의 주요 특징, 장르, 내용 스타일, 난이도, 분량, 가격 등 관련 정보를 활용하고, 어떤 독자에게 더 적합할지 등을 포함하여 답변하는 것이 좋습니다. 자연스러운 문장으로 설명해주세요.\n",
    "[비교 대상 책 정보]\n",
    "{% for doc in summaries %}\n",
    "--- 책 {{ loop.index }} (ISBN: {{ doc.isbn }}) ---\n",
    "제목: {{ doc.title }}\n",
    "저자: {{ doc.author }}\n",
    "분류: {{ doc.category }}\n",
    "페이지 수: {{ doc.page }}\n",
    "가격: {{ doc.price }} 원\n",
    "요약: {{ doc.summary }}\n",
    "{% endfor %}\n",
    "[사용자 비교 요청 관점/질문]\n",
    "\"{{ query }}\"\n",
    "[비교 설명]\n",
    "\"\"\"\n",
    "        try:\n",
    "            comp_template = PromptTemplate(\n",
    "                template=comparison_prompt_template,\n",
    "                input_variables=[\"summaries\", \"query\"],\n",
    "                template_format=\"jinja2\",\n",
    "            )\n",
    "            rendered_prompt = comp_template.render(\n",
    "                summaries=comparison_docs_info, query=query_part\n",
    "            )\n",
    "            logger.debug(\n",
    "                f\"도서 비교 프롬프트 생성 완료 (일부):\\n{rendered_prompt[:500]}...\"\n",
    "            )\n",
    "            comparison_result = await async_invoke_llm(\n",
    "                rendered_prompt, \"도서 비교 설명 생성\"\n",
    "            )\n",
    "            if (\n",
    "                not comparison_result\n",
    "                or len(comparison_result) < 20\n",
    "                or \"죄송\" in comparison_result\n",
    "                or \"모르겠\" in comparison_result\n",
    "            ):\n",
    "                logger.warning(\"LLM 기반 도서 비교 설명 생성 실패 또는 결과 부적절.\")\n",
    "                return \"죄송합니다, 요청하신 책들을 비교 설명하는 데 어려움이 있습니다.\"\n",
    "            logger.info(\"도서 비교 설명 생성 완료.\")\n",
    "            return comparison_result\n",
    "        except Exception as e:\n",
    "            logger.error(f\"도서 비교 설명 생성 중 예외 발생: {e}\", exc_info=True)\n",
    "            return \"죄송합니다, 책들을 비교하는 중 오류가 발생했습니다.\"\n",
    "\n",
    "    async def process_query(\n",
    "        self, user_query: str, force_recommendation: bool = False\n",
    "    ) -> str:\n",
    "        logger.info(f\"=== 새로운 사용자 쿼리 처리 시작: '{user_query}' ===\")\n",
    "        self.user_history.append(f\"사용자: {user_query}\")\n",
    "        await self.update_preferences_from_input(user_query)\n",
    "        is_potential_followup = self.last_action == \"추천\" and self.last_recommendations\n",
    "        if is_potential_followup:\n",
    "            logger.info(\"이전 추천에 대한 후속 질문 가능성 확인 중...\")\n",
    "            handled, followup_output = await self.handle_followup_query(user_query)\n",
    "            if handled:\n",
    "                logger.info(\"후속 질문 처리 완료.\")\n",
    "                self.llm_history.append(f\"챗봇: {followup_output}\")\n",
    "                return followup_output\n",
    "            else:\n",
    "                logger.info(\"후속 질문이 아님. 일반 질문 처리 로직으로 진행합니다.\")\n",
    "        action: Optional[str] = None\n",
    "        additional_question: str = \"\"\n",
    "        if not force_recommendation:\n",
    "            logger.info(\"행동 결정 요청 (추천 vs 추가 질문)\")\n",
    "            meaningful_prefs_count = sum(\n",
    "                1 for k, v in self.user_preferences.items() if v and k != \"title\"\n",
    "            )\n",
    "            should_recommend_heuristically = (\n",
    "                meaningful_prefs_count >= 1 or self.preference_update_count >= 2\n",
    "            )\n",
    "            if not should_recommend_heuristically and self.preference_update_count < 2:\n",
    "                logger.info(\n",
    "                    f\"선호도 부족 ({meaningful_prefs_count}개 / {self.preference_update_count}번 업데이트). '추가 질문' 강제 실행.\"\n",
    "                )\n",
    "                action = \"추가 질문\"\n",
    "                additional_question = \"어떤 종류의 책을 찾으시는지 좀 더 자세히 말씀해주시겠어요? (예: 구체적인 카테고리, 특정 작가, 책의 수준/분위기 등)\"\n",
    "            else:\n",
    "                prompt_vars = {\n",
    "                    \"history\": \"\\n\".join(\n",
    "                        self.user_history[-5:] + self.llm_history[-5:]\n",
    "                    ),\n",
    "                    \"query\": user_query,\n",
    "                    \"preferences\": self.preferences_text,\n",
    "                    \"role_instructions\": self.config.get(\n",
    "                        \"role_instructions\", general_role\n",
    "                    ),\n",
    "                }\n",
    "                try:\n",
    "                    decision_result = await async_invoke(\n",
    "                        self.decision_chain, prompt_vars, \"행동 결정\"\n",
    "                    )\n",
    "                    decision_text = decision_result.get(\"text\", \"\").strip()\n",
    "                    action, additional_question_llm = (\n",
    "                        self.robust_parse_decision_response(decision_text)\n",
    "                    )\n",
    "                    if action == \"추가 질문\" and additional_question_llm:\n",
    "                        additional_question = additional_question_llm\n",
    "                except Exception as e:\n",
    "                    logger.error(\n",
    "                        f\"행동 결정 LLM 호출 실패: {e}. '추가 질문'으로 안전하게 진행.\",\n",
    "                        exc_info=True,\n",
    "                    )\n",
    "                    action = \"추가 질문\"\n",
    "                    additional_question = \"요청을 이해하는 데 어려움이 있었습니다. 어떤 책을 찾으시는지 다시 말씀해주시겠어요?\"\n",
    "        else:\n",
    "            logger.info(\"강제 추천 모드 활성화. 행동='추천'\")\n",
    "            action = \"추천\"\n",
    "        response = \"\"\n",
    "        if action == \"추가 질문\":\n",
    "            logger.info(\"행동: 추가 질문\")\n",
    "            self.last_action = \"추가 질문\"\n",
    "            if additional_question:\n",
    "                try:\n",
    "                    add_q_emb = await asyncio.to_thread(\n",
    "                        self.embeddings.embed_query, additional_question\n",
    "                    )\n",
    "                    if is_similar_question(\n",
    "                        add_q_emb,\n",
    "                        previous_additional_question_embeddings,\n",
    "                        threshold=0.90,\n",
    "                    ):\n",
    "                        logger.warning(\n",
    "                            \"이전과 매우 유사한 추가 질문 생성됨. 추천 강제 시도.\"\n",
    "                        )\n",
    "                        return await self.process_query(\n",
    "                            user_query, force_recommendation=True\n",
    "                        )\n",
    "                    else:\n",
    "                        previous_additional_question_embeddings.append(add_q_emb)\n",
    "                        if len(previous_additional_question_embeddings) > 5:\n",
    "                            previous_additional_question_embeddings.pop(0)\n",
    "                        response = additional_question\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"추가 질문 임베딩 또는 유사도 비교 중 오류: {e}\")\n",
    "                    response = additional_question\n",
    "            else:\n",
    "                logger.warning(\"추가 질문 행동 결정되었으나 질문 내용 없음. 추천 시도.\")\n",
    "                action = \"추천\"\n",
    "        if action == \"추천\":\n",
    "            logger.info(\"행동: 추천\")\n",
    "            self.last_action = \"추천\"\n",
    "            final_query = await self.get_final_query(user_query)\n",
    "            if not final_query:\n",
    "                logger.error(\"최종 검색 쿼리 생성 실패. 추천 불가.\")\n",
    "                self.last_action = None\n",
    "                response = \"죄송합니다, 검색어를 만드는 데 실패했습니다. 다시 질문해 주시겠어요?\"\n",
    "            else:\n",
    "                recommendation_result = await self._generate_recommendations(\n",
    "                    final_query\n",
    "                )\n",
    "                response = recommendation_result\n",
    "                if (\n",
    "                    not self.last_recommendations\n",
    "                    and \"죄송합니다\" not in response\n",
    "                    and \"찾지 못했습니다\" not in response\n",
    "                ):\n",
    "                    logger.warning(\n",
    "                        \"추천 생성 과정 완료 후 self.last_recommendations가 비어있으나, 응답은 성공 메시지 형태임.\"\n",
    "                    )\n",
    "                    self.last_action = None\n",
    "        if response:\n",
    "            self.llm_history.append(f\"챗봇: {response}\")\n",
    "            logger.info(\n",
    "                f\"챗봇 응답 생성 완료 (Action: {self.last_action}). 응답 일부: {response[:200]}...\"\n",
    "            )\n",
    "            return response\n",
    "        else:\n",
    "            logger.error(f\"최종 응답 생성 실패 (Action: {action}).\")\n",
    "            self.last_action = None\n",
    "            fallback_msg = (\n",
    "                \"죄송합니다, 요청을 처리하는 중 문제가 발생했습니다. 다시 시도해주세요.\"\n",
    "            )\n",
    "            self.llm_history.append(f\"챗봇: {fallback_msg}\")\n",
    "            return fallback_msg\n",
    "\n",
    "    async def interactive_multi_turn_qa(self):\n",
    "        persona_greetings = {\n",
    "            \"Literature\": \"안녕하세요~ 감성적인 문학 도서 추천 챗봇입니다. 어떤 책을 찾으시나요? 당신의 이야기나 감정을 들려주셔도 좋아요.\",\n",
    "            \"Science\": \"안녕하십니까. 과학/기술 도서 전문 챗봇입니다. 관심 분야, 알고 계신 내용, 찾으시는 정보의 깊이 등을 알려주시면 더 정확한 추천을 드릴 수 있습니다.\",\n",
    "            \"General\": \"안녕하세요! 도서 추천 챗봇입니다. 어떤 종류의 책을 찾으시는지 편하게 말씀해주세요.\",\n",
    "        }\n",
    "        persona = self.config.get(\"persona\", \"General\")\n",
    "        greeting = persona_greetings.get(persona, persona_greetings[\"General\"])\n",
    "        self.llm_history.append(f\"챗봇: {greeting}\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"[{self.config.get('persona', '챗봇')}] {greeting}\")\n",
    "        print(\"-\" * 70)\n",
    "        turn_count = 0\n",
    "        while True:\n",
    "            turn_count += 1\n",
    "            print(f\"\\n--- Turn {turn_count} ---\")\n",
    "            logger.info(f\"--- Turn {turn_count} 시작 ---\")\n",
    "            logger.debug(\n",
    "                f\"Turn 시작 | last_action: {self.last_action} | last_recs: {len(self.last_recommendations)}\"\n",
    "            )\n",
    "            try:\n",
    "                user_query = input(\"[사용자] \").strip()\n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break\n",
    "            if user_query.lower() in [\"quit\", \"exit\", \"종료\", \"그만\"]:\n",
    "                print(\"\\n[대화 종료]\")\n",
    "                break\n",
    "            if not user_query:\n",
    "                continue\n",
    "            try:\n",
    "                final_answer = await self.process_query(user_query)\n",
    "            except Exception as e:\n",
    "                logger.critical(\n",
    "                    f\"대화 처리 중 치명적 오류 발생 (Turn {turn_count}): {e}\",\n",
    "                    exc_info=True,\n",
    "                )\n",
    "                final_answer = \"죄송합니다. 요청을 처리하는 중에 예상치 못한 오류가 발생했습니다. 잠시 후 다시 시도해주세요.\"\n",
    "            print(\"-\" * 70)\n",
    "            print(f\"[{self.config.get('persona', '챗봇')}]\\n{final_answer}\")\n",
    "            print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiteratureRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\n",
    "            \"persona\": \"Literature\",\n",
    "            \"role_instructions\": literature_role,\n",
    "            \"pref_extraction_template\": literature_pref_template,\n",
    "            \"consolidate_pref_template\": consolidate_pref_prompt,\n",
    "            \"decision_template\": decision_prompt_template,\n",
    "            \"final_query_template\": literature_final_query_template,\n",
    "            \"refine_template\": literature_refine_template,\n",
    "            \"expansion_template\": literature_expansion_template,\n",
    "            \"re_ranking_template\": re_ranking_prompt,\n",
    "            \"hyde_generation_template\": hyde_generation_prompt,\n",
    "            \"hyde_keyword_template\": hyde_keyword_prompt,\n",
    "            \"retrieval_weights\": {\n",
    "                \"main\": 0.1,\n",
    "                \"author\": 0.5,\n",
    "                \"title\": 0.1,\n",
    "                \"category\": 0.3,\n",
    "            },\n",
    "            \"persona_info\": \"감성, 현재 기분, 선호하는 문학 장르 및 작가 스타일\",\n",
    "        }\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )\n",
    "\n",
    "\n",
    "class ScienceRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\n",
    "            \"persona\": \"Science\",\n",
    "            \"role_instructions\": science_role,\n",
    "            \"pref_extraction_template\": science_pref_template,\n",
    "            \"consolidate_pref_template\": consolidate_pref_prompt,\n",
    "            \"decision_template\": decision_prompt_template,\n",
    "            \"final_query_template\": science_final_query_template,\n",
    "            \"refine_template\": science_refine_template,\n",
    "            \"expansion_template\": science_expansion_template,\n",
    "            \"re_ranking_template\": re_ranking_prompt,\n",
    "            \"hyde_generation_template\": hyde_generation_prompt,\n",
    "            \"hyde_keyword_template\": hyde_keyword_prompt,\n",
    "            \"retrieval_weights\": {\n",
    "                \"main\": 0.1,\n",
    "                \"author\": 0.2,\n",
    "                \"title\": 0.3,\n",
    "                \"category\": 0.4,\n",
    "            },\n",
    "            \"persona_info\": \"정확, 논리, 최신 기술 동향 및 전문 지식을 반영\",\n",
    "        }\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )\n",
    "\n",
    "\n",
    "class GeneralRAGPipeline(BaseRAGPipeline):\n",
    "    def __init__(self, llm, embeddings, vectorstore, es_store, retriever, documents):\n",
    "        config = {\n",
    "            \"persona\": \"General\",\n",
    "            \"role_instructions\": general_role,\n",
    "            \"pref_extraction_template\": general_pref_template,\n",
    "            \"consolidate_pref_template\": consolidate_pref_prompt,  # 선호도 통합 프롬프트 추가\n",
    "            \"decision_template\": decision_prompt_template,  # decision 프롬프트 추가\n",
    "            \"final_query_template\": general_final_query_template,\n",
    "            \"refine_template\": general_refine_template,\n",
    "            \"expansion_template\": general_expansion_template,\n",
    "            \"re_ranking_template\": re_ranking_prompt,\n",
    "            \"hyde_generation_template\": hyde_generation_prompt,\n",
    "            \"hyde_keyword_template\": hyde_keyword_prompt,\n",
    "            \"retrieval_weights\": {\n",
    "                \"main\": 0.25,\n",
    "                \"author\": 0.25,\n",
    "                \"title\": 0.25,\n",
    "                \"category\": 0.25,\n",
    "            },\n",
    "            \"persona_info\": \"친절, 균형잡힌 정보, 사용자의 선호와 분위기를 반영\",\n",
    "        }\n",
    "        super().__init__(\n",
    "            config, llm, embeddings, vectorstore, es_store, retriever, documents\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "페르소나를 선택해주세요:\n",
      "1. 예술/문학 (감성적, 문학적 표현)\n",
      "2. 과학/기술 (논리적, 정확한 정보)\n",
      "3. 범용/일반 (친절, 균형잡힌 정보)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 21:34:08,120 - INFO - 선택된 페르소나: Literature\n",
      "2025-04-07 21:34:08,121 - INFO - --- Turn 1 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Literature' 페르소나로 대화를 시작합니다.\n",
      "대화를 종료하려면 'quit', 'exit', '종료', '그만' 중 하나를 입력하세요.\n",
      "----------------------------------------------------------------------\n",
      "[Literature] 안녕하세요~ 감성적인 문학 도서 추천 챗봇입니다. 어떤 책을 찾으시나요? 당신의 이야기나 감정을 들려주셔도 좋아요.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Turn 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 21:34:14,586 - INFO - === 새로운 사용자 쿼리 처리 시작: '도파민 터지는 소설 추천해줘.' ===\n",
      "2025-04-07 21:34:14,587 - INFO - 사용자 입력에서 선호도 추출 시작: '도파민 터지는 소설 추천해줘....'\n",
      "2025-04-07 21:34:17,526 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:17,529 - INFO - 선호도 업데이트됨 [category]: ['소설']\n",
      "2025-04-07 21:34:17,530 - INFO - 선호도 업데이트됨 [purpose]: ['도파민 터지는']\n",
      "2025-04-07 21:34:17,530 - INFO - 선호도 업데이트 완료. 누적 업데이트 횟수: 1\n",
      "2025-04-07 21:34:17,531 - INFO - 행동 결정 요청 (추천 vs 추가 질문)\n",
      "2025-04-07 21:34:25,501 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:25,504 - INFO - 행동 결정 파싱 결과: 행동='추천', 추가 질문='...'\n",
      "2025-04-07 21:34:25,507 - INFO - 행동: 추천\n",
      "2025-04-07 21:34:25,507 - INFO - 최종 검색 쿼리 생성 시작\n",
      "2025-04-07 21:34:26,217 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:26,223 - INFO - LLM 생성 쿼리 (정제 전): '도파민 터지는 감성 소설 추천'\n",
      "2025-04-07 21:34:27,563 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:27,566 - INFO - 정제된 쿼리: '감각적인 문체와 진한 감동을 전하는 감성 소설 추천'\n",
      "2025-04-07 21:34:27,566 - INFO - 최종 결정된 검색 쿼리: '감각적인 문체와 진한 감동을 전하는 감성 소설 추천'\n",
      "2025-04-07 21:34:27,567 - INFO - 추천 생성 시작. 최종 쿼리: '감각적인 문체와 진한 감동을 전하는 감성 소설 추천'\n",
      "2025-04-07 21:34:27,567 - INFO - 일반 쿼리 검색 수행.\n",
      "2025-04-07 21:34:27,567 - INFO - 최종 리트리버 호출 시작 (쿼리: '감각적인 문체와 진한 감동을 전하는 감성 소설 추천...')\n",
      "2025-04-07 21:34:27,605 - INFO - POST http://localhost:9200/book_bm25_index_v2/_search [status:200 duration:0.032s]\n",
      "2025-04-07 21:34:27,676 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:27,884 - INFO - Async 검색 결과 총 문서 수: 10\n",
      "2025-04-07 21:34:27,884 - INFO - [Async] 병합 전 입력 문서 수: 10\n",
      "2025-04-07 21:34:27,885 - INFO - [Async] ISBN 병합 그룹 수: 9\n",
      "2025-04-07 21:34:27,886 - INFO - [Async] 병합 후 최종 문서 수: 9\n",
      "2025-04-07 21:34:27,887 - INFO - 검색된 문서 수 (ISBN 병합 완료됨): 9\n",
      "2025-04-07 21:34:27,888 - INFO - 초기 및 확장 검색 후 고려할 총 고유 문서 수: 9\n",
      "2025-04-07 21:34:27,888 - INFO - 리랭킹 수행...\n",
      "2025-04-07 21:34:27,978 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:27,987 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,102 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,236 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,321 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,399 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,477 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,570 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,656 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,773 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,871 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:28,958 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:29,031 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:29,112 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:29,182 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/api-tools/embedding/v2 \"HTTP/1.1 200 OK\"\n",
      "2025-04-07 21:34:29,190 - INFO - 리랭킹 완료 (정규화 가중치 방식)\n",
      "2025-04-07 21:34:29,190 - INFO - 1. 제목: 풀빛 빅북 세트(전10권) | ISBN: 9791161723648 | 점수: 0.5114\n",
      "2025-04-07 21:34:29,190 - INFO - 2. 제목: 너무 긴 하루(그린시선 1) | ISBN: 9788995810552 | 점수: 0.5053\n",
      "2025-04-07 21:34:29,191 - INFO - 3. 제목: 무심에서 감성으로 | ISBN: 9791165529543 | 점수: 0.5023\n",
      "2025-04-07 21:34:29,192 - INFO - 4. 제목: 설렌 감성으로 가울문 | ISBN: 9791162843079 | 점수: 0.4947\n",
      "2025-04-07 21:34:29,192 - INFO - 5. 제목: 오페라 분수 | ISBN: 9791167910172 | 점수: 0.4943\n",
      "2025-04-07 21:34:29,193 - INFO - 6. 제목: 하비루의 길 | ISBN: 9791141016029 | 점수: 0.4901\n",
      "2025-04-07 21:34:29,193 - INFO - 7. 제목: 집 떠난 뒤 맑음상 | ISBN: 9791160272376 | 점수: 0.4607\n",
      "2025-04-07 21:34:29,194 - INFO - 8. 제목: 희망은 깨어있네 SATB vol. 1 | ISBN: 9788960577428 | 점수: 0.4163\n",
      "2025-04-07 21:34:29,195 - INFO - 9. 제목: 희망은 깨어있네 SSA vol. 1 | ISBN: 9788960577435 | 점수: 0.4096\n",
      "2025-04-07 21:34:29,195 - INFO - 리랭킹 완료 (정규화 가중치 방식, metadata 이중 구조 대응).\n",
      "2025-04-07 21:34:29,196 - INFO - 최종 추천 후보 문서 수: 3\n",
      "2025-04-07 21:34:29,284 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-04-07 21:34:29,286 - ERROR - [청크 요약] LLM 호출 중 예외 발생: Error response 429 while fetching https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003: {\"status\":{\"code\":\"42901\",\"message\":\"Too many requests - rate exceeded\"},\"result\":null}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_7132\\1161191380.py\", line 31, in async_invoke_llm\n",
      "    response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 490, in _generate\n",
      "    response = self._completion_with_retry(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 422, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 161, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003: {\"status\":{\"code\":\"42901\",\"message\":\"Too many requests - rate exceeded\"},\"result\":null}\n",
      "2025-04-07 21:34:29,287 - WARNING - LLM 요약 실패 또는 부적절. Fallback 요약 사용: '크게 생각하고, 넓게 내다보고, 깊이 있고 풍부한 지식을 만날 수 있게 해 주는 빅북 그림책! 책이 크니까 받아들이는 감동과 지식도 큽니다! 큰 세상을 꿈꾸는 아이들을 위한 더 크...'\n",
      "2025-04-07 21:34:29,357 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-04-07 21:34:29,360 - ERROR - [청크 요약] LLM 호출 중 예외 발생: Error response 429 while fetching https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003: {\"status\":{\"code\":\"42901\",\"message\":\"Too many requests - rate exceeded\"},\"result\":null}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_7132\\1161191380.py\", line 31, in async_invoke_llm\n",
      "    response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 490, in _generate\n",
      "    response = self._completion_with_retry(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 422, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 161, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003: {\"status\":{\"code\":\"42901\",\"message\":\"Too many requests - rate exceeded\"},\"result\":null}\n",
      "2025-04-07 21:34:29,361 - WARNING - LLM 요약 실패 또는 부적절. Fallback 요약 사용: '한국 시단의 중견 시인으로서, 현재 왕성하게 시작들을 발표하며 꾸준히 문단 활동을 하고 있는 김지원 시인의 아홉 번째 시집. 정확한 시어로 맑은 영혼을 노래하는 간결하면서도 의미 ...'\n",
      "2025-04-07 21:34:29,451 - INFO - HTTP Request: POST https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003 \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-04-07 21:34:29,453 - ERROR - [청크 요약] LLM 호출 중 예외 발생: Error response 429 while fetching https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003: {\"status\":{\"code\":\"42901\",\"message\":\"Too many requests - rate exceeded\"},\"result\":null}\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\computer\\AppData\\Local\\Temp\\ipykernel_7132\\1161191380.py\", line 31, in async_invoke_llm\n",
      "    response = await asyncio.to_thread(llm_clova.invoke, prompt)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\threads.py\", line 25, in to_thread\n",
      "    return await loop.run_in_executor(None, func_call)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\tasks.py\", line 349, in __wakeup\n",
      "    future.result()\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 307, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 843, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 683, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 908, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 490, in _generate\n",
      "    response = self._completion_with_retry(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 422, in _completion_with_retry\n",
      "    _raise_on_error(response)\n",
      "  File \"c:\\Users\\computer\\anaconda3\\envs\\Kill_the_RAG_env\\Lib\\site-packages\\langchain_community\\chat_models\\naver.py\", line 161, in _raise_on_error\n",
      "    raise httpx.HTTPStatusError(\n",
      "httpx.HTTPStatusError: Error response 429 while fetching https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/HCX-003: {\"status\":{\"code\":\"42901\",\"message\":\"Too many requests - rate exceeded\"},\"result\":null}\n",
      "2025-04-07 21:34:29,455 - WARNING - LLM 요약 실패 또는 부적절. Fallback 요약 사용: '감성 시의 대가 윤보영 시인도 감탄한 일상에서 쏟아지는 빛나는 감성들 사람에게 감성은 매우 중요하다. 감성 시는 마음 치료이고 정신적 혼란을 극복하기에 좋은 매체이다. 부디 팬데믹...'\n",
      "2025-04-07 21:34:29,455 - INFO - '_generate_recommendations' 종료. last_recommendations 업데이트 (3개): ['풀빛 빅북 세트(전10권)', '너무 긴 하루(그린시선 1)', '무심에서 감성으로']\n",
      "2025-04-07 21:34:29,456 - INFO - 추천 응답 생성 완료.\n",
      "2025-04-07 21:34:29,456 - INFO - 챗봇 응답 생성 완료 (Action: 추천). 응답 일부: 이런 책들은 어떠신가요? 마음에 드는 책이 있다면 더 자세히 알려드릴게요.\n",
      "\n",
      "1. \n",
      "표지: https://image.aladin.co.kr/product/26882/98/cover500/k152730408_1.jpg\n",
      "제목: 풀빛 빅북 세트(전10권)\n",
      "저자: 보이치에흐 그라이코브스키 지음, 이지원 옮김\n",
      "- 추천 이유: 크게 생각하고, 넓게 내다보고, ...\n",
      "2025-04-07 21:34:29,457 - INFO - --- Turn 2 시작 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "[Literature]\n",
      "이런 책들은 어떠신가요? 마음에 드는 책이 있다면 더 자세히 알려드릴게요.\n",
      "\n",
      "1. \n",
      "표지: https://image.aladin.co.kr/product/26882/98/cover500/k152730408_1.jpg\n",
      "제목: 풀빛 빅북 세트(전10권)\n",
      "저자: 보이치에흐 그라이코브스키 지음, 이지원 옮김\n",
      "- 추천 이유: 크게 생각하고, 넓게 내다보고, 깊이 있고 풍부한 지식을 만날 수 있게 해 주는 빅북 그림책! 책이 크니까 받아들이는 감동과 지식도 큽니다! 큰 세상을 꿈꾸는 아이들을 위한 더 크고 더 깊고 더 풍부한 그림책 시리즈 작고 어린 아이들이라고 해서 생각의 크기와 시야까지 좁지는 않습니다. 어린 아이들일수록 크게 생각하고, 넓게 내다 보고, 깊이 있고 풍부한 지식을 받아들일 수 있게 해 주는 것이 중요합니다. 그래야 큰 세상을 꿈꿀 수 있으니까요. 풀빛 빅북 시리즈는 큰 세상을 꿈꾸는 아이들을 위한 그림책 시리즈입니다. 우리가 흔히 볼...\n",
      "\n",
      "2. \n",
      "표지: https://image.aladin.co.kr/product/23860/61/cover500/8995810556_1.jpg\n",
      "제목: 너무 긴 하루(그린시선 1)\n",
      "저자: 김지원 지음\n",
      "- 추천 이유: 한국 시단의 중견 시인으로서, 현재 왕성하게 시작들을 발표하며 꾸준히 문단 활동을 하고 있는 김지원 시인의 아홉 번째 시집. 정확한 시어로 맑은 영혼을 노래하는 간결하면서도 의미 깊은 시편들은 독자로 하여금 가슴 벅찬 감동을 느끼게 하고, 더 깊은 사유에 빠져들게 한다. 때론 아련한 추억을 떠올리게 하고, 때론 날카로운 시어로 현실을 간파하는 73편의 시와, 수려한 문체와 탁월한 현실 감각으로 물 흐르듯 써낸 산문 2편이 수록되어 있다.\n",
      "\n",
      "3. \n",
      "표지: https://image.aladin.co.kr/product/27568/8/cover500/k102733019_1.jpg\n",
      "제목: 무심에서 감성으로\n",
      "저자: 心청이, 이계선, 서복례, 염숙영, 탁영란, 김영희, 김석태, 우명자, 한미정, 최서윤, 박천혜, 김수.. 지음\n",
      "- 추천 이유: 감성 시의 대가 윤보영 시인도 감탄한 일상에서 쏟아지는 빛나는 감성들 사람에게 감성은 매우 중요하다. 감성 시는 마음 치료이고 정신적 혼란을 극복하기에 좋은 매체이다. 부디 팬데믹으로 인한 혼돈의 시기에 감성 시를 통하여 우리 함께 어려운 상황을 이겨내고 감동을 나누어 그늘진 마음에 따스한 빛이 되기를 바란다.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "--- Turn 2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 21:34:50,075 - INFO - Default Milvus 연결 해제 완료.\n",
      "2025-04-07 21:34:50,076 - INFO - 프로그램 종료.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[대화 종료]\n"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "def main():\n",
    "    previous_additional_question_embeddings.clear()\n",
    "    print(\"페르소나를 선택해주세요:\")\n",
    "    print(\"1. 예술/문학 (감성적, 문학적 표현)\")\n",
    "    print(\"2. 과학/기술 (논리적, 정확한 정보)\")\n",
    "    print(\"3. 범용/일반 (친절, 균형잡힌 정보)\")\n",
    "    pipeline = None\n",
    "    while pipeline is None:\n",
    "        choice = input(\"원하는 페르소나 번호를 입력하세요 (1, 2, 3): \").strip()\n",
    "        pipeline_map = {\n",
    "            \"1\": LiteratureRAGPipeline,\n",
    "            \"2\": ScienceRAGPipeline,\n",
    "            \"3\": GeneralRAGPipeline,\n",
    "        }\n",
    "        if choice in pipeline_map:\n",
    "            PipelineClass = pipeline_map[choice]\n",
    "            try:\n",
    "                pipeline = PipelineClass(\n",
    "                    llm=llm_clova,\n",
    "                    embeddings=ncp_embeddings,\n",
    "                    vectorstore=vectorstore,\n",
    "                    es_store=es_store,\n",
    "                    retriever=merged_hybrid_retriever,\n",
    "                    documents=documents,\n",
    "                )\n",
    "                logger.info(f\"선택된 페르소나: {pipeline.config['persona']}\")\n",
    "                print(f\"\\n'{pipeline.config['persona']}' 페르소나로 대화를 시작합니다.\")\n",
    "                print(\n",
    "                    \"대화를 종료하려면 'quit', 'exit', '종료', '그만' 중 하나를 입력하세요.\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                logger.critical(\n",
    "                    f\"파이프라인 초기화 중 치명적 오류 발생: {e}\", exc_info=True\n",
    "                )\n",
    "                print(\"오류: 파이프라인을 초기화할 수 없습니다. 로그를 확인하세요.\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"잘못된 선택입니다. 1, 2, 3 중 하나를 입력해주세요.\")\n",
    "    try:\n",
    "        asyncio.run(pipeline.interactive_multi_turn_qa())\n",
    "    except Exception as e:\n",
    "        logger.critical(f\"메인 실행 루프에서 치명적 오류 발생: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        try:\n",
    "            if connections.get_connection_addr(\"default\"):\n",
    "                connections.disconnect(\"default\")\n",
    "                logger.info(\"Default Milvus 연결 해제 완료.\")\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Milvus 연결 해제 중 오류 발생 (무시 가능): {e}\")\n",
    "        logger.info(\"프로그램 종료.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 사용자 선호도 추출 프롬프트\n",
    "extract_pref_prompt_v2 = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "다음 사용자 발화에서 사용자의 선호도 및 책에 대한 요구사항을 아래 JSON 형식으로 추출해라. 각 항목은 관련된 정보가 명확할때만 명확한 항목에 포함(소설 -> category)하고, 없다면 빈 리스트 `[]` 또는 빈 문자열 `\"\"`로 남겨라. 여러개가 추출될 수 있는 항목은 리스트로 추출하라.\n",
    "사용자 입력에서 모호한 정보는 implicit info로 포함해라.\n",
    "존재하지 않는 사용자 선호도 정보는 임의로 생성하지 마라.\n",
    "\n",
    "입력: {{ text }}\n",
    "\n",
    "출력 형식 (JSON, 다른 설명 없이 JSON만 출력):\n",
    "{\n",
    "    \"title\": [<!-- 추출된 책 제목 -->],\n",
    "    \"author\": [<!-- 추출된 책 저자 -->],\n",
    "    \"category\": [<!-- 추출된 책 분류/장르(소설/에세이/기술) -->],\n",
    "    \"author_intro\": [<!-- 저자 특성 언급/요구사항 -->],\n",
    "    \"book_intro\": [<!-- 줄거리 관련 언급/요구사항 -->],\n",
    "    \"table_of_contents\": [<!-- 세부적인 키워드 언급/요구사항 -->],\n",
    "    \"purpose\": [<!-- 사용자의 독서 목적/이유 목록 (예: '재미', '학습', '시간 때우기', '기분') -->],\n",
    "    \"implicit info\": [<!-- 추천해야 할 책에 대한 암시적 정보/특징/분위기 목록 (예: '밝은 분위기', '특정 상황에 어울리는 책', '최신 기술 동향') -->]\n",
    "}\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",  # 변수 치환을 위한 탬플릿\n",
    ")\n",
    "\n",
    "# 2. 선호도 통합 프롬프트\n",
    "consolidate_pref_prompt = PromptTemplate(\n",
    "    input_variables=[\"existing_preferences\", \"new_preferences\"],\n",
    "    template=\"\"\"\n",
    "기존에 수집된 사용자 선호도 정보와 새로 추출된 선호도 정보가 주어졌다. 두 정보를 지능적으로 통합하여 중복을 제거하고 관련 내용을 요약/결합하여 최종 선호도 목록을 생성해라.\n",
    "\n",
    "[기존 선호도]\n",
    "{{ existing_preferences }}\n",
    "\n",
    "[새로운 선호도]\n",
    "{{ new_preferences }}\n",
    "\n",
    "[통합된 최종 선호도 목록]\n",
    "(아래 목록 형태로만 출력, 각 항목은 문자열 리스트)\n",
    "- 항목1: [\"통합 내용1\", \"통합 내용2\"]\n",
    "- 항목2: [\"통합 내용3\"]\n",
    "...\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 3. Decision Prompt\n",
    "decision_prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 맥락]\n",
    "사용자 대화 내역:\n",
    "{{ history }}\n",
    "사용자의 최신 질문: \"{{ query }}\"\n",
    "수집된 사용자 선호도:\n",
    "{{ preferences }}\n",
    "\n",
    "[역할 및 목표]\n",
    "{{ role_instructions }}\n",
    "현재 대화 상황, 질문, 수집된 선호도를 분석하여 아래 두 가지 행동 중 하나만 결정하고 필요한 정보를 생성하라.\n",
    "- \"추천\": 사용자가 명시적으로 추천을 요청했거나, 사용자의 선호도 정보(카테고리, 저자, 목적, 책 줄거리, 사용자 수준, 분위기 등)를 반드시 3개 이상 수집했을 때만 추천에 들어가라.\n",
    "- \"추가 질문\": 추천하기에 정보가 부족하거나 모호할 때, **아직 수집되지 않았거나 더욱 구체적인 선호도 정보**를 얻기 위한 질문 생성. (예: 어떤 장르를 선호하시나요? 특정 작가를 찾으시나요? 책을 읽는 목적이 무엇인가요?)\n",
    "\n",
    "[출력 형식] (반드시 아래 형식만 정확히 따를 것)\n",
    "행동: <추천 또는 추가 질문>\n",
    "추가 질문: <\"추가 질문\" 행동일 경우 구체적인 질문 생성, \"추천\" 행동일 경우 빈 문자열>\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"preferences\", \"role_instructions\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 4. Final Query Generation Prompt\n",
    "final_query_generation_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "[대화 요약]\n",
    "{{ history }}\n",
    "\n",
    "[사용자 요청]\n",
    "{{ query }}\n",
    "\n",
    "[페르소나 정보]\n",
    "{{ persona_info }}\n",
    "\n",
    "[사용자 선호도 요약]\n",
    "{{ preferences }}\n",
    "\n",
    "위 정보를 전부 활용하여, 도서 검색에 가장 유용한 **핵심 키워드 중심의 최종 검색 쿼리**를 한 문장으로 작성하라.\n",
    "오직 검색 쿼리 문장만 출력하라.\n",
    "\"\"\",\n",
    "    input_variables=[\"history\", \"query\", \"persona_info\", \"preferences\"],\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 5. Refine Prompt - 추후 더 업데이트를 통해 정제 기능 활성화\n",
    "refine_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"주어진 검색 쿼리를 분석하여, 검색 엔진이나 다음 단계에서 사용하기 좋은 명확하고 간결한 단일 문장으로 정제해라. 불필요한 설명 없이 오직 정제된 쿼리 문장만 출력해라.\n",
    "\n",
    "- \"~~비슷한\", \"~ 같은\", \"~ 분위기의\" 라고 사용자가 언급하면, 해당 책/저자의 **특징(예: 장르, 분위기, 핵심 소재, 작가 스타일)**을 반영하여 확장하라. 책 제목이나 저자 이름은 절대 직접 포함하지 마라.\n",
    "- 예시 (입력: 해리포터 시리즈물같은 판타지 소설 알려줘) ->\n",
    "1. 마법학교 배경의 청소년 판타지 소설 추천\n",
    "2. 선과 악의 대결을 다룬 영국 판타지 시리즈\n",
    "3. 성장 서사를 담은 인기 판타지 소설\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[정제된 검색 쿼리]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 6. Query Expansion Prompt\n",
    "query_expansion_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"주어진 원본 검색 쿼리를 바탕으로, 관련성이 높으면서도 다양한 측면을 탐색할 수 있는 확장된 검색 쿼리 3개를 생성해라. 확장된 쿼리는 원본 쿼리의 핵심 의도를 반드시 유지해야 한다. 다른 설명이나 서론 없이, 오직 번호(1., 2., 3.)가 매겨진 확장 쿼리 목록만 한 줄에 하나씩 출력해라.\n",
    "\n",
    "[원본 검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[확장된 검색 쿼리 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 7. Re_ranking Prompt\n",
    "re_ranking_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"documents\"],\n",
    "    template=\"\"\"사용자의 검색 쿼리는 다음과 같습니다: \"{{ query }}\"\n",
    "다음은 검색된 도서 목록입니다 (내용은 일부만 표시됨):\n",
    "{% for doc in documents %}\n",
    "{{ loop.index }}. 제목: {{ doc.metadata.get('title', '제목 없음') }}, 저자: {{ doc.metadata.get('author', '저자 없음') }}, 내용 일부: {{ doc.page_content | truncate(200) }}\n",
    "{% endfor %}\n",
    "\n",
    "위 검색 결과를 사용자의 검색 쿼리 \"{{ query }}\"와의 관련성, 그리고 문서 내용의 충실도를 종합적으로 고려하여 가장 적합한 순서대로 재배치하라.\n",
    "가장 관련성이 높은 도서를 목록의 맨 위에 배치하고, 순위가 매겨진 **도서 제목과 저자**만으로 결과를 다음 형식으로 출력하라.\n",
    "\n",
    "[출력 형식 예시]\n",
    "1. 제목: <가장 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "2. 제목: <두 번째 관련성 높은 책 제목>, 저자: <저자 이름>\n",
    "...\n",
    "\n",
    "[리랭킹된 도서 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 8. HyDE Generation Prompt\n",
    "hyde_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"다음 검색 쿼리에 완벽하게 부합하는 **이상적인 가상의 책**을 추천하고 이를 기반으로 **간결한 요약(2-3 문장)**을 생성해라. 이 요약은 해당 쿼리로 책을 찾는 사용자가 가장 만족할 만한 내용을 담고 있어야 한다. 오직 생성된 요약 텍스트만 출력하라.\n",
    "\n",
    "[검색 쿼리]\n",
    "{{ query }}\n",
    "\n",
    "[가상의 책 요약]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")\n",
    "\n",
    "# 9. Persona prompt\n",
    "literature_role = \"너는 감성적이고 문학적인 도서 추천 챗봇이다. 사용자의 감정과 취향을 깊이 이해하고 공감하는 말투로 문학적인 표현을 사용하여 책을 추천해라.\"\n",
    "science_role = \"너는 정확하고 논리적인 과학/기술 도서 추천 챗봇이다. 사용자의 지식 수준과 관심 분야를 파악하고, 최신 정보와 기술 동향을 반영하여 체계적으로 책을 추천해라.\"\n",
    "general_role = \"너는 친절하고 신뢰할 수 있는 범용 도서 추천 챗봇이다. 친근한 말투로 다양한 분야의 책에 대해 균형 잡힌 시각으로 정보를 제공하고, 사용자의 요구사항에 맞춰 명확하고 이해하기 쉽게 책을 추천해라.\"\n",
    "\n",
    "\n",
    "# 10. hyde_keyword_prompt\n",
    "hyde_keyword_prompt = PromptTemplate(\n",
    "    input_variables=[\"hyde_summary\"],\n",
    "    template=\"\"\"다음은 사용자의 질문에 이상적으로 부합하는 가상의 책 요약입니다:\n",
    "\"{{ hyde_summary }}\"\n",
    "\n",
    "이 요약 내용에서 **핵심 키워드 5개**를 추출하여 쉼표(,)로 구분하여 나열해라. 오직 키워드 목록만 출력하라.\n",
    "\n",
    "[핵심 키워드 목록]\n",
    "\"\"\",\n",
    "    template_format=\"jinja2\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kill_the_RAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
